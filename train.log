2019-09-11 21:25:32,383 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:25:36,169 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:25:36,416 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:25:36,486 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 21:26:23,291 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:26:26,757 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:26:26,995 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:26:27,064 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 21:31:55,514 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:31:58,839 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:31:59,090 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:31:59,162 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 21:34:21,515 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:34:24,895 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:34:25,134 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:34:25,203 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 21:37:09,652 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:37:13,110 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:37:13,353 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:37:13,423 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 21:38:26,258 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=100, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 21:38:34,948 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:38:38,153 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:38:38,228 [cnn_ctc.py:50] INFO {"class_name": "Model", "config": {"name": "model_1", "layers": [{"name": "the_inputs", "class_name": "InputLayer", "config": {"batch_input_shape": [null, null, 200, 1], "dtype": "float32", "sparse": false, "name": "the_inputs"}, "inbound_nodes": []}, {"name": "conv2d_1", "class_name": "Conv2D", "config": {"name": "conv2d_1", "trainable": true, "dtype": "float32", "filters": 32, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["the_inputs", 0, 0, {}]]]}, {"name": "batch_normalization_1", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_1", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_1", 0, 0, {}]]]}, {"name": "conv2d_2", "class_name": "Conv2D", "config": {"name": "conv2d_2", "trainable": true, "dtype": "float32", "filters": 32, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["batch_normalization_1", 0, 0, {}]]]}, {"name": "batch_normalization_2", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_2", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_2", 0, 0, {}]]]}, {"name": "max_pooling2d_1", "class_name": "MaxPooling2D", "config": {"name": "max_pooling2d_1", "trainable": true, "dtype": "float32", "pool_size": [2, 2], "padding": "valid", "strides": [2, 2], "data_format": "channels_last"}, "inbound_nodes": [[["batch_normalization_2", 0, 0, {}]]]}, {"name": "conv2d_3", "class_name": "Conv2D", "config": {"name": "conv2d_3", "trainable": true, "dtype": "float32", "filters": 64, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["max_pooling2d_1", 0, 0, {}]]]}, {"name": "batch_normalization_3", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_3", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_3", 0, 0, {}]]]}, {"name": "conv2d_4", "class_name": "Conv2D", "config": {"name": "conv2d_4", "trainable": true, "dtype": "float32", "filters": 64, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["batch_normalization_3", 0, 0, {}]]]}, {"name": "batch_normalization_4", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_4", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_4", 0, 0, {}]]]}, {"name": "max_pooling2d_2", "class_name": "MaxPooling2D", "config": {"name": "max_pooling2d_2", "trainable": true, "dtype": "float32", "pool_size": [2, 2], "padding": "valid", "strides": [2, 2], "data_format": "channels_last"}, "inbound_nodes": [[["batch_normalization_4", 0, 0, {}]]]}, {"name": "conv2d_5", "class_name": "Conv2D", "config": {"name": "conv2d_5", "trainable": true, "dtype": "float32", "filters": 128, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["max_pooling2d_2", 0, 0, {}]]]}, {"name": "batch_normalization_5", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_5", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_5", 0, 0, {}]]]}, {"name": "conv2d_6", "class_name": "Conv2D", "config": {"name": "conv2d_6", "trainable": true, "dtype": "float32", "filters": 128, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["batch_normalization_5", 0, 0, {}]]]}, {"name": "batch_normalization_6", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_6", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_6", 0, 0, {}]]]}, {"name": "max_pooling2d_3", "class_name": "MaxPooling2D", "config": {"name": "max_pooling2d_3", "trainable": true, "dtype": "float32", "pool_size": [2, 2], "padding": "valid", "strides": [2, 2], "data_format": "channels_last"}, "inbound_nodes": [[["batch_normalization_6", 0, 0, {}]]]}, {"name": "conv2d_7", "class_name": "Conv2D", "config": {"name": "conv2d_7", "trainable": true, "dtype": "float32", "filters": 128, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["max_pooling2d_3", 0, 0, {}]]]}, {"name": "batch_normalization_7", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_7", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_7", 0, 0, {}]]]}, {"name": "conv2d_8", "class_name": "Conv2D", "config": {"name": "conv2d_8", "trainable": true, "dtype": "float32", "filters": 128, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["batch_normalization_7", 0, 0, {}]]]}, {"name": "batch_normalization_8", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_8", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_8", 0, 0, {}]]]}, {"name": "conv2d_9", "class_name": "Conv2D", "config": {"name": "conv2d_9", "trainable": true, "dtype": "float32", "filters": 128, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["batch_normalization_8", 0, 0, {}]]]}, {"name": "batch_normalization_9", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_9", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_9", 0, 0, {}]]]}, {"name": "conv2d_10", "class_name": "Conv2D", "config": {"name": "conv2d_10", "trainable": true, "dtype": "float32", "filters": 128, "kernel_size": [3, 3], "strides": [1, 1], "padding": "same", "data_format": "channels_last", "dilation_rate": [1, 1], "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["batch_normalization_9", 0, 0, {}]]]}, {"name": "batch_normalization_10", "class_name": "BatchNormalization", "config": {"name": "batch_normalization_10", "trainable": true, "dtype": "float32", "axis": -1, "momentum": 0.99, "epsilon": 0.001, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "moving_mean_initializer": {"class_name": "Zeros", "config": {}}, "moving_variance_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "inbound_nodes": [[["conv2d_10", 0, 0, {}]]]}, {"name": "reshape_1", "class_name": "Reshape", "config": {"name": "reshape_1", "trainable": true, "dtype": "float32", "target_shape": [-1, 3200]}, "inbound_nodes": [[["batch_normalization_10", 0, 0, {}]]]}, {"name": "dropout_1", "class_name": "Dropout", "config": {"name": "dropout_1", "trainable": true, "dtype": "float32", "rate": 0.2, "noise_shape": null, "seed": null}, "inbound_nodes": [[["reshape_1", 0, 0, {}]]]}, {"name": "dense_1", "class_name": "Dense", "config": {"name": "dense_1", "trainable": true, "dtype": "float32", "units": 256, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["dropout_1", 0, 0, {}]]]}, {"name": "dropout_2", "class_name": "Dropout", "config": {"name": "dropout_2", "trainable": true, "dtype": "float32", "rate": 0.2, "noise_shape": null, "seed": null}, "inbound_nodes": [[["dense_1", 0, 0, {}]]]}, {"name": "dense_2", "class_name": "Dense", "config": {"name": "dense_2", "trainable": true, "dtype": "float32", "units": 1042, "activation": "softmax", "use_bias": true, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"scale": 2.0, "mode": "fan_in", "distribution": "normal", "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "inbound_nodes": [[["dropout_2", 0, 0, {}]]]}], "input_layers": [["the_inputs", 0, 0]], "output_layers": [["dense_2", 0, 0]]}, "keras_version": "2.2.5", "backend": "tensorflow"}
2019-09-11 21:38:38,379 [train.py:82] INFO # of samples: 10000
2019-09-11 21:38:38,379 [train.py:83] INFO mini-batch size: 32
2019-09-11 21:38:38,379 [train.py:84] INFO # of iterations per epoch: 312
2019-09-11 21:38:38,416 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:38:38,491 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 21:39:06,583 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=100, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 21:39:14,967 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:39:18,206 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:39:18,269 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 21:39:18,270 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 21:39:18,270 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 21:39:18,270 [layer_utils.py:109] INFO =================================================================
2019-09-11 21:39:18,270 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 21:39:18,270 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,270 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 21:39:18,270 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,271 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 21:39:18,271 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,271 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 21:39:18,271 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,271 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 21:39:18,272 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,272 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 21:39:18,272 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,272 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 21:39:18,272 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,273 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 21:39:18,273 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,273 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 21:39:18,273 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,273 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 21:39:18,274 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,274 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 21:39:18,274 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,274 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 21:39:18,274 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,275 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 21:39:18,275 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,275 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 21:39:18,275 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,276 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 21:39:18,276 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,276 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 21:39:18,276 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,276 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:39:18,276 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,277 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 21:39:18,277 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,277 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:39:18,277 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,278 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 21:39:18,278 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,278 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:39:18,278 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,278 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 21:39:18,278 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,279 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 21:39:18,279 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,279 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 21:39:18,279 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,279 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 21:39:18,280 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,280 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 21:39:18,280 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,280 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 21:39:18,281 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,281 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 21:39:18,281 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:39:18,281 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 21:39:18,281 [layer_utils.py:169] INFO =================================================================
2019-09-11 21:39:18,282 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 21:39:18,282 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 21:39:18,282 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 21:39:18,282 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 21:39:18,431 [train.py:82] INFO # of samples: 10000
2019-09-11 21:39:18,431 [train.py:83] INFO mini-batch size: 32
2019-09-11 21:39:18,431 [train.py:84] INFO # of iterations per epoch: 312
2019-09-11 21:39:18,467 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:39:18,537 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 21:45:41,104 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=100, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 21:45:49,745 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:45:52,965 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:45:53,034 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 21:45:53,034 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 21:45:53,034 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 21:45:53,034 [layer_utils.py:109] INFO =================================================================
2019-09-11 21:45:53,034 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 21:45:53,035 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,035 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 21:45:53,035 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,035 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 21:45:53,035 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,035 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 21:45:53,036 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,036 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 21:45:53,036 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,036 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 21:45:53,036 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,036 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 21:45:53,036 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,036 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 21:45:53,037 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,037 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 21:45:53,037 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,037 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 21:45:53,037 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,037 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 21:45:53,037 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,038 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 21:45:53,038 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,038 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 21:45:53,038 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,038 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 21:45:53,038 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,038 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 21:45:53,039 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,039 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 21:45:53,039 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,039 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:45:53,039 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,039 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 21:45:53,040 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,040 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:45:53,040 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,040 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 21:45:53,040 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,040 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:45:53,041 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,041 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 21:45:53,041 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,041 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 21:45:53,041 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,041 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 21:45:53,041 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,042 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 21:45:53,042 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,042 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 21:45:53,042 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,042 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 21:45:53,042 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,042 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 21:45:53,042 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:45:53,043 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 21:45:53,043 [layer_utils.py:169] INFO =================================================================
2019-09-11 21:45:53,043 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 21:45:53,044 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 21:45:53,044 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 21:45:53,044 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 21:45:53,194 [train.py:82] INFO # of samples: 10000
2019-09-11 21:45:53,195 [train.py:83] INFO mini-batch size: 32
2019-09-11 21:45:53,195 [train.py:84] INFO # of iterations per epoch: 312
2019-09-11 21:45:53,232 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:45:53,307 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 21:46:42,253 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=100, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 21:46:50,634 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 21:46:53,869 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 21:46:53,933 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 21:46:53,933 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 21:46:53,933 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 21:46:53,933 [layer_utils.py:109] INFO =================================================================
2019-09-11 21:46:53,933 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 21:46:53,933 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,933 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 21:46:53,934 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,934 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 21:46:53,934 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,934 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 21:46:53,934 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,934 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 21:46:53,934 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,934 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 21:46:53,935 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,935 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 21:46:53,935 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,935 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 21:46:53,935 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,935 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 21:46:53,935 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,936 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 21:46:53,936 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,936 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 21:46:53,936 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,936 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 21:46:53,936 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,937 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 21:46:53,937 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,937 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 21:46:53,937 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,937 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 21:46:53,937 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,937 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 21:46:53,938 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,938 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:46:53,938 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,938 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 21:46:53,938 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,938 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:46:53,938 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,939 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 21:46:53,939 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,939 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 21:46:53,939 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,939 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 21:46:53,939 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,940 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 21:46:53,940 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,940 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 21:46:53,940 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,940 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 21:46:53,940 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,940 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 21:46:53,940 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,941 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 21:46:53,941 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,941 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 21:46:53,941 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 21:46:53,941 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 21:46:53,941 [layer_utils.py:169] INFO =================================================================
2019-09-11 21:46:53,942 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 21:46:53,942 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 21:46:53,942 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 21:46:53,942 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 21:46:54,082 [train.py:82] INFO # of samples: 10000
2019-09-11 21:46:54,083 [train.py:83] INFO mini-batch size: 32
2019-09-11 21:46:54,083 [train.py:84] INFO # of iterations per epoch: 312
2019-09-11 21:46:54,117 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 21:46:54,187 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:04:19,303 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:04:27,963 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:04:31,118 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:04:31,182 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:04:31,182 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:04:31,182 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:04:31,183 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:04:31,183 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:04:31,183 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,183 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:04:31,183 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,183 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:04:31,183 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,183 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:04:31,184 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,184 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:04:31,184 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,184 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:04:31,184 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,184 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:04:31,185 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,185 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:04:31,185 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,185 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:04:31,185 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,185 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:04:31,186 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,186 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:04:31,186 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,187 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:04:31,187 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,187 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:04:31,187 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,187 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:04:31,187 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,187 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:04:31,187 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,187 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:04:31,188 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,188 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:04:31,188 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,188 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:04:31,188 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,188 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:04:31,188 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,189 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:04:31,189 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,189 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:04:31,189 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,189 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:04:31,189 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,189 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:04:31,190 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,190 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:04:31,190 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,190 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:04:31,190 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,190 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:04:31,190 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,190 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:04:31,191 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,191 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:04:31,191 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:04:31,191 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:04:31,191 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:04:31,192 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:04:31,192 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:04:31,192 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:04:31,192 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:04:31,332 [train.py:82] INFO # of samples: 10000
2019-09-11 22:04:31,333 [train.py:83] INFO mini-batch size: 32
2019-09-11 22:04:31,333 [train.py:84] INFO # of iterations per epoch: 312
2019-09-11 22:04:31,368 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:04:31,437 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:12:17,781 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:12:26,317 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:12:29,571 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:12:29,635 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:12:29,635 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:12:29,635 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:12:29,635 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:12:29,636 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:12:29,636 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,636 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:12:29,636 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,636 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:12:29,636 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,636 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:12:29,637 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,637 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:12:29,637 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,637 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:12:29,637 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,637 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:12:29,637 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,637 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:12:29,638 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,638 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:12:29,638 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,638 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:12:29,638 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,638 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:12:29,639 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,639 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:12:29,639 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,639 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:12:29,639 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,639 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:12:29,639 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,639 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:12:29,639 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,640 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:12:29,640 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,640 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:12:29,640 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,640 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:12:29,640 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,641 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:12:29,641 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,641 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:12:29,641 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,641 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:12:29,641 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,641 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:12:29,641 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,642 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:12:29,642 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,642 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:12:29,642 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,642 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:12:29,642 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,642 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:12:29,642 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,643 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:12:29,643 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,643 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:12:29,643 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:12:29,643 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:12:29,643 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:12:29,644 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:12:29,644 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:12:29,644 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:12:29,644 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:12:29,794 [train.py:82] INFO # of samples: 10000
2019-09-11 22:12:29,794 [train.py:83] INFO mini-batch size: 32
2019-09-11 22:12:29,795 [train.py:84] INFO # of iterations per epoch: 312
2019-09-11 22:12:29,830 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:12:29,900 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:14:26,979 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:14:35,526 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:14:37,947 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:14:38,010 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:14:38,010 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:14:38,011 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:14:38,011 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:14:38,011 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:14:38,011 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,011 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:14:38,011 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,012 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:14:38,012 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,012 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:14:38,012 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,012 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:14:38,012 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,012 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:14:38,012 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,013 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:14:38,013 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,013 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:14:38,013 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,013 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:14:38,013 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,013 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:14:38,014 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,014 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:14:38,014 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,014 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:14:38,014 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,014 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:14:38,014 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,014 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:14:38,015 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,015 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:14:38,015 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,015 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:14:38,015 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,015 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:14:38,016 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,016 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:14:38,016 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,016 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:14:38,016 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,016 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:14:38,016 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,017 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:14:38,017 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,017 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:14:38,017 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,017 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:14:38,017 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,017 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:14:38,018 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,018 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:14:38,018 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,018 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:14:38,018 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,018 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:14:38,018 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,018 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:14:38,018 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:14:38,019 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:14:38,019 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:14:38,019 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:14:38,019 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:14:38,019 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:14:38,020 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:14:38,172 [train.py:83] INFO # of samples: 10000
2019-09-11 22:14:38,172 [train.py:84] INFO mini-batch size: 32
2019-09-11 22:14:38,173 [train.py:85] INFO # of iterations per epoch: 312
2019-09-11 22:14:38,209 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:14:38,280 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:17:11,228 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:17:19,800 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:17:22,105 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:17:22,168 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:17:22,168 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:17:22,169 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:17:22,169 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:17:22,169 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:17:22,169 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,169 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:17:22,170 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,170 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:17:22,170 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,170 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:17:22,170 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,170 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:17:22,170 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,171 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:17:22,171 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,171 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:17:22,171 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,171 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:17:22,171 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,171 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:17:22,172 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,172 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:17:22,172 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,172 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:17:22,172 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,172 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:17:22,172 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,172 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:17:22,173 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,173 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:17:22,173 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,173 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:17:22,173 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,173 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:17:22,173 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,174 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:17:22,174 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,174 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:17:22,174 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,174 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:17:22,174 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,174 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:17:22,175 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,175 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:17:22,175 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,175 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:17:22,175 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,175 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:17:22,175 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,175 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:17:22,176 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,176 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:17:22,176 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,176 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:17:22,176 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,176 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:17:22,177 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,177 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:17:22,177 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:17:22,177 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:17:22,177 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:17:22,178 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:17:22,178 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:17:22,178 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:17:22,178 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:17:22,317 [train.py:83] INFO # of samples: 10000
2019-09-11 22:17:22,318 [train.py:84] INFO mini-batch size: 32
2019-09-11 22:17:22,318 [train.py:85] INFO # of iterations per epoch: 312
2019-09-11 22:17:22,352 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:17:22,421 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:19:12,867 [train.py:28] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:19:21,467 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:19:24,618 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:19:24,682 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:19:24,682 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:19:24,682 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:19:24,682 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:19:24,682 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:19:24,682 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,682 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:19:24,682 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,683 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:19:24,683 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,683 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:19:24,683 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,683 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:19:24,683 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,683 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:19:24,684 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,684 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:19:24,684 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,684 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:19:24,684 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,684 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:19:24,684 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,684 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:19:24,685 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,685 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:19:24,685 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,685 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:19:24,685 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,686 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:19:24,686 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,686 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:19:24,686 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,686 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:19:24,686 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,686 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:19:24,686 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,686 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:19:24,687 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,687 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:19:24,687 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,687 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:19:24,687 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,687 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:19:24,688 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,688 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:19:24,688 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,688 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:19:24,688 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,688 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:19:24,688 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,688 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:19:24,689 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,689 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:19:24,689 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,689 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:19:24,689 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,689 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:19:24,689 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,689 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:19:24,690 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:19:24,690 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:19:24,690 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:19:24,690 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:19:24,690 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:19:24,691 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:19:24,691 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:19:24,831 [train.py:83] INFO # of samples: 10000
2019-09-11 22:19:24,831 [train.py:84] INFO mini-batch size: 32
2019-09-11 22:19:24,832 [train.py:85] INFO # of iterations per epoch: 312
2019-09-11 22:19:24,866 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:19:24,936 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:22:55,508 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:23:04,108 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:23:07,220 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:23:07,285 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:23:07,285 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:23:07,285 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:23:07,285 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:23:07,285 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:23:07,285 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,285 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:23:07,286 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,286 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:23:07,286 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,286 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:23:07,287 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,287 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:23:07,287 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,287 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:23:07,287 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,288 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:23:07,288 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,288 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:23:07,288 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,288 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:23:07,288 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,289 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:23:07,289 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,289 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:23:07,289 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,289 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:23:07,289 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,289 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:23:07,290 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,290 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:23:07,290 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,290 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:23:07,290 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,290 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:23:07,291 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,291 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:23:07,291 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,291 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:23:07,291 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,291 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:23:07,291 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,291 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:23:07,292 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,292 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:23:07,292 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,292 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:23:07,292 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,292 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:23:07,292 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,293 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:23:07,293 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,293 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:23:07,293 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,293 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:23:07,293 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,293 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:23:07,294 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,294 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:23:07,294 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:23:07,294 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:23:07,294 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:23:07,295 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:23:07,295 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:23:07,295 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:23:07,295 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:23:07,442 [train.py:84] INFO # of samples: 10000
2019-09-11 22:23:07,442 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:23:07,442 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 22:23:07,477 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:23:07,547 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:23:21,284 [callbacks.py:7] INFO For batch 0, loss is  751.22.
2019-09-11 22:23:24,131 [callbacks.py:7] INFO For batch 1, loss is  368.26.
2019-09-11 22:23:26,629 [callbacks.py:7] INFO For batch 2, loss is  360.77.
2019-09-11 22:23:29,264 [callbacks.py:7] INFO For batch 3, loss is  298.26.
2019-09-11 22:23:31,987 [callbacks.py:7] INFO For batch 4, loss is  263.61.
2019-09-11 22:23:34,825 [callbacks.py:7] INFO For batch 5, loss is  280.43.
2019-09-11 22:23:37,528 [callbacks.py:7] INFO For batch 6, loss is  264.00.
2019-09-11 22:23:38,001 [callbacks.py:7] INFO For batch 7, loss is  287.15.
2019-09-11 22:23:40,994 [callbacks.py:7] INFO For batch 8, loss is  246.62.
2019-09-11 22:23:41,480 [callbacks.py:7] INFO For batch 9, loss is  257.98.
2019-09-11 22:23:44,285 [callbacks.py:7] INFO For batch 10, loss is  282.97.
2019-09-11 22:23:47,332 [callbacks.py:7] INFO For batch 11, loss is  236.80.
2019-09-11 22:23:50,035 [callbacks.py:7] INFO For batch 12, loss is  235.84.
2019-09-11 22:23:52,588 [callbacks.py:7] INFO For batch 13, loss is  244.55.
2019-09-11 22:23:53,004 [callbacks.py:7] INFO For batch 14, loss is  232.80.
2019-09-11 22:23:55,785 [callbacks.py:7] INFO For batch 15, loss is  225.52.
2019-09-11 22:23:58,876 [callbacks.py:7] INFO For batch 16, loss is  228.00.
2019-09-11 22:24:01,704 [callbacks.py:7] INFO For batch 17, loss is  230.90.
2019-09-11 22:24:04,321 [callbacks.py:7] INFO For batch 18, loss is  222.34.
2019-09-11 22:24:04,731 [callbacks.py:7] INFO For batch 19, loss is  229.83.
2019-09-11 22:24:05,115 [callbacks.py:7] INFO For batch 20, loss is  219.33.
2019-09-11 22:24:05,530 [callbacks.py:7] INFO For batch 21, loss is  230.32.
2019-09-11 22:24:08,196 [callbacks.py:7] INFO For batch 22, loss is  215.66.
2019-09-11 22:24:11,071 [callbacks.py:7] INFO For batch 23, loss is  225.60.
2019-09-11 22:24:11,508 [callbacks.py:7] INFO For batch 24, loss is  216.99.
2019-09-11 22:24:14,304 [callbacks.py:7] INFO For batch 25, loss is  226.34.
2019-09-11 22:24:14,786 [callbacks.py:7] INFO For batch 26, loss is  213.89.
2019-09-11 22:24:15,271 [callbacks.py:7] INFO For batch 27, loss is  221.24.
2019-09-11 22:24:18,526 [callbacks.py:7] INFO For batch 28, loss is  227.41.
2019-09-11 22:24:21,694 [callbacks.py:7] INFO For batch 29, loss is  219.37.
2019-09-11 22:24:22,334 [callbacks.py:7] INFO For batch 30, loss is  219.80.
2019-09-11 22:24:22,758 [callbacks.py:7] INFO For batch 31, loss is  240.56.
2019-09-11 22:24:25,271 [callbacks.py:7] INFO For batch 32, loss is  231.89.
2019-09-11 22:24:25,688 [callbacks.py:7] INFO For batch 33, loss is  217.99.
2019-09-11 22:24:26,093 [callbacks.py:7] INFO For batch 34, loss is  225.71.
2019-09-11 22:24:26,488 [callbacks.py:7] INFO For batch 35, loss is  225.26.
2019-09-11 22:30:39,455 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:30:47,937 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:30:50,317 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:30:50,381 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:30:50,381 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:30:50,381 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:30:50,381 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:30:50,381 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:30:50,381 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,381 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:30:50,382 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,382 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:30:50,382 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,382 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:30:50,382 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,382 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:30:50,382 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,383 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:30:50,383 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,383 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:30:50,383 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,383 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:30:50,383 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,383 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:30:50,384 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,384 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:30:50,384 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,384 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:30:50,384 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,384 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:30:50,384 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,384 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:30:50,385 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,385 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:30:50,385 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,385 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:30:50,385 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,385 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:30:50,385 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,386 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:30:50,386 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,386 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:30:50,386 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,386 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:30:50,386 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,386 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:30:50,386 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,387 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:30:50,387 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,387 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:30:50,387 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,387 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:30:50,387 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,387 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:30:50,388 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,388 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:30:50,388 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,388 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:30:50,388 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,388 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:30:50,388 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,388 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:30:50,389 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:30:50,389 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:30:50,389 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:30:50,389 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:30:50,390 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:30:50,390 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:30:50,390 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:30:50,534 [train.py:84] INFO # of samples: 10000
2019-09-11 22:30:50,534 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:30:50,534 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 22:31:02,593 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:31:10,715 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:31:13,014 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:31:13,078 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:31:13,078 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:31:13,078 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:31:13,078 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:31:13,078 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:31:13,078 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,078 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:31:13,078 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,079 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:31:13,079 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,079 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:31:13,079 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,079 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:31:13,079 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,079 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:31:13,080 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,080 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:31:13,080 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,081 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:31:13,081 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,081 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:31:13,081 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,081 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:31:13,081 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,081 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:31:13,081 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,082 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:31:13,082 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,082 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:31:13,082 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,082 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:31:13,082 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,082 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:31:13,083 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,083 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:31:13,083 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,083 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:31:13,083 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,083 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:31:13,083 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,083 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:31:13,084 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,084 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:31:13,084 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,084 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:31:13,084 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,084 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:31:13,084 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,084 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:31:13,085 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,085 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:31:13,085 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,085 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:31:13,085 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,085 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:31:13,085 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,086 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:31:13,086 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,086 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:31:13,086 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:31:13,086 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:31:13,086 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:31:13,087 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:31:13,087 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:31:13,087 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:31:13,087 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:31:13,228 [train.py:84] INFO # of samples: 10000
2019-09-11 22:31:13,228 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:31:13,228 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 22:31:13,263 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:31:13,334 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:32:15,035 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:32:23,359 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:32:26,766 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:32:26,830 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:32:26,830 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:32:26,830 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:32:26,830 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:32:26,831 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:32:26,831 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,831 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:32:26,832 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,832 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:32:26,832 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,832 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:32:26,832 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,832 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:32:26,833 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,833 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:32:26,833 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,833 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:32:26,833 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,833 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:32:26,833 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,834 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:32:26,834 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,834 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:32:26,834 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,834 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:32:26,834 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,834 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:32:26,834 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,835 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:32:26,835 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,835 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:32:26,835 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,835 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:32:26,835 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,835 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:32:26,836 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,836 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:32:26,836 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,836 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:32:26,836 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,836 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:32:26,836 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,837 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:32:26,837 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,837 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:32:26,837 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,837 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:32:26,837 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,837 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:32:26,837 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,838 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:32:26,838 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,838 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:32:26,838 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,838 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:32:26,838 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,838 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:32:26,838 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,839 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:32:26,839 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:32:26,839 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 22:32:26,839 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:32:26,840 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 22:32:26,840 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 22:32:26,840 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:32:26,840 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:32:26,989 [train.py:84] INFO # of samples: 10000
2019-09-11 22:32:26,990 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:32:26,990 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 22:32:27,025 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:32:27,094 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:32:39,408 [callbacks.py:10] INFO For batch 0/312, loss is  654.88.
2019-09-11 22:32:41,888 [callbacks.py:10] INFO For batch 1/312, loss is  266.51.
2019-09-11 22:32:44,551 [callbacks.py:10] INFO For batch 2/312, loss is  452.69.
2019-09-11 22:32:47,514 [callbacks.py:10] INFO For batch 3/312, loss is  324.13.
2019-09-11 22:32:50,073 [callbacks.py:10] INFO For batch 4/312, loss is  243.11.
2019-09-11 22:32:52,714 [callbacks.py:10] INFO For batch 5/312, loss is  248.71.
2019-09-11 22:32:55,450 [callbacks.py:10] INFO For batch 6/312, loss is  240.88.
2019-09-11 22:32:58,217 [callbacks.py:10] INFO For batch 7/312, loss is  236.06.
2019-09-11 22:33:01,071 [callbacks.py:10] INFO For batch 8/312, loss is  233.44.
2019-09-11 22:33:03,619 [callbacks.py:10] INFO For batch 9/312, loss is  220.50.
2019-09-11 22:33:06,259 [callbacks.py:10] INFO For batch 10/312, loss is  236.02.
2019-09-11 22:33:09,067 [callbacks.py:10] INFO For batch 11/312, loss is  222.30.
2019-09-11 22:33:11,771 [callbacks.py:10] INFO For batch 12/312, loss is  217.69.
2019-09-11 22:33:14,956 [callbacks.py:10] INFO For batch 13/312, loss is  216.88.
2019-09-11 22:33:18,082 [callbacks.py:10] INFO For batch 14/312, loss is  216.97.
2019-09-11 22:33:18,515 [callbacks.py:10] INFO For batch 15/312, loss is  214.42.
2019-09-11 22:33:21,025 [callbacks.py:10] INFO For batch 16/312, loss is  224.69.
2019-09-11 22:33:23,758 [callbacks.py:10] INFO For batch 17/312, loss is  226.32.
2019-09-11 22:33:26,894 [callbacks.py:10] INFO For batch 18/312, loss is  236.24.
2019-09-11 22:33:29,689 [callbacks.py:10] INFO For batch 19/312, loss is  264.97.
2019-09-11 22:33:32,580 [callbacks.py:10] INFO For batch 20/312, loss is  245.83.
2019-09-11 22:33:35,382 [callbacks.py:10] INFO For batch 21/312, loss is  212.65.
2019-09-11 22:33:38,230 [callbacks.py:10] INFO For batch 22/312, loss is  239.09.
2019-09-11 22:33:41,154 [callbacks.py:10] INFO For batch 23/312, loss is  239.22.
2019-09-11 22:33:41,622 [callbacks.py:10] INFO For batch 24/312, loss is  226.04.
2019-09-11 22:33:44,146 [callbacks.py:10] INFO For batch 25/312, loss is  229.57.
2019-09-11 22:33:46,778 [callbacks.py:10] INFO For batch 26/312, loss is  227.72.
2019-09-11 22:33:47,236 [callbacks.py:10] INFO For batch 27/312, loss is  205.76.
2019-09-11 22:33:49,818 [callbacks.py:10] INFO For batch 28/312, loss is  213.40.
2019-09-11 22:33:50,239 [callbacks.py:10] INFO For batch 29/312, loss is  218.73.
2019-09-11 22:33:50,685 [callbacks.py:10] INFO For batch 30/312, loss is  226.93.
2019-09-11 22:33:53,698 [callbacks.py:10] INFO For batch 31/312, loss is  223.72.
2019-09-11 22:33:54,113 [callbacks.py:10] INFO For batch 32/312, loss is  213.59.
2019-09-11 22:33:57,197 [callbacks.py:10] INFO For batch 33/312, loss is  218.23.
2019-09-11 22:33:59,935 [callbacks.py:10] INFO For batch 34/312, loss is  211.93.
2019-09-11 22:34:02,646 [callbacks.py:10] INFO For batch 35/312, loss is  219.21.
2019-09-11 22:34:05,301 [callbacks.py:10] INFO For batch 36/312, loss is  218.00.
2019-09-11 22:34:05,775 [callbacks.py:10] INFO For batch 37/312, loss is  220.04.
2019-09-11 22:34:06,238 [callbacks.py:10] INFO For batch 38/312, loss is  216.06.
2019-09-11 22:34:06,706 [callbacks.py:10] INFO For batch 39/312, loss is  219.93.
2019-09-11 22:34:09,389 [callbacks.py:10] INFO For batch 40/312, loss is  211.98.
2019-09-11 22:34:12,590 [callbacks.py:10] INFO For batch 41/312, loss is  216.65.
2019-09-11 22:34:13,028 [callbacks.py:10] INFO For batch 42/312, loss is  213.78.
2019-09-11 22:34:15,529 [callbacks.py:10] INFO For batch 43/312, loss is  210.07.
2019-09-11 22:34:18,506 [callbacks.py:10] INFO For batch 44/312, loss is  215.40.
2019-09-11 22:34:18,985 [callbacks.py:10] INFO For batch 45/312, loss is  211.95.
2019-09-11 22:34:19,450 [callbacks.py:10] INFO For batch 46/312, loss is  212.71.
2019-09-11 22:34:19,868 [callbacks.py:10] INFO For batch 47/312, loss is  216.28.
2019-09-11 22:34:20,280 [callbacks.py:10] INFO For batch 48/312, loss is  215.40.
2019-09-11 22:34:23,041 [callbacks.py:10] INFO For batch 49/312, loss is  212.64.
2019-09-11 22:34:23,447 [callbacks.py:10] INFO For batch 50/312, loss is  211.58.
2019-09-11 22:34:23,872 [callbacks.py:10] INFO For batch 51/312, loss is  209.64.
2019-09-11 22:34:24,300 [callbacks.py:10] INFO For batch 52/312, loss is  214.67.
2019-09-11 22:34:26,999 [callbacks.py:10] INFO For batch 53/312, loss is  219.23.
2019-09-11 22:34:27,475 [callbacks.py:10] INFO For batch 54/312, loss is  212.00.
2019-09-11 22:34:27,901 [callbacks.py:10] INFO For batch 55/312, loss is  211.68.
2019-09-11 22:34:28,359 [callbacks.py:10] INFO For batch 56/312, loss is  207.65.
2019-09-11 22:34:28,835 [callbacks.py:10] INFO For batch 57/312, loss is  209.18.
2019-09-11 22:34:31,507 [callbacks.py:10] INFO For batch 58/312, loss is  200.91.
2019-09-11 22:34:31,950 [callbacks.py:10] INFO For batch 59/312, loss is  214.21.
2019-09-11 22:34:32,377 [callbacks.py:10] INFO For batch 60/312, loss is  209.30.
2019-09-11 22:34:32,788 [callbacks.py:10] INFO For batch 61/312, loss is  211.57.
2019-09-11 22:34:35,844 [callbacks.py:10] INFO For batch 62/312, loss is  218.02.
2019-09-11 22:34:36,261 [callbacks.py:10] INFO For batch 63/312, loss is  209.11.
2019-09-11 22:34:36,663 [callbacks.py:10] INFO For batch 64/312, loss is  209.54.
2019-09-11 22:34:37,097 [callbacks.py:10] INFO For batch 65/312, loss is  215.14.
2019-09-11 22:34:37,561 [callbacks.py:10] INFO For batch 66/312, loss is  210.66.
2019-09-11 22:34:37,978 [callbacks.py:10] INFO For batch 67/312, loss is  210.17.
2019-09-11 22:34:38,398 [callbacks.py:10] INFO For batch 68/312, loss is  212.78.
2019-09-11 22:34:38,899 [callbacks.py:10] INFO For batch 69/312, loss is  217.53.
2019-09-11 22:34:39,391 [callbacks.py:10] INFO For batch 70/312, loss is  209.87.
2019-09-11 22:34:41,982 [callbacks.py:10] INFO For batch 71/312, loss is  200.08.
2019-09-11 22:34:42,387 [callbacks.py:10] INFO For batch 72/312, loss is  215.54.
2019-09-11 22:34:42,881 [callbacks.py:10] INFO For batch 73/312, loss is  216.09.
2019-09-11 22:34:45,607 [callbacks.py:10] INFO For batch 74/312, loss is  203.93.
2019-09-11 22:34:46,002 [callbacks.py:10] INFO For batch 75/312, loss is  208.50.
2019-09-11 22:34:46,439 [callbacks.py:10] INFO For batch 76/312, loss is  209.40.
2019-09-11 22:34:46,917 [callbacks.py:10] INFO For batch 77/312, loss is  215.29.
2019-09-11 22:34:47,367 [callbacks.py:10] INFO For batch 78/312, loss is  215.50.
2019-09-11 22:34:47,744 [callbacks.py:10] INFO For batch 79/312, loss is  202.24.
2019-09-11 22:34:48,169 [callbacks.py:10] INFO For batch 80/312, loss is  217.57.
2019-09-11 22:34:51,143 [callbacks.py:10] INFO For batch 81/312, loss is  214.79.
2019-09-11 22:34:51,536 [callbacks.py:10] INFO For batch 82/312, loss is  209.40.
2019-09-11 22:34:51,929 [callbacks.py:10] INFO For batch 83/312, loss is  205.74.
2019-09-11 22:34:52,402 [callbacks.py:10] INFO For batch 84/312, loss is  210.35.
2019-09-11 22:34:54,887 [callbacks.py:10] INFO For batch 85/312, loss is  204.52.
2019-09-11 22:34:55,345 [callbacks.py:10] INFO For batch 86/312, loss is  209.86.
2019-09-11 22:34:55,770 [callbacks.py:10] INFO For batch 87/312, loss is  209.01.
2019-09-11 22:34:56,228 [callbacks.py:10] INFO For batch 88/312, loss is  211.82.
2019-09-11 22:34:56,655 [callbacks.py:10] INFO For batch 89/312, loss is  208.55.
2019-09-11 22:34:57,052 [callbacks.py:10] INFO For batch 90/312, loss is  207.23.
2019-09-11 22:34:57,474 [callbacks.py:10] INFO For batch 91/312, loss is  208.04.
2019-09-11 22:34:57,971 [callbacks.py:10] INFO For batch 92/312, loss is  210.62.
2019-09-11 22:34:58,392 [callbacks.py:10] INFO For batch 93/312, loss is  215.81.
2019-09-11 22:35:00,961 [callbacks.py:10] INFO For batch 94/312, loss is  203.67.
2019-09-11 22:35:01,416 [callbacks.py:10] INFO For batch 95/312, loss is  208.93.
2019-09-11 22:35:01,842 [callbacks.py:10] INFO For batch 96/312, loss is  209.23.
2019-09-11 22:35:02,252 [callbacks.py:10] INFO For batch 97/312, loss is  200.92.
2019-09-11 22:35:02,676 [callbacks.py:10] INFO For batch 98/312, loss is  209.58.
2019-09-11 22:35:03,089 [callbacks.py:10] INFO For batch 99/312, loss is  204.47.
2019-09-11 22:35:03,508 [callbacks.py:10] INFO For batch 100/312, loss is  205.60.
2019-09-11 22:35:03,962 [callbacks.py:10] INFO For batch 101/312, loss is  196.63.
2019-09-11 22:35:04,452 [callbacks.py:10] INFO For batch 102/312, loss is  203.87.
2019-09-11 22:35:04,844 [callbacks.py:10] INFO For batch 103/312, loss is  206.77.
2019-09-11 22:35:05,314 [callbacks.py:10] INFO For batch 104/312, loss is  208.97.
2019-09-11 22:35:05,719 [callbacks.py:10] INFO For batch 105/312, loss is  210.76.
2019-09-11 22:35:06,175 [callbacks.py:10] INFO For batch 106/312, loss is  206.74.
2019-09-11 22:35:06,561 [callbacks.py:10] INFO For batch 107/312, loss is  208.17.
2019-09-11 22:35:06,938 [callbacks.py:10] INFO For batch 108/312, loss is  210.43.
2019-09-11 22:35:07,317 [callbacks.py:10] INFO For batch 109/312, loss is  203.94.
2019-09-11 22:35:10,300 [callbacks.py:10] INFO For batch 110/312, loss is  215.33.
2019-09-11 22:35:10,733 [callbacks.py:10] INFO For batch 111/312, loss is  201.92.
2019-09-11 22:35:11,131 [callbacks.py:10] INFO For batch 112/312, loss is  206.13.
2019-09-11 22:35:11,622 [callbacks.py:10] INFO For batch 113/312, loss is  211.99.
2019-09-11 22:35:12,080 [callbacks.py:10] INFO For batch 114/312, loss is  212.18.
2019-09-11 22:35:12,488 [callbacks.py:10] INFO For batch 115/312, loss is  210.80.
2019-09-11 22:35:12,876 [callbacks.py:10] INFO For batch 116/312, loss is  210.22.
2019-09-11 22:35:15,839 [callbacks.py:10] INFO For batch 117/312, loss is  215.72.
2019-09-11 22:35:16,350 [callbacks.py:10] INFO For batch 118/312, loss is  207.12.
2019-09-11 22:35:16,778 [callbacks.py:10] INFO For batch 119/312, loss is  206.77.
2019-09-11 22:35:17,248 [callbacks.py:10] INFO For batch 120/312, loss is  212.86.
2019-09-11 22:35:17,627 [callbacks.py:10] INFO For batch 121/312, loss is  210.97.
2019-09-11 22:35:18,171 [callbacks.py:10] INFO For batch 122/312, loss is  202.56.
2019-09-11 22:35:18,549 [callbacks.py:10] INFO For batch 123/312, loss is  203.37.
2019-09-11 22:35:18,969 [callbacks.py:10] INFO For batch 124/312, loss is  203.92.
2019-09-11 22:35:19,466 [callbacks.py:10] INFO For batch 125/312, loss is  207.56.
2019-09-11 22:35:19,855 [callbacks.py:10] INFO For batch 126/312, loss is  210.20.
2019-09-11 22:35:20,329 [callbacks.py:10] INFO For batch 127/312, loss is  202.83.
2019-09-11 22:35:20,748 [callbacks.py:10] INFO For batch 128/312, loss is  207.00.
2019-09-11 22:35:21,195 [callbacks.py:10] INFO For batch 129/312, loss is  207.63.
2019-09-11 22:35:21,648 [callbacks.py:10] INFO For batch 130/312, loss is  207.40.
2019-09-11 22:35:22,187 [callbacks.py:10] INFO For batch 131/312, loss is  200.30.
2019-09-11 22:35:22,572 [callbacks.py:10] INFO For batch 132/312, loss is  204.23.
2019-09-11 22:35:23,002 [callbacks.py:10] INFO For batch 133/312, loss is  196.25.
2019-09-11 22:35:23,375 [callbacks.py:10] INFO For batch 134/312, loss is  192.33.
2019-09-11 22:35:23,804 [callbacks.py:10] INFO For batch 135/312, loss is  206.80.
2019-09-11 22:35:24,286 [callbacks.py:10] INFO For batch 136/312, loss is  209.34.
2019-09-11 22:35:24,711 [callbacks.py:10] INFO For batch 137/312, loss is  202.47.
2019-09-11 22:35:25,158 [callbacks.py:10] INFO For batch 138/312, loss is  207.50.
2019-09-11 22:35:25,648 [callbacks.py:10] INFO For batch 139/312, loss is  197.32.
2019-09-11 22:35:28,718 [callbacks.py:10] INFO For batch 140/312, loss is  209.91.
2019-09-11 22:35:29,092 [callbacks.py:10] INFO For batch 141/312, loss is  204.77.
2019-09-11 22:35:29,492 [callbacks.py:10] INFO For batch 142/312, loss is  217.13.
2019-09-11 22:35:29,948 [callbacks.py:10] INFO For batch 143/312, loss is  214.50.
2019-09-11 22:35:30,363 [callbacks.py:10] INFO For batch 144/312, loss is  204.26.
2019-09-11 22:35:30,806 [callbacks.py:10] INFO For batch 145/312, loss is  209.12.
2019-09-11 22:35:31,215 [callbacks.py:10] INFO For batch 146/312, loss is  208.52.
2019-09-11 22:35:31,694 [callbacks.py:10] INFO For batch 147/312, loss is  207.33.
2019-09-11 22:35:32,129 [callbacks.py:10] INFO For batch 148/312, loss is  196.60.
2019-09-11 22:35:32,551 [callbacks.py:10] INFO For batch 149/312, loss is  199.78.
2019-09-11 22:35:33,050 [callbacks.py:10] INFO For batch 150/312, loss is  209.36.
2019-09-11 22:35:33,470 [callbacks.py:10] INFO For batch 151/312, loss is  209.73.
2019-09-11 22:35:33,883 [callbacks.py:10] INFO For batch 152/312, loss is  202.76.
2019-09-11 22:35:34,279 [callbacks.py:10] INFO For batch 153/312, loss is  205.21.
2019-09-11 22:35:34,788 [callbacks.py:10] INFO For batch 154/312, loss is  205.69.
2019-09-11 22:35:35,206 [callbacks.py:10] INFO For batch 155/312, loss is  204.05.
2019-09-11 22:35:35,619 [callbacks.py:10] INFO For batch 156/312, loss is  202.00.
2019-09-11 22:35:35,988 [callbacks.py:10] INFO For batch 157/312, loss is  211.23.
2019-09-11 22:35:36,578 [callbacks.py:10] INFO For batch 158/312, loss is  208.91.
2019-09-11 22:35:36,999 [callbacks.py:10] INFO For batch 159/312, loss is  204.35.
2019-09-11 22:35:37,504 [callbacks.py:10] INFO For batch 160/312, loss is  214.05.
2019-09-11 22:35:37,931 [callbacks.py:10] INFO For batch 161/312, loss is  203.55.
2019-09-11 22:35:38,345 [callbacks.py:10] INFO For batch 162/312, loss is  211.64.
2019-09-11 22:35:38,869 [callbacks.py:10] INFO For batch 163/312, loss is  205.34.
2019-09-11 22:35:39,258 [callbacks.py:10] INFO For batch 164/312, loss is  204.19.
2019-09-11 22:35:39,681 [callbacks.py:10] INFO For batch 165/312, loss is  209.37.
2019-09-11 22:35:40,144 [callbacks.py:10] INFO For batch 166/312, loss is  212.81.
2019-09-11 22:35:40,668 [callbacks.py:10] INFO For batch 167/312, loss is  212.04.
2019-09-11 22:35:41,100 [callbacks.py:10] INFO For batch 168/312, loss is  199.49.
2019-09-11 22:35:41,523 [callbacks.py:10] INFO For batch 169/312, loss is  202.29.
2019-09-11 22:35:41,881 [callbacks.py:10] INFO For batch 170/312, loss is  208.19.
2019-09-11 22:35:44,530 [callbacks.py:10] INFO For batch 171/312, loss is  201.37.
2019-09-11 22:35:45,003 [callbacks.py:10] INFO For batch 172/312, loss is  212.18.
2019-09-11 22:35:45,405 [callbacks.py:10] INFO For batch 173/312, loss is  206.47.
2019-09-11 22:35:45,807 [callbacks.py:10] INFO For batch 174/312, loss is  203.18.
2019-09-11 22:35:46,202 [callbacks.py:10] INFO For batch 175/312, loss is  205.93.
2019-09-11 22:35:46,684 [callbacks.py:10] INFO For batch 176/312, loss is  208.28.
2019-09-11 22:35:47,100 [callbacks.py:10] INFO For batch 177/312, loss is  207.89.
2019-09-11 22:35:47,620 [callbacks.py:10] INFO For batch 178/312, loss is  210.28.
2019-09-11 22:35:48,120 [callbacks.py:10] INFO For batch 179/312, loss is  205.54.
2019-09-11 22:35:48,523 [callbacks.py:10] INFO For batch 180/312, loss is  204.24.
2019-09-11 22:35:48,942 [callbacks.py:10] INFO For batch 181/312, loss is  213.97.
2019-09-11 22:35:49,384 [callbacks.py:10] INFO For batch 182/312, loss is  205.00.
2019-09-11 22:35:49,852 [callbacks.py:10] INFO For batch 183/312, loss is  203.24.
2019-09-11 22:35:50,239 [callbacks.py:10] INFO For batch 184/312, loss is  209.22.
2019-09-11 22:35:50,645 [callbacks.py:10] INFO For batch 185/312, loss is  208.18.
2019-09-11 22:35:54,044 [callbacks.py:10] INFO For batch 186/312, loss is  214.97.
2019-09-11 22:35:54,514 [callbacks.py:10] INFO For batch 187/312, loss is  203.08.
2019-09-11 22:35:54,883 [callbacks.py:10] INFO For batch 188/312, loss is  205.01.
2019-09-11 22:35:55,284 [callbacks.py:10] INFO For batch 189/312, loss is  203.40.
2019-09-11 22:35:55,751 [callbacks.py:10] INFO For batch 190/312, loss is  203.24.
2019-09-11 22:35:56,127 [callbacks.py:10] INFO For batch 191/312, loss is  208.90.
2019-09-11 22:35:56,530 [callbacks.py:10] INFO For batch 192/312, loss is  201.99.
2019-09-11 22:35:56,912 [callbacks.py:10] INFO For batch 193/312, loss is  203.32.
2019-09-11 22:35:57,366 [callbacks.py:10] INFO For batch 194/312, loss is  203.86.
2019-09-11 22:35:57,928 [callbacks.py:10] INFO For batch 195/312, loss is  209.05.
2019-09-11 22:35:58,318 [callbacks.py:10] INFO For batch 196/312, loss is  215.31.
2019-09-11 22:35:58,823 [callbacks.py:10] INFO For batch 197/312, loss is  216.45.
2019-09-11 22:35:59,301 [callbacks.py:10] INFO For batch 198/312, loss is  212.08.
2019-09-11 22:35:59,827 [callbacks.py:10] INFO For batch 199/312, loss is  200.92.
2019-09-11 22:36:00,247 [callbacks.py:10] INFO For batch 200/312, loss is  199.84.
2019-09-11 22:36:00,730 [callbacks.py:10] INFO For batch 201/312, loss is  212.51.
2019-09-11 22:36:01,158 [callbacks.py:10] INFO For batch 202/312, loss is  201.74.
2019-09-11 22:36:01,560 [callbacks.py:10] INFO For batch 203/312, loss is  208.99.
2019-09-11 22:36:02,014 [callbacks.py:10] INFO For batch 204/312, loss is  208.42.
2019-09-11 22:36:02,388 [callbacks.py:10] INFO For batch 205/312, loss is  205.48.
2019-09-11 22:36:02,784 [callbacks.py:10] INFO For batch 206/312, loss is  198.46.
2019-09-11 22:36:03,193 [callbacks.py:10] INFO For batch 207/312, loss is  206.72.
2019-09-11 22:36:03,653 [callbacks.py:10] INFO For batch 208/312, loss is  210.23.
2019-09-11 22:36:04,168 [callbacks.py:10] INFO For batch 209/312, loss is  211.29.
2019-09-11 22:36:04,639 [callbacks.py:10] INFO For batch 210/312, loss is  208.33.
2019-09-11 22:36:05,033 [callbacks.py:10] INFO For batch 211/312, loss is  199.48.
2019-09-11 22:36:05,582 [callbacks.py:10] INFO For batch 212/312, loss is  214.64.
2019-09-11 22:36:05,968 [callbacks.py:10] INFO For batch 213/312, loss is  200.18.
2019-09-11 22:36:06,336 [callbacks.py:10] INFO For batch 214/312, loss is  205.27.
2019-09-11 22:36:06,940 [callbacks.py:10] INFO For batch 215/312, loss is  213.95.
2019-09-11 22:36:09,603 [callbacks.py:10] INFO For batch 216/312, loss is  198.61.
2019-09-11 22:36:10,087 [callbacks.py:10] INFO For batch 217/312, loss is  212.58.
2019-09-11 22:36:10,502 [callbacks.py:10] INFO For batch 218/312, loss is  210.71.
2019-09-11 22:36:10,874 [callbacks.py:10] INFO For batch 219/312, loss is  209.39.
2019-09-11 22:36:11,450 [callbacks.py:10] INFO For batch 220/312, loss is  208.56.
2019-09-11 22:36:11,830 [callbacks.py:10] INFO For batch 221/312, loss is  200.37.
2019-09-11 22:36:12,234 [callbacks.py:10] INFO For batch 222/312, loss is  210.06.
2019-09-11 22:36:12,623 [callbacks.py:10] INFO For batch 223/312, loss is  202.12.
2019-09-11 22:36:13,120 [callbacks.py:10] INFO For batch 224/312, loss is  211.25.
2019-09-11 22:36:13,595 [callbacks.py:10] INFO For batch 225/312, loss is  205.53.
2019-09-11 22:36:14,016 [callbacks.py:10] INFO For batch 226/312, loss is  203.31.
2019-09-11 22:36:14,404 [callbacks.py:10] INFO For batch 227/312, loss is  205.41.
2019-09-11 22:36:14,862 [callbacks.py:10] INFO For batch 228/312, loss is  213.19.
2019-09-11 22:36:15,339 [callbacks.py:10] INFO For batch 229/312, loss is  200.11.
2019-09-11 22:36:15,726 [callbacks.py:10] INFO For batch 230/312, loss is  212.24.
2019-09-11 22:36:16,190 [callbacks.py:10] INFO For batch 231/312, loss is  208.63.
2019-09-11 22:36:16,703 [callbacks.py:10] INFO For batch 232/312, loss is  209.13.
2019-09-11 22:36:17,111 [callbacks.py:10] INFO For batch 233/312, loss is  208.35.
2019-09-11 22:36:17,611 [callbacks.py:10] INFO For batch 234/312, loss is  206.78.
2019-09-11 22:36:18,064 [callbacks.py:10] INFO For batch 235/312, loss is  211.46.
2019-09-11 22:36:18,450 [callbacks.py:10] INFO For batch 236/312, loss is  195.27.
2019-09-11 22:36:18,835 [callbacks.py:10] INFO For batch 237/312, loss is  203.30.
2019-09-11 22:36:19,192 [callbacks.py:10] INFO For batch 238/312, loss is  205.55.
2019-09-11 22:36:19,680 [callbacks.py:10] INFO For batch 239/312, loss is  199.09.
2019-09-11 22:36:20,086 [callbacks.py:10] INFO For batch 240/312, loss is  204.10.
2019-09-11 22:36:20,496 [callbacks.py:10] INFO For batch 241/312, loss is  209.26.
2019-09-11 22:36:21,040 [callbacks.py:10] INFO For batch 242/312, loss is  203.05.
2019-09-11 22:36:24,301 [callbacks.py:10] INFO For batch 243/312, loss is  206.77.
2019-09-11 22:36:24,822 [callbacks.py:10] INFO For batch 244/312, loss is  210.90.
2019-09-11 22:36:25,253 [callbacks.py:10] INFO For batch 245/312, loss is  211.07.
2019-09-11 22:36:28,043 [callbacks.py:10] INFO For batch 246/312, loss is  199.88.
2019-09-11 22:36:28,517 [callbacks.py:10] INFO For batch 247/312, loss is  206.57.
2019-09-11 22:36:28,906 [callbacks.py:10] INFO For batch 248/312, loss is  209.10.
2019-09-11 22:36:29,273 [callbacks.py:10] INFO For batch 249/312, loss is  202.61.
2019-09-11 22:36:29,669 [callbacks.py:10] INFO For batch 250/312, loss is  207.03.
2019-09-11 22:36:30,172 [callbacks.py:10] INFO For batch 251/312, loss is  205.24.
2019-09-11 22:36:30,642 [callbacks.py:10] INFO For batch 252/312, loss is  201.66.
2019-09-11 22:36:31,074 [callbacks.py:10] INFO For batch 253/312, loss is  204.08.
2019-09-11 22:36:31,503 [callbacks.py:10] INFO For batch 254/312, loss is  192.07.
2019-09-11 22:36:31,897 [callbacks.py:10] INFO For batch 255/312, loss is  204.28.
2019-09-11 22:36:32,407 [callbacks.py:10] INFO For batch 256/312, loss is  210.66.
2019-09-11 22:36:32,835 [callbacks.py:10] INFO For batch 257/312, loss is  206.22.
2019-09-11 22:36:33,223 [callbacks.py:10] INFO For batch 258/312, loss is  205.39.
2019-09-11 22:36:33,692 [callbacks.py:10] INFO For batch 259/312, loss is  209.90.
2019-09-11 22:36:34,146 [callbacks.py:10] INFO For batch 260/312, loss is  201.88.
2019-09-11 22:36:34,520 [callbacks.py:10] INFO For batch 261/312, loss is  212.07.
2019-09-11 22:36:34,986 [callbacks.py:10] INFO For batch 262/312, loss is  208.61.
2019-09-11 22:36:35,403 [callbacks.py:10] INFO For batch 263/312, loss is  201.77.
2019-09-11 22:36:35,875 [callbacks.py:10] INFO For batch 264/312, loss is  200.30.
2019-09-11 22:36:36,381 [callbacks.py:10] INFO For batch 265/312, loss is  205.37.
2019-09-11 22:36:36,804 [callbacks.py:10] INFO For batch 266/312, loss is  212.17.
2019-09-11 22:36:37,285 [callbacks.py:10] INFO For batch 267/312, loss is  210.09.
2019-09-11 22:36:37,691 [callbacks.py:10] INFO For batch 268/312, loss is  192.23.
2019-09-11 22:36:38,094 [callbacks.py:10] INFO For batch 269/312, loss is  205.89.
2019-09-11 22:36:38,601 [callbacks.py:10] INFO For batch 270/312, loss is  206.50.
2019-09-11 22:36:39,068 [callbacks.py:10] INFO For batch 271/312, loss is  206.52.
2019-09-11 22:36:39,486 [callbacks.py:10] INFO For batch 272/312, loss is  201.21.
2019-09-11 22:36:39,943 [callbacks.py:10] INFO For batch 273/312, loss is  205.80.
2019-09-11 22:36:40,403 [callbacks.py:10] INFO For batch 274/312, loss is  196.84.
2019-09-11 22:36:40,820 [callbacks.py:10] INFO For batch 275/312, loss is  201.45.
2019-09-11 22:36:41,288 [callbacks.py:10] INFO For batch 276/312, loss is  202.56.
2019-09-11 22:36:41,704 [callbacks.py:10] INFO For batch 277/312, loss is  210.86.
2019-09-11 22:36:42,148 [callbacks.py:10] INFO For batch 278/312, loss is  206.71.
2019-09-11 22:36:42,611 [callbacks.py:10] INFO For batch 279/312, loss is  196.95.
2019-09-11 22:36:43,141 [callbacks.py:10] INFO For batch 280/312, loss is  210.81.
2019-09-11 22:36:43,537 [callbacks.py:10] INFO For batch 281/312, loss is  200.73.
2019-09-11 22:36:43,946 [callbacks.py:10] INFO For batch 282/312, loss is  201.99.
2019-09-11 22:36:44,494 [callbacks.py:10] INFO For batch 283/312, loss is  194.63.
2019-09-11 22:36:44,916 [callbacks.py:10] INFO For batch 284/312, loss is  207.98.
2019-09-11 22:36:45,371 [callbacks.py:10] INFO For batch 285/312, loss is  211.20.
2019-09-11 22:36:45,767 [callbacks.py:10] INFO For batch 286/312, loss is  196.41.
2019-09-11 22:36:46,235 [callbacks.py:10] INFO For batch 287/312, loss is  198.57.
2019-09-11 22:36:46,701 [callbacks.py:10] INFO For batch 288/312, loss is  197.12.
2019-09-11 22:36:47,098 [callbacks.py:10] INFO For batch 289/312, loss is  194.44.
2019-09-11 22:36:47,602 [callbacks.py:10] INFO For batch 290/312, loss is  198.18.
2019-09-11 22:36:48,008 [callbacks.py:10] INFO For batch 291/312, loss is  197.42.
2019-09-11 22:36:48,411 [callbacks.py:10] INFO For batch 292/312, loss is  207.59.
2019-09-11 22:36:51,169 [callbacks.py:10] INFO For batch 293/312, loss is  201.72.
2019-09-11 22:36:51,541 [callbacks.py:10] INFO For batch 294/312, loss is  206.07.
2019-09-11 22:36:51,960 [callbacks.py:10] INFO For batch 295/312, loss is  210.55.
2019-09-11 22:36:52,344 [callbacks.py:10] INFO For batch 296/312, loss is  199.62.
2019-09-11 22:36:52,755 [callbacks.py:10] INFO For batch 297/312, loss is  208.54.
2019-09-11 22:36:53,324 [callbacks.py:10] INFO For batch 298/312, loss is  207.24.
2019-09-11 22:36:53,741 [callbacks.py:10] INFO For batch 299/312, loss is  203.35.
2019-09-11 22:36:54,183 [callbacks.py:10] INFO For batch 300/312, loss is  201.05.
2019-09-11 22:36:54,671 [callbacks.py:10] INFO For batch 301/312, loss is  203.78.
2019-09-11 22:36:55,072 [callbacks.py:10] INFO For batch 302/312, loss is  209.62.
2019-09-11 22:36:55,539 [callbacks.py:10] INFO For batch 303/312, loss is  199.99.
2019-09-11 22:36:55,966 [callbacks.py:10] INFO For batch 304/312, loss is  203.25.
2019-09-11 22:36:56,437 [callbacks.py:10] INFO For batch 305/312, loss is  198.68.
2019-09-11 22:36:56,866 [callbacks.py:10] INFO For batch 306/312, loss is  201.69.
2019-09-11 22:36:57,274 [callbacks.py:10] INFO For batch 307/312, loss is  196.90.
2019-09-11 22:36:57,806 [callbacks.py:10] INFO For batch 308/312, loss is  205.38.
2019-09-11 22:36:58,221 [callbacks.py:10] INFO For batch 309/312, loss is  209.03.
2019-09-11 22:36:58,717 [callbacks.py:10] INFO For batch 310/312, loss is  212.41.
2019-09-11 22:36:59,192 [callbacks.py:10] INFO For batch 311/312, loss is  203.24.
2019-09-11 22:36:59,711 [callbacks.py:13] INFO For batch 0, loss is  214.43.
2019-09-11 22:36:59,943 [callbacks.py:13] INFO For batch 1, loss is  214.43.
2019-09-11 22:37:00,270 [callbacks.py:13] INFO For batch 2, loss is  214.43.
2019-09-11 22:37:00,495 [callbacks.py:13] INFO For batch 3, loss is  214.43.
2019-09-11 22:37:00,736 [callbacks.py:13] INFO For batch 4, loss is  214.43.
2019-09-11 22:37:00,936 [callbacks.py:13] INFO For batch 5, loss is  214.43.
2019-09-11 22:37:01,171 [callbacks.py:13] INFO For batch 6, loss is  214.43.
2019-09-11 22:37:01,404 [callbacks.py:13] INFO For batch 7, loss is  214.43.
2019-09-11 22:37:01,659 [callbacks.py:13] INFO For batch 8, loss is  231.78.
2019-09-11 22:37:01,883 [callbacks.py:13] INFO For batch 9, loss is  231.78.
2019-09-11 22:37:02,092 [callbacks.py:13] INFO For batch 10, loss is  231.78.
2019-09-11 22:37:02,287 [callbacks.py:13] INFO For batch 11, loss is  231.78.
2019-09-11 22:37:02,502 [callbacks.py:13] INFO For batch 12, loss is  231.78.
2019-09-11 22:37:02,686 [callbacks.py:13] INFO For batch 13, loss is  231.78.
2019-09-11 22:37:02,895 [callbacks.py:13] INFO For batch 14, loss is  231.78.
2019-09-11 22:37:03,102 [callbacks.py:13] INFO For batch 15, loss is  231.78.
2019-09-11 22:37:03,270 [callbacks.py:13] INFO For batch 16, loss is  234.48.
2019-09-11 22:37:03,550 [callbacks.py:13] INFO For batch 17, loss is  234.48.
2019-09-11 22:37:03,743 [callbacks.py:13] INFO For batch 18, loss is  234.48.
2019-09-11 22:37:04,017 [callbacks.py:13] INFO For batch 19, loss is  234.48.
2019-09-11 22:37:04,211 [callbacks.py:13] INFO For batch 20, loss is  234.48.
2019-09-11 22:37:04,407 [callbacks.py:13] INFO For batch 21, loss is  234.48.
2019-09-11 22:37:04,632 [callbacks.py:13] INFO For batch 22, loss is  234.48.
2019-09-11 22:37:04,849 [callbacks.py:13] INFO For batch 23, loss is  234.48.
2019-09-11 22:37:05,045 [callbacks.py:13] INFO For batch 24, loss is  218.86.
2019-09-11 22:37:05,250 [callbacks.py:13] INFO For batch 25, loss is  218.86.
2019-09-11 22:37:05,485 [callbacks.py:13] INFO For batch 26, loss is  218.86.
2019-09-11 22:37:07,384 [callbacks.py:16] INFO The average loss for epoch 0 is  211.92.
2019-09-11 22:39:03,090 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:39:05,036 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:39:08,138 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:39:08,202 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:39:08,203 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:39:08,203 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:39:08,203 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:39:08,203 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:39:08,203 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,203 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:39:08,203 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,204 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:39:08,204 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,204 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:39:08,204 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,204 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:39:08,205 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,205 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:39:08,205 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,205 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:39:08,205 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,205 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:39:08,205 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,205 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:39:08,206 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,206 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:39:08,206 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,206 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:39:08,206 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,206 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:39:08,206 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,207 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:39:08,207 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,207 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:39:08,207 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,207 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:39:08,207 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,208 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:39:08,208 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,208 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:39:08,208 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,208 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:39:08,208 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,209 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:39:08,209 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,209 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:39:08,209 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,209 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:39:08,209 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,209 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:39:08,209 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,210 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:39:08,210 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,210 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:39:08,211 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,211 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:39:08,211 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,211 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:39:08,211 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,211 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:39:08,211 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,211 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:39:08,212 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:39:08,212 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 781)         200717    
2019-09-11 22:39:08,212 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:39:08,212 [layer_utils.py:182] INFO Total params: 1,900,781
2019-09-11 22:39:08,212 [layer_utils.py:183] INFO Trainable params: 1,898,861
2019-09-11 22:39:08,213 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:39:08,213 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:39:08,356 [train.py:84] INFO # of samples: 128
2019-09-11 22:39:08,356 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:39:08,356 [train.py:86] INFO # of iterations per epoch: 4
2019-09-11 22:39:08,391 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:39:08,462 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:39:20,699 [callbacks.py:10] INFO For batch 0/4, loss is  643.90.
2019-09-11 22:39:23,436 [callbacks.py:10] INFO For batch 1/4, loss is  266.67.
2019-09-11 22:39:26,091 [callbacks.py:10] INFO For batch 2/4, loss is  411.94.
2019-09-11 22:39:26,546 [callbacks.py:10] INFO For batch 3/4, loss is  310.36.
2019-09-11 22:39:27,725 [callbacks.py:13] INFO For batch 0, validation loss is  268.69.
2019-09-11 22:39:28,107 [callbacks.py:13] INFO For batch 1, validation loss is  268.69.
2019-09-11 22:39:28,396 [callbacks.py:13] INFO For batch 2, validation loss is  268.69.
2019-09-11 22:39:28,684 [callbacks.py:13] INFO For batch 3, validation loss is  268.69.
2019-09-11 22:39:29,013 [callbacks.py:13] INFO For batch 4, validation loss is  268.69.
2019-09-11 22:39:29,416 [callbacks.py:13] INFO For batch 5, validation loss is  268.69.
2019-09-11 22:39:29,777 [callbacks.py:13] INFO For batch 6, validation loss is  268.69.
2019-09-11 22:39:30,159 [callbacks.py:13] INFO For batch 7, validation loss is  268.69.
2019-09-11 22:39:31,214 [callbacks.py:13] INFO For batch 8, validation loss is  260.35.
2019-09-11 22:39:31,640 [callbacks.py:13] INFO For batch 9, validation loss is  260.35.
2019-09-11 22:39:31,880 [callbacks.py:13] INFO For batch 10, validation loss is  260.35.
2019-09-11 22:39:32,181 [callbacks.py:13] INFO For batch 11, validation loss is  260.35.
2019-09-11 22:39:32,484 [callbacks.py:13] INFO For batch 12, validation loss is  260.35.
2019-09-11 22:39:32,708 [callbacks.py:13] INFO For batch 13, validation loss is  260.35.
2019-09-11 22:39:33,054 [callbacks.py:13] INFO For batch 14, validation loss is  260.35.
2019-09-11 22:39:33,399 [callbacks.py:13] INFO For batch 15, validation loss is  260.35.
2019-09-11 22:39:34,294 [callbacks.py:13] INFO For batch 16, validation loss is  266.43.
2019-09-11 22:39:34,449 [callbacks.py:13] INFO For batch 17, validation loss is  266.43.
2019-09-11 22:39:34,748 [callbacks.py:13] INFO For batch 18, validation loss is  266.43.
2019-09-11 22:39:34,969 [callbacks.py:13] INFO For batch 19, validation loss is  266.43.
2019-09-11 22:39:35,185 [callbacks.py:13] INFO For batch 20, validation loss is  266.43.
2019-09-11 22:39:35,465 [callbacks.py:13] INFO For batch 21, validation loss is  266.43.
2019-09-11 22:39:35,716 [callbacks.py:13] INFO For batch 22, validation loss is  266.43.
2019-09-11 22:39:35,893 [callbacks.py:13] INFO For batch 23, validation loss is  266.43.
2019-09-11 22:39:36,172 [callbacks.py:13] INFO For batch 24, validation loss is  247.73.
2019-09-11 22:39:36,442 [callbacks.py:13] INFO For batch 25, validation loss is  247.73.
2019-09-11 22:39:36,595 [callbacks.py:13] INFO For batch 26, validation loss is  247.73.
2019-09-11 22:41:01,908 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:41:03,945 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:41:06,991 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:41:07,055 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:41:07,055 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:41:07,055 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:41:07,056 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:41:07,056 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:41:07,056 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,056 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:41:07,057 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,057 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:41:07,057 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,057 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:41:07,057 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,058 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:41:07,058 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,058 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:41:07,058 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,058 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:41:07,058 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,058 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:41:07,058 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,058 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:41:07,059 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,059 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:41:07,059 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,059 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:41:07,059 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,059 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:41:07,059 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,060 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:41:07,060 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,060 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:41:07,060 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,060 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:41:07,060 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,060 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:41:07,061 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,061 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:41:07,061 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,061 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:41:07,061 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,061 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:41:07,061 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,061 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:41:07,062 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,062 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:41:07,062 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,062 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:41:07,062 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,062 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:41:07,062 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,062 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:41:07,063 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,063 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:41:07,063 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,063 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:41:07,063 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,063 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:41:07,063 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,063 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:41:07,064 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:41:07,064 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 781)         200717    
2019-09-11 22:41:07,064 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:41:07,065 [layer_utils.py:182] INFO Total params: 1,900,781
2019-09-11 22:41:07,065 [layer_utils.py:183] INFO Trainable params: 1,898,861
2019-09-11 22:41:07,065 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:41:07,065 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:41:07,205 [train.py:84] INFO # of samples: 128
2019-09-11 22:41:07,206 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:41:07,206 [train.py:86] INFO # of iterations per epoch: 4
2019-09-11 22:41:07,240 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:41:07,311 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:41:18,837 [callbacks.py:12] INFO For batch 0/4, loss is  650.61.
2019-09-11 22:41:21,481 [callbacks.py:12] INFO For batch 1/4, loss is  309.98.
2019-09-11 22:41:23,987 [callbacks.py:12] INFO For batch 2/4, loss is  414.05.
2019-09-11 22:41:26,681 [callbacks.py:12] INFO For batch 3/4, loss is  347.45.
2019-09-11 22:41:27,849 [callbacks.py:15] INFO For batch 0, validation loss is  306.66.
2019-09-11 22:41:28,097 [callbacks.py:15] INFO For batch 1, validation loss is  306.66.
2019-09-11 22:41:28,337 [callbacks.py:15] INFO For batch 2, validation loss is  306.66.
2019-09-11 22:41:28,575 [callbacks.py:15] INFO For batch 3, validation loss is  306.66.
2019-09-11 22:41:28,878 [callbacks.py:15] INFO For batch 4, validation loss is  306.66.
2019-09-11 22:41:29,202 [callbacks.py:15] INFO For batch 5, validation loss is  306.66.
2019-09-11 22:41:29,523 [callbacks.py:15] INFO For batch 6, validation loss is  306.66.
2019-09-11 22:41:29,765 [callbacks.py:15] INFO For batch 7, validation loss is  306.66.
2019-09-11 22:41:30,719 [callbacks.py:15] INFO For batch 8, validation loss is  265.01.
2019-09-11 22:41:30,981 [callbacks.py:15] INFO For batch 9, validation loss is  265.01.
2019-09-11 22:41:31,219 [callbacks.py:15] INFO For batch 10, validation loss is  265.01.
2019-09-11 22:41:31,434 [callbacks.py:15] INFO For batch 11, validation loss is  265.01.
2019-09-11 22:41:31,641 [callbacks.py:15] INFO For batch 12, validation loss is  265.01.
2019-09-11 22:41:31,943 [callbacks.py:15] INFO For batch 13, validation loss is  265.01.
2019-09-11 22:41:32,160 [callbacks.py:15] INFO For batch 14, validation loss is  265.01.
2019-09-11 22:41:32,440 [callbacks.py:15] INFO For batch 15, validation loss is  265.01.
2019-09-11 22:41:33,367 [callbacks.py:15] INFO For batch 16, validation loss is  270.69.
2019-09-11 22:41:33,544 [callbacks.py:15] INFO For batch 17, validation loss is  270.69.
2019-09-11 22:41:33,757 [callbacks.py:15] INFO For batch 18, validation loss is  270.69.
2019-09-11 22:41:33,932 [callbacks.py:15] INFO For batch 19, validation loss is  270.69.
2019-09-11 22:41:34,106 [callbacks.py:15] INFO For batch 20, validation loss is  270.69.
2019-09-11 22:41:34,275 [callbacks.py:15] INFO For batch 21, validation loss is  270.69.
2019-09-11 22:41:34,430 [callbacks.py:15] INFO For batch 22, validation loss is  270.69.
2019-09-11 22:41:34,597 [callbacks.py:15] INFO For batch 23, validation loss is  270.69.
2019-09-11 22:41:34,792 [callbacks.py:15] INFO For batch 24, validation loss is  263.24.
2019-09-11 22:41:34,946 [callbacks.py:15] INFO For batch 25, validation loss is  263.24.
2019-09-11 22:41:35,187 [callbacks.py:15] INFO For batch 26, validation loss is  263.24.
2019-09-11 22:41:35,194 [callbacks.py:19] INFO The validation average loss is  278.84.
2019-09-11 22:41:37,146 [callbacks.py:23] INFO The average loss for epoch 0 is  430.52.
2019-09-11 22:42:32,148 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:42:33,890 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:42:36,972 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:42:37,035 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:42:37,036 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:42:37,036 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:42:37,036 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:42:37,036 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:42:37,036 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,036 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:42:37,036 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,037 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:42:37,037 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,037 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:42:37,037 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,038 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:42:37,038 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,038 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:42:37,038 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,038 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:42:37,038 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,038 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:42:37,039 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,039 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:42:37,039 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,039 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:42:37,039 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,039 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:42:37,039 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,040 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:42:37,040 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,040 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:42:37,040 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,040 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:42:37,040 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,040 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:42:37,041 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,041 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:42:37,041 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,041 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:42:37,041 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,041 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:42:37,041 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,041 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:42:37,042 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,042 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:42:37,042 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,042 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:42:37,042 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,042 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:42:37,042 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,042 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:42:37,043 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,043 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:42:37,043 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,043 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:42:37,043 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,043 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:42:37,044 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,044 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:42:37,044 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,044 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:42:37,044 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:42:37,044 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 781)         200717    
2019-09-11 22:42:37,044 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:42:37,045 [layer_utils.py:182] INFO Total params: 1,900,781
2019-09-11 22:42:37,045 [layer_utils.py:183] INFO Trainable params: 1,898,861
2019-09-11 22:42:37,045 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:42:37,045 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:42:37,184 [train.py:84] INFO # of samples: 128
2019-09-11 22:42:37,185 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:42:37,185 [train.py:86] INFO # of iterations per epoch: 4
2019-09-11 22:42:37,219 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:42:37,288 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:42:49,074 [callbacks.py:12] INFO For batch 0/4, loss is  670.88.
2019-09-11 22:42:51,546 [callbacks.py:12] INFO For batch 1/4, loss is  530.81.
2019-09-11 22:42:54,204 [callbacks.py:12] INFO For batch 2/4, loss is  511.46.
2019-09-11 22:42:56,746 [callbacks.py:12] INFO For batch 3/4, loss is  245.92.
2019-09-11 22:42:57,896 [callbacks.py:15] INFO For batch 0, validation loss is  355.58.
2019-09-11 22:42:58,275 [callbacks.py:15] INFO For batch 1, validation loss is  355.58.
2019-09-11 22:42:58,574 [callbacks.py:15] INFO For batch 2, validation loss is  355.58.
2019-09-11 22:42:58,861 [callbacks.py:15] INFO For batch 3, validation loss is  355.58.
2019-09-11 22:42:59,277 [callbacks.py:15] INFO For batch 4, validation loss is  355.58.
2019-09-11 22:42:59,640 [callbacks.py:15] INFO For batch 5, validation loss is  355.58.
2019-09-11 22:42:59,984 [callbacks.py:15] INFO For batch 6, validation loss is  355.58.
2019-09-11 22:43:00,304 [callbacks.py:15] INFO For batch 7, validation loss is  355.58.
2019-09-11 22:43:01,378 [callbacks.py:15] INFO For batch 8, validation loss is  318.94.
2019-09-11 22:43:01,743 [callbacks.py:15] INFO For batch 9, validation loss is  318.94.
2019-09-11 22:43:02,030 [callbacks.py:15] INFO For batch 10, validation loss is  318.94.
2019-09-11 22:43:02,246 [callbacks.py:15] INFO For batch 11, validation loss is  318.94.
2019-09-11 22:43:02,586 [callbacks.py:15] INFO For batch 12, validation loss is  318.94.
2019-09-11 22:43:02,898 [callbacks.py:15] INFO For batch 13, validation loss is  318.94.
2019-09-11 22:43:03,163 [callbacks.py:15] INFO For batch 14, validation loss is  318.94.
2019-09-11 22:43:03,519 [callbacks.py:15] INFO For batch 15, validation loss is  318.94.
2019-09-11 22:43:04,405 [callbacks.py:15] INFO For batch 16, validation loss is  350.49.
2019-09-11 22:43:04,561 [callbacks.py:15] INFO For batch 17, validation loss is  350.49.
2019-09-11 22:43:04,770 [callbacks.py:15] INFO For batch 18, validation loss is  350.49.
2019-09-11 22:43:04,923 [callbacks.py:15] INFO For batch 19, validation loss is  350.49.
2019-09-11 22:43:05,093 [callbacks.py:15] INFO For batch 20, validation loss is  350.49.
2019-09-11 22:43:05,243 [callbacks.py:15] INFO For batch 21, validation loss is  350.49.
2019-09-11 22:43:05,395 [callbacks.py:15] INFO For batch 22, validation loss is  350.49.
2019-09-11 22:43:05,574 [callbacks.py:15] INFO For batch 23, validation loss is  350.49.
2019-09-11 22:43:05,851 [callbacks.py:15] INFO For batch 24, validation loss is  315.31.
2019-09-11 22:43:06,058 [callbacks.py:15] INFO For batch 25, validation loss is  315.31.
2019-09-11 22:43:06,266 [callbacks.py:15] INFO For batch 26, validation loss is  315.31.
2019-09-11 22:43:06,273 [callbacks.py:19] INFO The validation average loss is  338.74.
2019-09-11 22:43:08,249 [callbacks.py:23] INFO The average loss for epoch 0 is  489.77.
2019-09-11 22:46:08,353 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:46:10,247 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:46:13,475 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:46:13,540 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:46:13,540 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:46:13,540 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:46:13,540 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:46:13,540 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:46:13,541 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,541 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:46:13,541 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,541 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:46:13,541 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,541 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:46:13,542 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,542 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:46:13,542 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,542 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:46:13,542 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,542 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:46:13,542 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,542 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:46:13,543 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,543 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:46:13,543 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,543 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:46:13,543 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,543 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:46:13,543 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,543 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:46:13,544 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,544 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:46:13,544 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,544 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:46:13,544 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,545 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:46:13,545 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,545 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:46:13,545 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,545 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:46:13,545 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,545 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:46:13,545 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,546 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:46:13,546 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,546 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:46:13,546 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,546 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:46:13,546 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,547 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:46:13,547 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,547 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:46:13,547 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,547 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:46:13,547 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,547 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:46:13,547 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,547 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:46:13,548 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,548 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:46:13,548 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,548 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:46:13,548 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:46:13,548 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 781)         200717    
2019-09-11 22:46:13,549 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:46:13,549 [layer_utils.py:182] INFO Total params: 1,900,781
2019-09-11 22:46:13,549 [layer_utils.py:183] INFO Trainable params: 1,898,861
2019-09-11 22:46:13,549 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:46:13,550 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:46:13,703 [train.py:84] INFO # of samples: 128
2019-09-11 22:46:13,703 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:46:13,703 [train.py:86] INFO # of iterations per epoch: 4
2019-09-11 22:46:13,739 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:46:13,809 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:46:25,249 [callbacks.py:12] INFO For batch 0/4, loss is  658.48.
2019-09-11 22:46:27,926 [callbacks.py:12] INFO For batch 1/4, loss is  539.32.
2019-09-11 22:46:30,522 [callbacks.py:12] INFO For batch 2/4, loss is  268.70.
2019-09-11 22:46:33,245 [callbacks.py:12] INFO For batch 3/4, loss is  316.41.
2019-09-11 22:46:34,401 [callbacks.py:15] INFO For batch 0, validation loss is  234.10.
2019-09-11 22:46:34,630 [callbacks.py:15] INFO For batch 1, validation loss is  234.10.
2019-09-11 22:46:34,876 [callbacks.py:15] INFO For batch 2, validation loss is  234.10.
2019-09-11 22:46:35,111 [callbacks.py:15] INFO For batch 3, validation loss is  234.10.
2019-09-11 22:46:35,337 [callbacks.py:15] INFO For batch 4, validation loss is  234.10.
2019-09-11 22:46:35,574 [callbacks.py:15] INFO For batch 5, validation loss is  234.10.
2019-09-11 22:46:35,983 [callbacks.py:15] INFO For batch 6, validation loss is  234.10.
2019-09-11 22:46:36,373 [callbacks.py:15] INFO For batch 7, validation loss is  234.10.
2019-09-11 22:46:37,410 [callbacks.py:15] INFO For batch 8, validation loss is  250.88.
2019-09-11 22:46:37,760 [callbacks.py:15] INFO For batch 9, validation loss is  250.88.
2019-09-11 22:46:37,992 [callbacks.py:15] INFO For batch 10, validation loss is  250.88.
2019-09-11 22:46:38,235 [callbacks.py:15] INFO For batch 11, validation loss is  250.88.
2019-09-11 22:46:38,549 [callbacks.py:15] INFO For batch 12, validation loss is  250.88.
2019-09-11 22:46:38,937 [callbacks.py:15] INFO For batch 13, validation loss is  250.88.
2019-09-11 22:46:39,185 [callbacks.py:15] INFO For batch 14, validation loss is  250.88.
2019-09-11 22:46:39,463 [callbacks.py:15] INFO For batch 15, validation loss is  250.88.
2019-09-11 22:46:40,367 [callbacks.py:15] INFO For batch 16, validation loss is  261.39.
2019-09-11 22:46:40,525 [callbacks.py:15] INFO For batch 17, validation loss is  261.39.
2019-09-11 22:46:40,685 [callbacks.py:15] INFO For batch 18, validation loss is  261.39.
2019-09-11 22:46:40,830 [callbacks.py:15] INFO For batch 19, validation loss is  261.39.
2019-09-11 22:46:40,986 [callbacks.py:15] INFO For batch 20, validation loss is  261.39.
2019-09-11 22:46:41,143 [callbacks.py:15] INFO For batch 21, validation loss is  261.39.
2019-09-11 22:46:41,299 [callbacks.py:15] INFO For batch 22, validation loss is  261.39.
2019-09-11 22:46:41,452 [callbacks.py:15] INFO For batch 23, validation loss is  261.39.
2019-09-11 22:46:41,607 [callbacks.py:15] INFO For batch 24, validation loss is  241.51.
2019-09-11 22:46:41,798 [callbacks.py:15] INFO For batch 25, validation loss is  241.51.
2019-09-11 22:46:42,003 [callbacks.py:15] INFO For batch 26, validation loss is  241.51.
2019-09-11 22:46:42,004 [callbacks.py:19] INFO The validation average loss is  247.98.
2019-09-11 22:46:43,996 [callbacks.py:23] INFO The average loss for epoch 0 is  445.73.
2019-09-11 22:50:25,105 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:50:26,724 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 22:50:30,181 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 22:50:30,247 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 22:50:30,247 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 22:50:30,247 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 22:50:30,247 [layer_utils.py:109] INFO =================================================================
2019-09-11 22:50:30,248 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 22:50:30,248 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,248 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 22:50:30,248 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,248 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 22:50:30,249 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,249 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 22:50:30,249 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,249 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 22:50:30,250 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,250 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 22:50:30,250 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,250 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 22:50:30,250 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,250 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 22:50:30,251 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,251 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 22:50:30,251 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,251 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 22:50:30,251 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,252 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 22:50:30,252 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,252 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 22:50:30,252 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,252 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 22:50:30,252 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,253 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 22:50:30,253 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,253 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 22:50:30,253 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,253 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 22:50:30,254 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,254 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:50:30,254 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,254 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 22:50:30,254 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,254 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:50:30,255 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,255 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 22:50:30,255 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,255 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 22:50:30,255 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,255 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 22:50:30,256 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,256 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 22:50:30,256 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,256 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 22:50:30,256 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,256 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 22:50:30,256 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,257 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 22:50:30,257 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,257 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 22:50:30,257 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,257 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 22:50:30,257 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 22:50:30,257 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 781)         200717    
2019-09-11 22:50:30,257 [layer_utils.py:169] INFO =================================================================
2019-09-11 22:50:30,258 [layer_utils.py:182] INFO Total params: 1,900,781
2019-09-11 22:50:30,258 [layer_utils.py:183] INFO Trainable params: 1,898,861
2019-09-11 22:50:30,258 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 22:50:30,259 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 22:50:30,411 [train.py:84] INFO # of samples: 128
2019-09-11 22:50:30,412 [train.py:85] INFO mini-batch size: 32
2019-09-11 22:50:30,412 [train.py:86] INFO # of iterations per epoch: 4
2019-09-11 22:50:30,450 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 22:50:30,522 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 22:50:42,941 [callbacks.py:12] INFO For batch 0/4, loss is  633.26.
2019-09-11 22:50:45,377 [callbacks.py:12] INFO For batch 1/4, loss is  246.28.
2019-09-11 22:50:48,083 [callbacks.py:12] INFO For batch 2/4, loss is  455.67.
2019-09-11 22:50:48,437 [callbacks.py:12] INFO For batch 3/4, loss is  419.70.
2019-09-11 22:50:49,548 [callbacks.py:15] INFO For batch 0, validation loss is  320.01.
2019-09-11 22:50:49,758 [callbacks.py:15] INFO For batch 1, validation loss is  320.01.
2019-09-11 22:50:49,928 [callbacks.py:15] INFO For batch 2, validation loss is  320.01.
2019-09-11 22:50:50,091 [callbacks.py:15] INFO For batch 3, validation loss is  320.01.
2019-09-11 22:50:50,327 [callbacks.py:15] INFO For batch 4, validation loss is  320.01.
2019-09-11 22:50:50,568 [callbacks.py:15] INFO For batch 5, validation loss is  320.01.
2019-09-11 22:50:50,926 [callbacks.py:15] INFO For batch 6, validation loss is  320.01.
2019-09-11 22:50:51,431 [callbacks.py:15] INFO For batch 7, validation loss is  320.01.
2019-09-11 22:50:52,495 [callbacks.py:15] INFO For batch 8, validation loss is  288.30.
2019-09-11 22:50:52,717 [callbacks.py:15] INFO For batch 9, validation loss is  288.30.
2019-09-11 22:50:52,957 [callbacks.py:15] INFO For batch 10, validation loss is  288.30.
2019-09-11 22:50:53,121 [callbacks.py:15] INFO For batch 11, validation loss is  288.30.
2019-09-11 22:50:53,291 [callbacks.py:15] INFO For batch 12, validation loss is  288.30.
2019-09-11 22:50:53,447 [callbacks.py:15] INFO For batch 13, validation loss is  288.30.
2019-09-11 22:50:53,656 [callbacks.py:15] INFO For batch 14, validation loss is  288.30.
2019-09-11 22:50:53,831 [callbacks.py:15] INFO For batch 15, validation loss is  288.30.
2019-09-11 22:50:54,670 [callbacks.py:15] INFO For batch 16, validation loss is  313.90.
2019-09-11 22:50:54,866 [callbacks.py:15] INFO For batch 17, validation loss is  313.90.
2019-09-11 22:50:55,013 [callbacks.py:15] INFO For batch 18, validation loss is  313.90.
2019-09-11 22:50:55,185 [callbacks.py:15] INFO For batch 19, validation loss is  313.90.
2019-09-11 22:50:55,329 [callbacks.py:15] INFO For batch 20, validation loss is  313.90.
2019-09-11 22:50:55,477 [callbacks.py:15] INFO For batch 21, validation loss is  313.90.
2019-09-11 22:50:55,617 [callbacks.py:15] INFO For batch 22, validation loss is  313.90.
2019-09-11 22:50:55,762 [callbacks.py:15] INFO For batch 23, validation loss is  313.90.
2019-09-11 22:50:55,943 [callbacks.py:15] INFO For batch 24, validation loss is  307.37.
2019-09-11 22:50:56,138 [callbacks.py:15] INFO For batch 25, validation loss is  307.37.
2019-09-11 22:50:56,336 [callbacks.py:15] INFO For batch 26, validation loss is  307.37.
2019-09-11 22:50:56,337 [callbacks.py:19] INFO The validation average loss is  307.40.
2019-09-11 22:50:58,506 [callbacks.py:23] INFO The average loss for epoch 0 is  438.73.
2019-09-11 22:59:57,403 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 22:59:59,013 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 23:00:02,115 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 23:00:02,180 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 23:00:02,181 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 23:00:02,181 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 23:00:02,181 [layer_utils.py:109] INFO =================================================================
2019-09-11 23:00:02,181 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 23:00:02,181 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,181 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 23:00:02,181 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,181 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 23:00:02,182 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,182 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 23:00:02,182 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,182 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 23:00:02,183 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,183 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 23:00:02,183 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,183 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 23:00:02,183 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,184 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 23:00:02,184 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,184 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 23:00:02,184 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,184 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 23:00:02,184 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,184 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 23:00:02,184 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,184 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 23:00:02,184 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,184 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 23:00:02,185 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,185 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 23:00:02,185 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,185 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 23:00:02,186 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,186 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 23:00:02,186 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,186 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:00:02,187 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,187 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 23:00:02,187 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,187 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:00:02,187 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,188 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 23:00:02,188 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,188 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:00:02,188 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,188 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 23:00:02,188 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,188 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 23:00:02,188 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,189 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 23:00:02,189 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,189 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 23:00:02,189 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,189 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 23:00:02,189 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,189 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 23:00:02,189 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,190 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 23:00:02,190 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:00:02,190 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 781)         200717    
2019-09-11 23:00:02,190 [layer_utils.py:169] INFO =================================================================
2019-09-11 23:00:02,191 [layer_utils.py:182] INFO Total params: 1,900,781
2019-09-11 23:00:02,191 [layer_utils.py:183] INFO Trainable params: 1,898,861
2019-09-11 23:00:02,191 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 23:00:02,191 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 23:00:02,333 [train.py:84] INFO # of samples: 128
2019-09-11 23:00:02,333 [train.py:85] INFO mini-batch size: 32
2019-09-11 23:00:02,333 [train.py:86] INFO # of iterations per epoch: 4
2019-09-11 23:00:02,369 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:00:02,439 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 23:00:13,625 [callbacks.py:12] INFO For batch 0/4, loss is  645.40.
2019-09-11 23:00:16,382 [callbacks.py:12] INFO For batch 1/4, loss is  399.86.
2019-09-11 23:00:18,917 [callbacks.py:12] INFO For batch 2/4, loss is  335.45.
2019-09-11 23:00:19,337 [callbacks.py:12] INFO For batch 3/4, loss is  297.37.
2019-09-11 23:00:20,499 [callbacks.py:15] INFO For batch 0, validation loss is  392.74.
2019-09-11 23:00:20,833 [callbacks.py:15] INFO For batch 1, validation loss is  392.74.
2019-09-11 23:00:21,128 [callbacks.py:15] INFO For batch 2, validation loss is  392.74.
2019-09-11 23:00:21,418 [callbacks.py:15] INFO For batch 3, validation loss is  392.74.
2019-09-11 23:00:21,707 [callbacks.py:15] INFO For batch 4, validation loss is  392.74.
2019-09-11 23:00:21,961 [callbacks.py:15] INFO For batch 5, validation loss is  392.74.
2019-09-11 23:00:22,341 [callbacks.py:15] INFO For batch 6, validation loss is  392.74.
2019-09-11 23:00:22,682 [callbacks.py:15] INFO For batch 7, validation loss is  392.74.
2019-09-11 23:00:23,837 [callbacks.py:15] INFO For batch 8, validation loss is  452.08.
2019-09-11 23:00:24,182 [callbacks.py:15] INFO For batch 9, validation loss is  452.08.
2019-09-11 23:00:24,466 [callbacks.py:15] INFO For batch 10, validation loss is  452.08.
2019-09-11 23:00:24,750 [callbacks.py:15] INFO For batch 11, validation loss is  452.08.
2019-09-11 23:00:25,051 [callbacks.py:15] INFO For batch 12, validation loss is  452.08.
2019-09-11 23:00:25,467 [callbacks.py:15] INFO For batch 13, validation loss is  452.08.
2019-09-11 23:00:25,693 [callbacks.py:15] INFO For batch 14, validation loss is  452.08.
2019-09-11 23:00:25,930 [callbacks.py:15] INFO For batch 15, validation loss is  452.08.
2019-09-11 23:00:26,912 [callbacks.py:15] INFO For batch 16, validation loss is  449.41.
2019-09-11 23:00:27,069 [callbacks.py:15] INFO For batch 17, validation loss is  449.41.
2019-09-11 23:00:27,251 [callbacks.py:15] INFO For batch 18, validation loss is  449.41.
2019-09-11 23:00:27,404 [callbacks.py:15] INFO For batch 19, validation loss is  449.41.
2019-09-11 23:00:27,558 [callbacks.py:15] INFO For batch 20, validation loss is  449.41.
2019-09-11 23:00:27,730 [callbacks.py:15] INFO For batch 21, validation loss is  449.41.
2019-09-11 23:00:27,894 [callbacks.py:15] INFO For batch 22, validation loss is  449.41.
2019-09-11 23:00:28,132 [callbacks.py:15] INFO For batch 23, validation loss is  449.41.
2019-09-11 23:00:28,389 [callbacks.py:15] INFO For batch 24, validation loss is  407.90.
2019-09-11 23:00:28,573 [callbacks.py:15] INFO For batch 25, validation loss is  407.90.
2019-09-11 23:00:28,783 [callbacks.py:15] INFO For batch 26, validation loss is  407.90.
2019-09-11 23:00:28,784 [callbacks.py:19] INFO The validation average loss is  428.80.
2019-09-11 23:00:30,826 [callbacks.py:23] INFO The average loss for epoch 0 is  419.52.
2019-09-11 23:05:14,345 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 23:05:16,224 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 23:05:19,798 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 23:05:19,863 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 23:05:19,864 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 23:05:19,864 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 23:05:19,864 [layer_utils.py:109] INFO =================================================================
2019-09-11 23:05:19,864 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 23:05:19,864 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,864 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 23:05:19,865 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,865 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 23:05:19,865 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,865 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 23:05:19,866 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,866 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 23:05:19,866 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,866 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 23:05:19,866 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,866 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 23:05:19,867 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,867 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 23:05:19,867 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,867 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 23:05:19,867 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,867 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 23:05:19,868 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,868 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 23:05:19,868 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,868 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 23:05:19,868 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,868 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 23:05:19,868 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,869 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 23:05:19,869 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,869 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 23:05:19,869 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,869 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 23:05:19,870 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,870 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:05:19,870 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,870 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 23:05:19,871 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,871 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:05:19,871 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,871 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 23:05:19,871 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,871 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:05:19,871 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,871 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 23:05:19,872 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,872 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 23:05:19,872 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,872 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 23:05:19,872 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,872 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 23:05:19,872 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,872 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 23:05:19,873 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,873 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 23:05:19,873 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,873 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 23:05:19,873 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:05:19,873 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 781)         200717    
2019-09-11 23:05:19,873 [layer_utils.py:169] INFO =================================================================
2019-09-11 23:05:19,874 [layer_utils.py:182] INFO Total params: 1,900,781
2019-09-11 23:05:19,874 [layer_utils.py:183] INFO Trainable params: 1,898,861
2019-09-11 23:05:19,874 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 23:05:19,875 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 23:05:20,017 [train.py:84] INFO # of samples: 128
2019-09-11 23:05:20,017 [train.py:85] INFO mini-batch size: 32
2019-09-11 23:05:20,017 [train.py:86] INFO # of iterations per epoch: 4
2019-09-11 23:05:20,053 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:05:20,123 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 23:05:31,782 [callbacks.py:12] INFO For batch 0/4, loss is  685.26.
2019-09-11 23:05:32,237 [callbacks.py:12] INFO For batch 1/4, loss is  318.93.
2019-09-11 23:05:32,668 [callbacks.py:12] INFO For batch 2/4, loss is  408.01.
2019-09-11 23:05:35,320 [callbacks.py:12] INFO For batch 3/4, loss is  277.05.
2019-09-11 23:05:36,426 [callbacks.py:15] INFO For batch 0, validation loss is  250.97.
2019-09-11 23:05:36,817 [callbacks.py:15] INFO For batch 1, validation loss is  250.97.
2019-09-11 23:05:37,109 [callbacks.py:15] INFO For batch 2, validation loss is  250.97.
2019-09-11 23:05:37,403 [callbacks.py:15] INFO For batch 3, validation loss is  250.97.
2019-09-11 23:05:37,661 [callbacks.py:15] INFO For batch 4, validation loss is  250.97.
2019-09-11 23:05:38,071 [callbacks.py:15] INFO For batch 5, validation loss is  250.97.
2019-09-11 23:05:38,481 [callbacks.py:15] INFO For batch 6, validation loss is  250.97.
2019-09-11 23:05:38,810 [callbacks.py:15] INFO For batch 7, validation loss is  250.97.
2019-09-11 23:05:39,929 [callbacks.py:15] INFO For batch 8, validation loss is  239.55.
2019-09-11 23:05:40,284 [callbacks.py:15] INFO For batch 9, validation loss is  239.55.
2019-09-11 23:05:40,576 [callbacks.py:15] INFO For batch 10, validation loss is  239.55.
2019-09-11 23:05:40,801 [callbacks.py:15] INFO For batch 11, validation loss is  239.55.
2019-09-11 23:05:41,049 [callbacks.py:15] INFO For batch 12, validation loss is  239.55.
2019-09-11 23:05:41,317 [callbacks.py:15] INFO For batch 13, validation loss is  239.55.
2019-09-11 23:05:41,582 [callbacks.py:15] INFO For batch 14, validation loss is  239.55.
2019-09-11 23:05:41,838 [callbacks.py:15] INFO For batch 15, validation loss is  239.55.
2019-09-11 23:05:42,726 [callbacks.py:15] INFO For batch 16, validation loss is  249.09.
2019-09-11 23:05:42,938 [callbacks.py:15] INFO For batch 17, validation loss is  249.09.
2019-09-11 23:05:43,123 [callbacks.py:15] INFO For batch 18, validation loss is  249.09.
2019-09-11 23:05:43,298 [callbacks.py:15] INFO For batch 19, validation loss is  249.09.
2019-09-11 23:05:43,472 [callbacks.py:15] INFO For batch 20, validation loss is  249.09.
2019-09-11 23:05:43,627 [callbacks.py:15] INFO For batch 21, validation loss is  249.09.
2019-09-11 23:05:43,800 [callbacks.py:15] INFO For batch 22, validation loss is  249.09.
2019-09-11 23:05:44,066 [callbacks.py:15] INFO For batch 23, validation loss is  249.09.
2019-09-11 23:05:44,469 [callbacks.py:15] INFO For batch 24, validation loss is  230.20.
2019-09-11 23:05:44,653 [callbacks.py:15] INFO For batch 25, validation loss is  230.20.
2019-09-11 23:05:44,861 [callbacks.py:15] INFO For batch 26, validation loss is  230.20.
2019-09-11 23:05:44,869 [callbacks.py:19] INFO The validation average loss is  244.72.
2019-09-11 23:05:46,793 [callbacks.py:23] INFO The average loss for epoch 0 is  422.31.
2019-09-11 23:21:22,370 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 23:21:31,634 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 23:21:39,817 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 23:21:42,958 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 23:21:43,022 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 23:21:43,022 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 23:21:43,022 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 23:21:43,022 [layer_utils.py:109] INFO =================================================================
2019-09-11 23:21:43,022 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 23:21:43,023 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,023 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 23:21:43,023 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,023 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 23:21:43,024 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,024 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 23:21:43,024 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,025 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 23:21:43,025 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,025 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 23:21:43,025 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,025 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 23:21:43,025 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,026 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 23:21:43,026 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,026 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 23:21:43,026 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,026 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 23:21:43,026 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,027 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 23:21:43,027 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,027 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 23:21:43,027 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,027 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 23:21:43,027 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,028 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 23:21:43,028 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,028 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 23:21:43,028 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,028 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 23:21:43,028 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,028 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:21:43,029 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,029 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 23:21:43,029 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,029 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:21:43,029 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,029 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 23:21:43,030 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,030 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:21:43,030 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,030 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 23:21:43,030 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,030 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 23:21:43,030 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,031 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 23:21:43,031 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,031 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 23:21:43,031 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,031 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 23:21:43,031 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,031 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 23:21:43,032 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,032 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 23:21:43,032 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:21:43,032 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 23:21:43,032 [layer_utils.py:169] INFO =================================================================
2019-09-11 23:21:43,033 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 23:21:43,033 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 23:21:43,033 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 23:21:43,034 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 23:21:43,184 [train.py:84] INFO # of samples: 10000
2019-09-11 23:21:43,185 [train.py:85] INFO mini-batch size: 32
2019-09-11 23:21:43,185 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 23:21:43,222 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:21:43,292 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 23:22:15,515 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 23:22:23,692 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 23:22:27,070 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 23:22:27,133 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 23:22:27,134 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 23:22:27,134 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 23:22:27,134 [layer_utils.py:109] INFO =================================================================
2019-09-11 23:22:27,134 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 23:22:27,134 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,134 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 23:22:27,134 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,134 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 23:22:27,135 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,135 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 23:22:27,135 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,135 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 23:22:27,135 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,135 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 23:22:27,136 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,136 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 23:22:27,136 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,136 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 23:22:27,136 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,137 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 23:22:27,137 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,137 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 23:22:27,137 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,137 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 23:22:27,137 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,138 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 23:22:27,138 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,138 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 23:22:27,138 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,138 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 23:22:27,138 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,138 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 23:22:27,139 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,139 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 23:22:27,139 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,139 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:22:27,139 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,139 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 23:22:27,139 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,139 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:22:27,139 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,140 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 23:22:27,140 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,140 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:22:27,140 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,140 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 23:22:27,140 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,140 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 23:22:27,141 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,141 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 23:22:27,141 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,141 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 23:22:27,141 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,141 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 23:22:27,141 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,141 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 23:22:27,142 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,142 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 23:22:27,142 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:22:27,142 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 23:22:27,142 [layer_utils.py:169] INFO =================================================================
2019-09-11 23:22:27,143 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 23:22:27,143 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 23:22:27,143 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 23:22:27,143 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 23:22:27,295 [train.py:84] INFO # of samples: 10000
2019-09-11 23:22:27,295 [train.py:85] INFO mini-batch size: 32
2019-09-11 23:22:27,295 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 23:22:27,332 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:22:27,402 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 23:22:39,358 [callbacks.py:12] INFO For batch 0/312, loss is  756.79.
2019-09-11 23:22:41,893 [callbacks.py:12] INFO For batch 1/312, loss is  568.05.
2019-09-11 23:22:44,651 [callbacks.py:12] INFO For batch 2/312, loss is  631.82.
2019-09-11 23:22:47,454 [callbacks.py:12] INFO For batch 3/312, loss is  315.35.
2019-09-11 23:22:50,043 [callbacks.py:12] INFO For batch 4/312, loss is  313.85.
2019-09-11 23:22:52,727 [callbacks.py:12] INFO For batch 5/312, loss is  265.86.
2019-09-11 23:22:55,434 [callbacks.py:12] INFO For batch 6/312, loss is  266.35.
2019-09-11 23:22:58,296 [callbacks.py:12] INFO For batch 7/312, loss is  261.43.
2019-09-11 23:23:01,072 [callbacks.py:12] INFO For batch 8/312, loss is  262.63.
2019-09-11 23:23:04,194 [callbacks.py:12] INFO For batch 9/312, loss is  253.63.
2019-09-11 23:23:07,096 [callbacks.py:12] INFO For batch 10/312, loss is  235.80.
2019-09-11 23:23:09,905 [callbacks.py:12] INFO For batch 11/312, loss is  249.41.
2019-09-11 23:23:12,731 [callbacks.py:12] INFO For batch 12/312, loss is  234.44.
2019-09-11 23:23:13,213 [callbacks.py:12] INFO For batch 13/312, loss is  255.41.
2019-09-11 23:23:16,352 [callbacks.py:12] INFO For batch 14/312, loss is  277.81.
2019-09-11 23:23:19,231 [callbacks.py:12] INFO For batch 15/312, loss is  240.46.
2019-09-11 23:23:21,896 [callbacks.py:12] INFO For batch 16/312, loss is  259.40.
2019-09-11 23:23:22,370 [callbacks.py:12] INFO For batch 17/312, loss is  233.50.
2019-09-11 23:23:24,914 [callbacks.py:12] INFO For batch 18/312, loss is  229.68.
2019-09-11 23:23:25,330 [callbacks.py:12] INFO For batch 19/312, loss is  236.20.
2019-09-11 23:23:25,795 [callbacks.py:12] INFO For batch 20/312, loss is  242.08.
2019-09-11 23:23:28,765 [callbacks.py:12] INFO For batch 21/312, loss is  245.00.
2019-09-11 23:23:31,389 [callbacks.py:12] INFO For batch 22/312, loss is  228.68.
2019-09-11 23:23:33,938 [callbacks.py:12] INFO For batch 23/312, loss is  225.32.
2019-09-11 23:23:37,021 [callbacks.py:12] INFO For batch 24/312, loss is  225.57.
2019-09-11 23:23:39,642 [callbacks.py:12] INFO For batch 25/312, loss is  227.11.
2019-09-11 23:23:40,091 [callbacks.py:12] INFO For batch 26/312, loss is  224.57.
2019-09-11 23:23:42,759 [callbacks.py:12] INFO For batch 27/312, loss is  209.74.
2019-09-11 23:23:45,398 [callbacks.py:12] INFO For batch 28/312, loss is  231.56.
2019-09-11 23:23:48,393 [callbacks.py:12] INFO For batch 29/312, loss is  241.00.
2019-09-11 23:23:48,805 [callbacks.py:12] INFO For batch 30/312, loss is  220.95.
2019-09-11 23:23:49,304 [callbacks.py:12] INFO For batch 31/312, loss is  221.76.
2019-09-11 23:23:49,834 [callbacks.py:12] INFO For batch 32/312, loss is  237.46.
2019-09-11 23:23:50,316 [callbacks.py:12] INFO For batch 33/312, loss is  217.34.
2019-09-11 23:23:50,716 [callbacks.py:12] INFO For batch 34/312, loss is  221.12.
2019-09-11 23:23:51,261 [callbacks.py:12] INFO For batch 35/312, loss is  223.82.
2019-09-11 23:23:51,668 [callbacks.py:12] INFO For batch 36/312, loss is  211.49.
2019-09-11 23:23:54,796 [callbacks.py:12] INFO For batch 37/312, loss is  224.65.
2019-09-11 23:23:55,340 [callbacks.py:12] INFO For batch 38/312, loss is  226.34.
2019-09-11 23:23:58,102 [callbacks.py:12] INFO For batch 39/312, loss is  221.49.
2019-09-11 23:23:58,502 [callbacks.py:12] INFO For batch 40/312, loss is  201.27.
2019-09-11 23:24:01,087 [callbacks.py:12] INFO For batch 41/312, loss is  220.98.
2019-09-11 23:24:01,525 [callbacks.py:12] INFO For batch 42/312, loss is  223.18.
2019-09-11 23:24:04,464 [callbacks.py:12] INFO For batch 43/312, loss is  213.50.
2019-09-11 23:24:04,930 [callbacks.py:12] INFO For batch 44/312, loss is  217.99.
2019-09-11 23:24:05,326 [callbacks.py:12] INFO For batch 45/312, loss is  213.70.
2019-09-11 23:24:05,793 [callbacks.py:12] INFO For batch 46/312, loss is  221.00.
2019-09-11 23:24:06,177 [callbacks.py:12] INFO For batch 47/312, loss is  210.21.
2019-09-11 23:24:09,149 [callbacks.py:12] INFO For batch 48/312, loss is  215.91.
2019-09-11 23:24:11,906 [callbacks.py:12] INFO For batch 49/312, loss is  212.01.
2019-09-11 23:24:12,371 [callbacks.py:12] INFO For batch 50/312, loss is  214.48.
2019-09-11 23:24:14,881 [callbacks.py:12] INFO For batch 51/312, loss is  217.14.
2019-09-11 23:24:17,711 [callbacks.py:12] INFO For batch 52/312, loss is  221.12.
2019-09-11 23:24:20,229 [callbacks.py:12] INFO For batch 53/312, loss is  210.10.
2019-09-11 23:24:20,688 [callbacks.py:12] INFO For batch 54/312, loss is  214.40.
2019-09-11 23:24:21,149 [callbacks.py:12] INFO For batch 55/312, loss is  204.11.
2019-09-11 23:24:23,827 [callbacks.py:12] INFO For batch 56/312, loss is  208.05.
2019-09-11 23:24:26,534 [callbacks.py:12] INFO For batch 57/312, loss is  207.98.
2019-09-11 23:24:26,967 [callbacks.py:12] INFO For batch 58/312, loss is  209.07.
2019-09-11 23:24:30,182 [callbacks.py:12] INFO For batch 59/312, loss is  217.79.
2019-09-11 23:24:30,595 [callbacks.py:12] INFO For batch 60/312, loss is  210.49.
2019-09-11 23:24:31,017 [callbacks.py:12] INFO For batch 61/312, loss is  212.67.
2019-09-11 23:24:33,825 [callbacks.py:12] INFO For batch 62/312, loss is  212.43.
2019-09-11 23:24:34,262 [callbacks.py:12] INFO For batch 63/312, loss is  209.19.
2019-09-11 23:24:34,662 [callbacks.py:12] INFO For batch 64/312, loss is  205.81.
2019-09-11 23:24:35,013 [callbacks.py:12] INFO For batch 65/312, loss is  204.05.
2019-09-11 23:24:35,521 [callbacks.py:12] INFO For batch 66/312, loss is  205.84.
2019-09-11 23:24:35,961 [callbacks.py:12] INFO For batch 67/312, loss is  215.77.
2019-09-11 23:24:36,416 [callbacks.py:12] INFO For batch 68/312, loss is  208.99.
2019-09-11 23:24:36,803 [callbacks.py:12] INFO For batch 69/312, loss is  211.04.
2019-09-11 23:24:39,712 [callbacks.py:12] INFO For batch 70/312, loss is  206.65.
2019-09-11 23:24:42,375 [callbacks.py:12] INFO For batch 71/312, loss is  209.84.
2019-09-11 23:24:42,745 [callbacks.py:12] INFO For batch 72/312, loss is  205.28.
2019-09-11 23:24:43,205 [callbacks.py:12] INFO For batch 73/312, loss is  209.03.
2019-09-11 23:24:46,144 [callbacks.py:12] INFO For batch 74/312, loss is  215.58.
2019-09-11 23:24:46,598 [callbacks.py:12] INFO For batch 75/312, loss is  204.80.
2019-09-11 23:24:49,492 [callbacks.py:12] INFO For batch 76/312, loss is  206.53.
2019-09-11 23:24:49,914 [callbacks.py:12] INFO For batch 77/312, loss is  213.53.
2019-09-11 23:24:50,320 [callbacks.py:12] INFO For batch 78/312, loss is  210.67.
2019-09-11 23:24:50,721 [callbacks.py:12] INFO For batch 79/312, loss is  207.83.
2019-09-11 23:24:51,156 [callbacks.py:12] INFO For batch 80/312, loss is  209.68.
2019-09-11 23:24:51,633 [callbacks.py:12] INFO For batch 81/312, loss is  209.67.
2019-09-11 23:24:54,966 [callbacks.py:12] INFO For batch 82/312, loss is  209.44.
2019-09-11 23:24:55,313 [callbacks.py:12] INFO For batch 83/312, loss is  204.86.
2019-09-11 23:24:55,720 [callbacks.py:12] INFO For batch 84/312, loss is  210.12.
2019-09-11 23:24:56,137 [callbacks.py:12] INFO For batch 85/312, loss is  211.99.
2019-09-11 23:24:56,622 [callbacks.py:12] INFO For batch 86/312, loss is  210.52.
2019-09-11 23:24:57,078 [callbacks.py:12] INFO For batch 87/312, loss is  211.28.
2019-09-11 23:24:59,801 [callbacks.py:12] INFO For batch 88/312, loss is  210.17.
2019-09-11 23:25:00,206 [callbacks.py:12] INFO For batch 89/312, loss is  216.70.
2019-09-11 23:25:00,563 [callbacks.py:12] INFO For batch 90/312, loss is  209.41.
2019-09-11 23:25:01,052 [callbacks.py:12] INFO For batch 91/312, loss is  208.68.
2019-09-11 23:25:01,460 [callbacks.py:12] INFO For batch 92/312, loss is  209.55.
2019-09-11 23:25:01,911 [callbacks.py:12] INFO For batch 93/312, loss is  217.43.
2019-09-11 23:25:02,289 [callbacks.py:12] INFO For batch 94/312, loss is  214.75.
2019-09-11 23:25:02,838 [callbacks.py:12] INFO For batch 95/312, loss is  203.67.
2019-09-11 23:25:03,222 [callbacks.py:12] INFO For batch 96/312, loss is  202.30.
2019-09-11 23:25:03,677 [callbacks.py:12] INFO For batch 97/312, loss is  203.73.
2019-09-11 23:25:04,157 [callbacks.py:12] INFO For batch 98/312, loss is  207.23.
2019-09-11 23:25:04,613 [callbacks.py:12] INFO For batch 99/312, loss is  211.29.
2019-09-11 23:25:07,230 [callbacks.py:12] INFO For batch 100/312, loss is  205.77.
2019-09-11 23:25:10,001 [callbacks.py:12] INFO For batch 101/312, loss is  211.99.
2019-09-11 23:25:12,490 [callbacks.py:12] INFO For batch 102/312, loss is  201.73.
2019-09-11 23:25:12,910 [callbacks.py:12] INFO For batch 103/312, loss is  209.41.
2019-09-11 23:25:13,327 [callbacks.py:12] INFO For batch 104/312, loss is  210.61.
2019-09-11 23:25:13,759 [callbacks.py:12] INFO For batch 105/312, loss is  212.49.
2019-09-11 23:25:14,183 [callbacks.py:12] INFO For batch 106/312, loss is  206.99.
2019-09-11 23:25:14,644 [callbacks.py:12] INFO For batch 107/312, loss is  210.38.
2019-09-11 23:25:15,088 [callbacks.py:12] INFO For batch 108/312, loss is  204.38.
2019-09-11 23:25:15,522 [callbacks.py:12] INFO For batch 109/312, loss is  202.08.
2019-09-11 23:25:16,028 [callbacks.py:12] INFO For batch 110/312, loss is  205.30.
2019-09-11 23:25:16,464 [callbacks.py:12] INFO For batch 111/312, loss is  209.42.
2019-09-11 23:25:16,859 [callbacks.py:12] INFO For batch 112/312, loss is  201.27.
2019-09-11 23:25:17,268 [callbacks.py:12] INFO For batch 113/312, loss is  206.33.
2019-09-11 23:25:17,784 [callbacks.py:12] INFO For batch 114/312, loss is  208.56.
2019-09-11 23:25:18,165 [callbacks.py:12] INFO For batch 115/312, loss is  211.82.
2019-09-11 23:25:18,527 [callbacks.py:12] INFO For batch 116/312, loss is  206.12.
2019-09-11 23:25:18,945 [callbacks.py:12] INFO For batch 117/312, loss is  207.17.
2019-09-11 23:25:19,419 [callbacks.py:12] INFO For batch 118/312, loss is  202.53.
2019-09-11 23:25:19,936 [callbacks.py:12] INFO For batch 119/312, loss is  213.64.
2019-09-11 23:25:20,315 [callbacks.py:12] INFO For batch 120/312, loss is  205.48.
2019-09-11 23:25:20,727 [callbacks.py:12] INFO For batch 121/312, loss is  202.77.
2019-09-11 23:25:21,172 [callbacks.py:12] INFO For batch 122/312, loss is  204.10.
2019-09-11 23:25:21,648 [callbacks.py:12] INFO For batch 123/312, loss is  200.28.
2019-09-11 23:25:22,007 [callbacks.py:12] INFO For batch 124/312, loss is  199.05.
2019-09-11 23:25:22,495 [callbacks.py:12] INFO For batch 125/312, loss is  209.18.
2019-09-11 23:25:22,955 [callbacks.py:12] INFO For batch 126/312, loss is  203.43.
2019-09-11 23:25:23,454 [callbacks.py:12] INFO For batch 127/312, loss is  205.46.
2019-09-11 23:25:23,895 [callbacks.py:12] INFO For batch 128/312, loss is  210.58.
2019-09-11 23:25:24,357 [callbacks.py:12] INFO For batch 129/312, loss is  211.32.
2019-09-11 23:25:24,782 [callbacks.py:12] INFO For batch 130/312, loss is  202.74.
2019-09-11 23:25:25,226 [callbacks.py:12] INFO For batch 131/312, loss is  211.39.
2019-09-11 23:25:25,672 [callbacks.py:12] INFO For batch 132/312, loss is  217.55.
2019-09-11 23:25:26,121 [callbacks.py:12] INFO For batch 133/312, loss is  204.28.
2019-09-11 23:25:26,557 [callbacks.py:12] INFO For batch 134/312, loss is  211.93.
2019-09-11 23:25:26,957 [callbacks.py:12] INFO For batch 135/312, loss is  213.59.
2019-09-11 23:25:27,405 [callbacks.py:12] INFO For batch 136/312, loss is  213.49.
2019-09-11 23:25:27,926 [callbacks.py:12] INFO For batch 137/312, loss is  206.29.
2019-09-11 23:25:28,309 [callbacks.py:12] INFO For batch 138/312, loss is  208.27.
2019-09-11 23:25:28,722 [callbacks.py:12] INFO For batch 139/312, loss is  204.35.
2019-09-11 23:25:29,233 [callbacks.py:12] INFO For batch 140/312, loss is  201.00.
2019-09-11 23:25:29,666 [callbacks.py:12] INFO For batch 141/312, loss is  202.06.
2019-09-11 23:25:30,151 [callbacks.py:12] INFO For batch 142/312, loss is  205.02.
2019-09-11 23:25:30,680 [callbacks.py:12] INFO For batch 143/312, loss is  205.76.
2019-09-11 23:25:31,143 [callbacks.py:12] INFO For batch 144/312, loss is  205.24.
2019-09-11 23:25:31,546 [callbacks.py:12] INFO For batch 145/312, loss is  203.37.
2019-09-11 23:25:32,006 [callbacks.py:12] INFO For batch 146/312, loss is  211.19.
2019-09-11 23:25:32,478 [callbacks.py:12] INFO For batch 147/312, loss is  205.73.
2019-09-11 23:25:32,902 [callbacks.py:12] INFO For batch 148/312, loss is  205.02.
2019-09-11 23:25:33,333 [callbacks.py:12] INFO For batch 149/312, loss is  210.19.
2019-09-11 23:25:33,713 [callbacks.py:12] INFO For batch 150/312, loss is  203.34.
2019-09-11 23:25:34,187 [callbacks.py:12] INFO For batch 151/312, loss is  211.81.
2019-09-11 23:25:34,599 [callbacks.py:12] INFO For batch 152/312, loss is  209.92.
2019-09-11 23:25:35,041 [callbacks.py:12] INFO For batch 153/312, loss is  203.24.
2019-09-11 23:25:35,431 [callbacks.py:12] INFO For batch 154/312, loss is  208.15.
2019-09-11 23:25:35,798 [callbacks.py:12] INFO For batch 155/312, loss is  198.08.
2019-09-11 23:25:36,339 [callbacks.py:12] INFO For batch 156/312, loss is  210.33.
2019-09-11 23:25:36,925 [callbacks.py:12] INFO For batch 157/312, loss is  214.41.
2019-09-11 23:25:37,351 [callbacks.py:12] INFO For batch 158/312, loss is  215.78.
2019-09-11 23:25:37,737 [callbacks.py:12] INFO For batch 159/312, loss is  198.79.
2019-09-11 23:25:38,117 [callbacks.py:12] INFO For batch 160/312, loss is  201.18.
2019-09-11 23:25:38,587 [callbacks.py:12] INFO For batch 161/312, loss is  203.05.
2019-09-11 23:25:38,997 [callbacks.py:12] INFO For batch 162/312, loss is  201.06.
2019-09-11 23:25:39,484 [callbacks.py:12] INFO For batch 163/312, loss is  202.84.
2019-09-11 23:25:39,902 [callbacks.py:12] INFO For batch 164/312, loss is  202.44.
2019-09-11 23:25:40,348 [callbacks.py:12] INFO For batch 165/312, loss is  205.85.
2019-09-11 23:25:40,798 [callbacks.py:12] INFO For batch 166/312, loss is  207.60.
2019-09-11 23:25:41,211 [callbacks.py:12] INFO For batch 167/312, loss is  210.49.
2019-09-11 23:25:41,602 [callbacks.py:12] INFO For batch 168/312, loss is  207.38.
2019-09-11 23:25:42,027 [callbacks.py:12] INFO For batch 169/312, loss is  205.62.
2019-09-11 23:25:42,504 [callbacks.py:12] INFO For batch 170/312, loss is  206.43.
2019-09-11 23:25:42,960 [callbacks.py:12] INFO For batch 171/312, loss is  211.51.
2019-09-11 23:25:43,336 [callbacks.py:12] INFO For batch 172/312, loss is  200.10.
2019-09-11 23:25:43,818 [callbacks.py:12] INFO For batch 173/312, loss is  209.83.
2019-09-11 23:25:44,274 [callbacks.py:12] INFO For batch 174/312, loss is  206.68.
2019-09-11 23:25:44,668 [callbacks.py:12] INFO For batch 175/312, loss is  212.93.
2019-09-11 23:25:45,039 [callbacks.py:12] INFO For batch 176/312, loss is  208.85.
2019-09-11 23:25:45,424 [callbacks.py:12] INFO For batch 177/312, loss is  201.76.
2019-09-11 23:25:45,843 [callbacks.py:12] INFO For batch 178/312, loss is  207.52.
2019-09-11 23:25:46,321 [callbacks.py:12] INFO For batch 179/312, loss is  223.45.
2019-09-11 23:25:46,714 [callbacks.py:12] INFO For batch 180/312, loss is  208.61.
2019-09-11 23:25:47,217 [callbacks.py:12] INFO For batch 181/312, loss is  209.43.
2019-09-11 23:25:47,630 [callbacks.py:12] INFO For batch 182/312, loss is  208.54.
2019-09-11 23:25:50,819 [callbacks.py:12] INFO For batch 183/312, loss is  209.16.
2019-09-11 23:25:51,304 [callbacks.py:12] INFO For batch 184/312, loss is  208.49.
2019-09-11 23:25:51,796 [callbacks.py:12] INFO For batch 185/312, loss is  209.54.
2019-09-11 23:25:52,274 [callbacks.py:12] INFO For batch 186/312, loss is  210.39.
2019-09-11 23:25:52,715 [callbacks.py:12] INFO For batch 187/312, loss is  208.67.
2019-09-11 23:25:53,101 [callbacks.py:12] INFO For batch 188/312, loss is  212.16.
2019-09-11 23:25:53,572 [callbacks.py:12] INFO For batch 189/312, loss is  202.93.
2019-09-11 23:25:54,044 [callbacks.py:12] INFO For batch 190/312, loss is  206.28.
2019-09-11 23:25:54,442 [callbacks.py:12] INFO For batch 191/312, loss is  198.12.
2019-09-11 23:25:54,884 [callbacks.py:12] INFO For batch 192/312, loss is  210.94.
2019-09-11 23:25:55,345 [callbacks.py:12] INFO For batch 193/312, loss is  206.30.
2019-09-11 23:25:55,817 [callbacks.py:12] INFO For batch 194/312, loss is  214.29.
2019-09-11 23:25:56,210 [callbacks.py:12] INFO For batch 195/312, loss is  205.96.
2019-09-11 23:25:56,666 [callbacks.py:12] INFO For batch 196/312, loss is  204.94.
2019-09-11 23:25:57,095 [callbacks.py:12] INFO For batch 197/312, loss is  203.01.
2019-09-11 23:25:57,540 [callbacks.py:12] INFO For batch 198/312, loss is  201.53.
2019-09-11 23:25:57,960 [callbacks.py:12] INFO For batch 199/312, loss is  213.68.
2019-09-11 23:25:58,425 [callbacks.py:12] INFO For batch 200/312, loss is  210.23.
2019-09-11 23:25:58,890 [callbacks.py:12] INFO For batch 201/312, loss is  209.26.
2019-09-11 23:25:59,276 [callbacks.py:12] INFO For batch 202/312, loss is  210.69.
2019-09-11 23:25:59,683 [callbacks.py:12] INFO For batch 203/312, loss is  202.82.
2019-09-11 23:26:00,161 [callbacks.py:12] INFO For batch 204/312, loss is  206.65.
2019-09-11 23:26:00,621 [callbacks.py:12] INFO For batch 205/312, loss is  197.81.
2019-09-11 23:26:01,086 [callbacks.py:12] INFO For batch 206/312, loss is  200.71.
2019-09-11 23:26:01,575 [callbacks.py:12] INFO For batch 207/312, loss is  203.61.
2019-09-11 23:26:01,953 [callbacks.py:12] INFO For batch 208/312, loss is  208.66.
2019-09-11 23:26:02,325 [callbacks.py:12] INFO For batch 209/312, loss is  211.36.
2019-09-11 23:26:02,816 [callbacks.py:12] INFO For batch 210/312, loss is  209.13.
2019-09-11 23:26:03,224 [callbacks.py:12] INFO For batch 211/312, loss is  206.80.
2019-09-11 23:26:03,692 [callbacks.py:12] INFO For batch 212/312, loss is  197.67.
2019-09-11 23:26:04,124 [callbacks.py:12] INFO For batch 213/312, loss is  219.17.
2019-09-11 23:26:04,509 [callbacks.py:12] INFO For batch 214/312, loss is  213.52.
2019-09-11 23:26:05,043 [callbacks.py:12] INFO For batch 215/312, loss is  206.01.
2019-09-11 23:26:07,684 [callbacks.py:12] INFO For batch 216/312, loss is  205.50.
2019-09-11 23:26:08,080 [callbacks.py:12] INFO For batch 217/312, loss is  207.34.
2019-09-11 23:26:08,450 [callbacks.py:12] INFO For batch 218/312, loss is  203.78.
2019-09-11 23:26:08,860 [callbacks.py:12] INFO For batch 219/312, loss is  209.34.
2019-09-11 23:26:09,354 [callbacks.py:12] INFO For batch 220/312, loss is  203.83.
2019-09-11 23:26:09,832 [callbacks.py:12] INFO For batch 221/312, loss is  206.64.
2019-09-11 23:26:10,319 [callbacks.py:12] INFO For batch 222/312, loss is  200.92.
2019-09-11 23:26:10,711 [callbacks.py:12] INFO For batch 223/312, loss is  202.34.
2019-09-11 23:26:11,149 [callbacks.py:12] INFO For batch 224/312, loss is  205.41.
2019-09-11 23:26:11,573 [callbacks.py:12] INFO For batch 225/312, loss is  206.25.
2019-09-11 23:26:11,989 [callbacks.py:12] INFO For batch 226/312, loss is  196.79.
2019-09-11 23:26:12,430 [callbacks.py:12] INFO For batch 227/312, loss is  198.30.
2019-09-11 23:26:12,835 [callbacks.py:12] INFO For batch 228/312, loss is  205.64.
2019-09-11 23:26:13,290 [callbacks.py:12] INFO For batch 229/312, loss is  204.39.
2019-09-11 23:26:16,450 [callbacks.py:12] INFO For batch 230/312, loss is  206.12.
2019-09-11 23:26:16,864 [callbacks.py:12] INFO For batch 231/312, loss is  204.81.
2019-09-11 23:26:17,254 [callbacks.py:12] INFO For batch 232/312, loss is  201.82.
2019-09-11 23:26:17,692 [callbacks.py:12] INFO For batch 233/312, loss is  201.98.
2019-09-11 23:26:18,086 [callbacks.py:12] INFO For batch 234/312, loss is  203.28.
2019-09-11 23:26:18,535 [callbacks.py:12] INFO For batch 235/312, loss is  206.30.
2019-09-11 23:26:19,001 [callbacks.py:12] INFO For batch 236/312, loss is  212.40.
2019-09-11 23:26:19,404 [callbacks.py:12] INFO For batch 237/312, loss is  196.21.
2019-09-11 23:26:19,851 [callbacks.py:12] INFO For batch 238/312, loss is  206.94.
2019-09-11 23:26:20,388 [callbacks.py:12] INFO For batch 239/312, loss is  212.37.
2019-09-11 23:26:20,834 [callbacks.py:12] INFO For batch 240/312, loss is  200.37.
2019-09-11 23:26:21,274 [callbacks.py:12] INFO For batch 241/312, loss is  208.92.
2019-09-11 23:26:21,668 [callbacks.py:12] INFO For batch 242/312, loss is  208.51.
2019-09-11 23:26:22,134 [callbacks.py:12] INFO For batch 243/312, loss is  211.27.
2019-09-11 23:26:22,583 [callbacks.py:12] INFO For batch 244/312, loss is  206.24.
2019-09-11 23:26:23,093 [callbacks.py:12] INFO For batch 245/312, loss is  205.25.
2019-09-11 23:26:23,515 [callbacks.py:12] INFO For batch 246/312, loss is  213.62.
2019-09-11 23:26:23,962 [callbacks.py:12] INFO For batch 247/312, loss is  209.26.
2019-09-11 23:26:24,456 [callbacks.py:12] INFO For batch 248/312, loss is  209.17.
2019-09-11 23:26:24,907 [callbacks.py:12] INFO For batch 249/312, loss is  202.06.
2019-09-11 23:26:25,369 [callbacks.py:12] INFO For batch 250/312, loss is  207.63.
2019-09-11 23:26:25,816 [callbacks.py:12] INFO For batch 251/312, loss is  199.30.
2019-09-11 23:26:26,288 [callbacks.py:12] INFO For batch 252/312, loss is  195.95.
2019-09-11 23:26:26,686 [callbacks.py:12] INFO For batch 253/312, loss is  213.58.
2019-09-11 23:26:27,150 [callbacks.py:12] INFO For batch 254/312, loss is  211.89.
2019-09-11 23:26:27,524 [callbacks.py:12] INFO For batch 255/312, loss is  208.72.
2019-09-11 23:26:28,027 [callbacks.py:12] INFO For batch 256/312, loss is  212.18.
2019-09-11 23:26:28,534 [callbacks.py:12] INFO For batch 257/312, loss is  202.73.
2019-09-11 23:26:28,942 [callbacks.py:12] INFO For batch 258/312, loss is  207.60.
2019-09-11 23:26:31,533 [callbacks.py:12] INFO For batch 259/312, loss is  192.03.
2019-09-11 23:26:31,886 [callbacks.py:12] INFO For batch 260/312, loss is  200.78.
2019-09-11 23:26:32,385 [callbacks.py:12] INFO For batch 261/312, loss is  203.46.
2019-09-11 23:26:32,778 [callbacks.py:12] INFO For batch 262/312, loss is  204.68.
2019-09-11 23:26:33,186 [callbacks.py:12] INFO For batch 263/312, loss is  201.85.
2019-09-11 23:26:33,656 [callbacks.py:12] INFO For batch 264/312, loss is  210.22.
2019-09-11 23:26:34,130 [callbacks.py:12] INFO For batch 265/312, loss is  205.34.
2019-09-11 23:26:34,569 [callbacks.py:12] INFO For batch 266/312, loss is  206.17.
2019-09-11 23:26:34,963 [callbacks.py:12] INFO For batch 267/312, loss is  196.61.
2019-09-11 23:26:35,377 [callbacks.py:12] INFO For batch 268/312, loss is  200.30.
2019-09-11 23:26:35,802 [callbacks.py:12] INFO For batch 269/312, loss is  202.75.
2019-09-11 23:26:36,247 [callbacks.py:12] INFO For batch 270/312, loss is  201.19.
2019-09-11 23:26:36,623 [callbacks.py:12] INFO For batch 271/312, loss is  201.87.
2019-09-11 23:26:37,038 [callbacks.py:12] INFO For batch 272/312, loss is  196.14.
2019-09-11 23:26:37,531 [callbacks.py:12] INFO For batch 273/312, loss is  202.61.
2019-09-11 23:26:37,928 [callbacks.py:12] INFO For batch 274/312, loss is  205.06.
2019-09-11 23:26:38,359 [callbacks.py:12] INFO For batch 275/312, loss is  211.24.
2019-09-11 23:26:38,785 [callbacks.py:12] INFO For batch 276/312, loss is  202.77.
2019-09-11 23:26:39,190 [callbacks.py:12] INFO For batch 277/312, loss is  207.54.
2019-09-11 23:26:39,642 [callbacks.py:12] INFO For batch 278/312, loss is  201.66.
2019-09-11 23:26:40,053 [callbacks.py:12] INFO For batch 279/312, loss is  211.30.
2019-09-11 23:26:40,507 [callbacks.py:12] INFO For batch 280/312, loss is  207.97.
2019-09-11 23:26:40,914 [callbacks.py:12] INFO For batch 281/312, loss is  208.77.
2019-09-11 23:26:41,411 [callbacks.py:12] INFO For batch 282/312, loss is  193.75.
2019-09-11 23:26:41,822 [callbacks.py:12] INFO For batch 283/312, loss is  206.66.
2019-09-11 23:26:42,279 [callbacks.py:12] INFO For batch 284/312, loss is  205.20.
2019-09-11 23:26:42,741 [callbacks.py:12] INFO For batch 285/312, loss is  199.09.
2019-09-11 23:26:43,211 [callbacks.py:12] INFO For batch 286/312, loss is  201.13.
2019-09-11 23:26:43,603 [callbacks.py:12] INFO For batch 287/312, loss is  204.65.
2019-09-11 23:26:44,060 [callbacks.py:12] INFO For batch 288/312, loss is  198.34.
2019-09-11 23:26:44,478 [callbacks.py:12] INFO For batch 289/312, loss is  208.60.
2019-09-11 23:26:44,872 [callbacks.py:12] INFO For batch 290/312, loss is  205.76.
2019-09-11 23:26:45,276 [callbacks.py:12] INFO For batch 291/312, loss is  201.98.
2019-09-11 23:26:45,803 [callbacks.py:12] INFO For batch 292/312, loss is  205.02.
2019-09-11 23:26:46,186 [callbacks.py:12] INFO For batch 293/312, loss is  206.51.
2019-09-11 23:26:46,625 [callbacks.py:12] INFO For batch 294/312, loss is  212.14.
2019-09-11 23:26:47,033 [callbacks.py:12] INFO For batch 295/312, loss is  198.23.
2019-09-11 23:26:47,508 [callbacks.py:12] INFO For batch 296/312, loss is  208.60.
2019-09-11 23:26:48,006 [callbacks.py:12] INFO For batch 297/312, loss is  198.05.
2019-09-11 23:26:48,403 [callbacks.py:12] INFO For batch 298/312, loss is  205.46.
2019-09-11 23:26:48,843 [callbacks.py:12] INFO For batch 299/312, loss is  206.16.
2019-09-11 23:26:49,292 [callbacks.py:12] INFO For batch 300/312, loss is  205.34.
2019-09-11 23:26:49,695 [callbacks.py:12] INFO For batch 301/312, loss is  203.53.
2019-09-11 23:26:50,093 [callbacks.py:12] INFO For batch 302/312, loss is  203.79.
2019-09-11 23:26:50,459 [callbacks.py:12] INFO For batch 303/312, loss is  199.48.
2019-09-11 23:26:51,001 [callbacks.py:12] INFO For batch 304/312, loss is  194.33.
2019-09-11 23:26:51,501 [callbacks.py:12] INFO For batch 305/312, loss is  206.06.
2019-09-11 23:26:51,901 [callbacks.py:12] INFO For batch 306/312, loss is  204.76.
2019-09-11 23:26:52,335 [callbacks.py:12] INFO For batch 307/312, loss is  190.27.
2019-09-11 23:26:52,788 [callbacks.py:12] INFO For batch 308/312, loss is  197.67.
2019-09-11 23:26:53,208 [callbacks.py:12] INFO For batch 309/312, loss is  202.66.
2019-09-11 23:26:53,661 [callbacks.py:12] INFO For batch 310/312, loss is  196.63.
2019-09-11 23:26:54,052 [callbacks.py:12] INFO For batch 311/312, loss is  194.09.
2019-09-11 23:26:54,536 [callbacks.py:15] INFO For batch 0, validation loss is  214.26.
2019-09-11 23:26:54,721 [callbacks.py:15] INFO For batch 1, validation loss is  214.26.
2019-09-11 23:26:54,916 [callbacks.py:15] INFO For batch 2, validation loss is  214.26.
2019-09-11 23:26:55,104 [callbacks.py:15] INFO For batch 3, validation loss is  214.26.
2019-09-11 23:26:55,293 [callbacks.py:15] INFO For batch 4, validation loss is  214.26.
2019-09-11 23:26:55,487 [callbacks.py:15] INFO For batch 5, validation loss is  214.26.
2019-09-11 23:26:55,677 [callbacks.py:15] INFO For batch 6, validation loss is  214.26.
2019-09-11 23:26:55,978 [callbacks.py:15] INFO For batch 7, validation loss is  214.26.
2019-09-11 23:26:56,225 [callbacks.py:15] INFO For batch 8, validation loss is  230.94.
2019-09-11 23:26:56,451 [callbacks.py:15] INFO For batch 9, validation loss is  230.94.
2019-09-11 23:26:56,688 [callbacks.py:15] INFO For batch 10, validation loss is  230.94.
2019-09-11 23:26:56,882 [callbacks.py:15] INFO For batch 11, validation loss is  230.94.
2019-09-11 23:26:57,081 [callbacks.py:15] INFO For batch 12, validation loss is  230.94.
2019-09-11 23:26:57,288 [callbacks.py:15] INFO For batch 13, validation loss is  230.94.
2019-09-11 23:26:57,490 [callbacks.py:15] INFO For batch 14, validation loss is  230.94.
2019-09-11 23:26:57,700 [callbacks.py:15] INFO For batch 15, validation loss is  230.94.
2019-09-11 23:26:57,907 [callbacks.py:15] INFO For batch 16, validation loss is  234.28.
2019-09-11 23:26:58,111 [callbacks.py:15] INFO For batch 17, validation loss is  234.28.
2019-09-11 23:26:58,310 [callbacks.py:15] INFO For batch 18, validation loss is  234.28.
2019-09-11 23:26:58,528 [callbacks.py:15] INFO For batch 19, validation loss is  234.28.
2019-09-11 23:26:58,726 [callbacks.py:15] INFO For batch 20, validation loss is  234.28.
2019-09-11 23:26:58,922 [callbacks.py:15] INFO For batch 21, validation loss is  234.28.
2019-09-11 23:26:59,123 [callbacks.py:15] INFO For batch 22, validation loss is  234.28.
2019-09-11 23:26:59,316 [callbacks.py:15] INFO For batch 23, validation loss is  234.28.
2019-09-11 23:26:59,527 [callbacks.py:15] INFO For batch 24, validation loss is  218.69.
2019-09-11 23:26:59,749 [callbacks.py:15] INFO For batch 25, validation loss is  218.69.
2019-09-11 23:26:59,951 [callbacks.py:15] INFO For batch 26, validation loss is  218.69.
2019-09-11 23:26:59,952 [callbacks.py:19] INFO The validation average loss is  225.63.
2019-09-11 23:27:02,090 [callbacks.py:23] INFO The average loss for epoch 0 is  215.20.
2019-09-11 23:27:02,376 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:296: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
2019-09-11 23:27:02,389 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:141: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
2019-09-11 23:27:03,516 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:220: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv1d instead.
2019-09-11 23:27:03,597 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:317: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:28:16,212 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=1, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 23:28:24,888 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 23:28:28,193 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 23:28:28,258 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 23:28:28,258 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 23:28:28,258 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 23:28:28,258 [layer_utils.py:109] INFO =================================================================
2019-09-11 23:28:28,258 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 23:28:28,259 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,259 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 23:28:28,259 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,259 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 23:28:28,259 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,260 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 23:28:28,260 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,260 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 23:28:28,260 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,260 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 23:28:28,260 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,261 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 23:28:28,261 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,261 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 23:28:28,261 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,261 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 23:28:28,261 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,262 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 23:28:28,262 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,262 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 23:28:28,262 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,262 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 23:28:28,262 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,262 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 23:28:28,263 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,263 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 23:28:28,263 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,263 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 23:28:28,264 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,264 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 23:28:28,264 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,264 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:28:28,264 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,264 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 23:28:28,264 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,265 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:28:28,265 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,265 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 23:28:28,265 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,265 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:28:28,265 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,266 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 23:28:28,266 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,266 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 23:28:28,266 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,266 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 23:28:28,266 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,267 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 23:28:28,267 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,267 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 23:28:28,267 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,267 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 23:28:28,267 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,268 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 23:28:28,268 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:28:28,268 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 23:28:28,268 [layer_utils.py:169] INFO =================================================================
2019-09-11 23:28:28,269 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 23:28:28,269 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 23:28:28,269 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 23:28:28,269 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 23:28:28,421 [train.py:84] INFO # of samples: 10000
2019-09-11 23:28:28,422 [train.py:85] INFO mini-batch size: 32
2019-09-11 23:28:28,422 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 23:28:28,459 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:28:28,530 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 23:28:42,146 [callbacks.py:12] INFO For batch 0/312, loss is  781.63.
2019-09-11 23:28:44,720 [callbacks.py:12] INFO For batch 1/312, loss is  389.07.
2019-09-11 23:28:47,555 [callbacks.py:12] INFO For batch 2/312, loss is  394.26.
2019-09-11 23:28:50,412 [callbacks.py:12] INFO For batch 3/312, loss is  414.05.
2019-09-11 23:28:53,160 [callbacks.py:12] INFO For batch 4/312, loss is  284.26.
2019-09-11 23:28:56,354 [callbacks.py:12] INFO For batch 5/312, loss is  286.77.
2019-09-11 23:28:59,005 [callbacks.py:12] INFO For batch 6/312, loss is  301.85.
2019-09-11 23:29:01,742 [callbacks.py:12] INFO For batch 7/312, loss is  257.52.
2019-09-11 23:29:02,223 [callbacks.py:12] INFO For batch 8/312, loss is  249.36.
2019-09-11 23:29:04,752 [callbacks.py:12] INFO For batch 9/312, loss is  260.09.
2019-09-11 23:29:07,593 [callbacks.py:12] INFO For batch 10/312, loss is  250.73.
2019-09-11 23:29:08,059 [callbacks.py:12] INFO For batch 11/312, loss is  232.78.
2019-09-11 23:29:10,730 [callbacks.py:12] INFO For batch 12/312, loss is  239.28.
2019-09-11 23:29:13,296 [callbacks.py:12] INFO For batch 13/312, loss is  233.07.
2019-09-11 23:29:16,474 [callbacks.py:12] INFO For batch 14/312, loss is  242.61.
2019-09-11 23:29:19,885 [callbacks.py:12] INFO For batch 15/312, loss is  247.02.
2019-09-11 23:29:20,369 [callbacks.py:12] INFO For batch 16/312, loss is  229.05.
2019-09-11 23:29:23,214 [callbacks.py:12] INFO For batch 17/312, loss is  226.97.
2019-09-11 23:29:25,856 [callbacks.py:12] INFO For batch 18/312, loss is  219.56.
2019-09-11 23:29:29,111 [callbacks.py:12] INFO For batch 19/312, loss is  225.15.
2019-09-11 23:29:31,991 [callbacks.py:12] INFO For batch 20/312, loss is  225.81.
2019-09-11 23:29:34,785 [callbacks.py:12] INFO For batch 21/312, loss is  222.02.
2019-09-11 23:29:35,367 [callbacks.py:12] INFO For batch 22/312, loss is  230.18.
2019-09-11 23:29:38,248 [callbacks.py:12] INFO For batch 23/312, loss is  222.27.
2019-09-11 23:29:41,053 [callbacks.py:12] INFO For batch 24/312, loss is  222.60.
2019-09-11 23:29:43,757 [callbacks.py:12] INFO For batch 25/312, loss is  223.22.
2019-09-11 23:29:46,375 [callbacks.py:12] INFO For batch 26/312, loss is  217.72.
2019-09-11 23:29:49,684 [callbacks.py:12] INFO For batch 27/312, loss is  222.24.
2019-09-11 23:29:52,516 [callbacks.py:12] INFO For batch 28/312, loss is  226.58.
2019-09-11 23:29:55,426 [callbacks.py:12] INFO For batch 29/312, loss is  225.44.
2019-09-11 23:29:58,140 [callbacks.py:12] INFO For batch 30/312, loss is  215.28.
2019-09-11 23:29:58,652 [callbacks.py:12] INFO For batch 31/312, loss is  209.68.
2019-09-11 23:30:01,569 [callbacks.py:12] INFO For batch 32/312, loss is  223.35.
2019-09-11 23:30:04,679 [callbacks.py:12] INFO For batch 33/312, loss is  224.94.
2019-09-11 23:30:05,113 [callbacks.py:12] INFO For batch 34/312, loss is  221.83.
2019-09-11 23:30:08,042 [callbacks.py:12] INFO For batch 35/312, loss is  207.47.
2019-09-11 23:30:10,540 [callbacks.py:12] INFO For batch 36/312, loss is  211.07.
2019-09-11 23:30:10,923 [callbacks.py:12] INFO For batch 37/312, loss is  220.42.
2019-09-11 23:30:11,307 [callbacks.py:12] INFO For batch 38/312, loss is  211.61.
2019-09-11 23:30:11,694 [callbacks.py:12] INFO For batch 39/312, loss is  210.19.
2019-09-11 23:30:12,116 [callbacks.py:12] INFO For batch 40/312, loss is  216.62.
2019-09-11 23:30:12,629 [callbacks.py:12] INFO For batch 41/312, loss is  213.06.
2019-09-11 23:30:15,374 [callbacks.py:12] INFO For batch 42/312, loss is  212.91.
2019-09-11 23:30:15,903 [callbacks.py:12] INFO For batch 43/312, loss is  212.23.
2019-09-11 23:30:16,313 [callbacks.py:12] INFO For batch 44/312, loss is  215.93.
2019-09-11 23:30:19,551 [callbacks.py:12] INFO For batch 45/312, loss is  218.20.
2019-09-11 23:30:22,308 [callbacks.py:12] INFO For batch 46/312, loss is  216.23.
2019-09-11 23:30:22,785 [callbacks.py:12] INFO For batch 47/312, loss is  218.43.
2019-09-11 23:30:23,255 [callbacks.py:12] INFO For batch 48/312, loss is  215.42.
2019-09-11 23:30:23,755 [callbacks.py:12] INFO For batch 49/312, loss is  209.18.
2019-09-11 23:30:24,296 [callbacks.py:12] INFO For batch 50/312, loss is  205.58.
2019-09-11 23:30:24,843 [callbacks.py:12] INFO For batch 51/312, loss is  216.89.
2019-09-11 23:30:25,318 [callbacks.py:12] INFO For batch 52/312, loss is  210.65.
2019-09-11 23:30:25,797 [callbacks.py:12] INFO For batch 53/312, loss is  214.97.
2019-09-11 23:30:26,244 [callbacks.py:12] INFO For batch 54/312, loss is  213.64.
2019-09-11 23:30:26,755 [callbacks.py:12] INFO For batch 55/312, loss is  216.04.
2019-09-11 23:30:27,153 [callbacks.py:12] INFO For batch 56/312, loss is  207.35.
2019-09-11 23:30:30,150 [callbacks.py:12] INFO For batch 57/312, loss is  208.93.
2019-09-11 23:30:30,605 [callbacks.py:12] INFO For batch 58/312, loss is  213.88.
2019-09-11 23:30:31,061 [callbacks.py:12] INFO For batch 59/312, loss is  210.56.
2019-09-11 23:30:33,734 [callbacks.py:12] INFO For batch 60/312, loss is  206.67.
2019-09-11 23:30:36,841 [callbacks.py:12] INFO For batch 61/312, loss is  217.03.
2019-09-11 23:30:37,271 [callbacks.py:12] INFO For batch 62/312, loss is  205.39.
2019-09-11 23:30:39,760 [callbacks.py:12] INFO For batch 63/312, loss is  211.06.
2019-09-11 23:30:42,322 [callbacks.py:12] INFO For batch 64/312, loss is  213.21.
2019-09-11 23:30:42,726 [callbacks.py:12] INFO For batch 65/312, loss is  204.16.
2019-09-11 23:30:43,108 [callbacks.py:12] INFO For batch 66/312, loss is  203.40.
2019-09-11 23:30:43,507 [callbacks.py:12] INFO For batch 67/312, loss is  198.15.
2019-09-11 23:30:43,991 [callbacks.py:12] INFO For batch 68/312, loss is  206.32.
2019-09-11 23:30:44,463 [callbacks.py:12] INFO For batch 69/312, loss is  206.13.
2019-09-11 23:30:44,946 [callbacks.py:12] INFO For batch 70/312, loss is  214.29.
2019-09-11 23:30:45,344 [callbacks.py:12] INFO For batch 71/312, loss is  210.61.
2019-09-11 23:30:48,487 [callbacks.py:12] INFO For batch 72/312, loss is  212.05.
2019-09-11 23:30:48,986 [callbacks.py:12] INFO For batch 73/312, loss is  206.87.
2019-09-11 23:30:51,894 [callbacks.py:12] INFO For batch 74/312, loss is  210.49.
2019-09-11 23:30:52,373 [callbacks.py:12] INFO For batch 75/312, loss is  207.80.
2019-09-11 23:30:52,880 [callbacks.py:12] INFO For batch 76/312, loss is  211.93.
2019-09-11 23:30:53,268 [callbacks.py:12] INFO For batch 77/312, loss is  200.06.
2019-09-11 23:30:53,700 [callbacks.py:12] INFO For batch 78/312, loss is  212.81.
2019-09-11 23:30:54,137 [callbacks.py:12] INFO For batch 79/312, loss is  203.69.
2019-09-11 23:30:54,635 [callbacks.py:12] INFO For batch 80/312, loss is  204.45.
2019-09-11 23:30:55,049 [callbacks.py:12] INFO For batch 81/312, loss is  210.41.
2019-09-11 23:30:55,468 [callbacks.py:12] INFO For batch 82/312, loss is  216.09.
2019-09-11 23:30:55,885 [callbacks.py:12] INFO For batch 83/312, loss is  208.96.
2019-09-11 23:30:56,379 [callbacks.py:12] INFO For batch 84/312, loss is  213.60.
2019-09-11 23:30:56,784 [callbacks.py:12] INFO For batch 85/312, loss is  198.68.
2019-09-11 23:30:59,496 [callbacks.py:12] INFO For batch 86/312, loss is  212.06.
2019-09-11 23:30:59,985 [callbacks.py:12] INFO For batch 87/312, loss is  218.03.
2019-09-11 23:31:00,438 [callbacks.py:12] INFO For batch 88/312, loss is  207.84.
2019-09-11 23:31:00,944 [callbacks.py:12] INFO For batch 89/312, loss is  205.50.
2019-09-11 23:31:01,449 [callbacks.py:12] INFO For batch 90/312, loss is  213.85.
2019-09-11 23:31:01,916 [callbacks.py:12] INFO For batch 91/312, loss is  199.30.
2019-09-11 23:31:02,322 [callbacks.py:12] INFO For batch 92/312, loss is  198.18.
2019-09-11 23:31:02,742 [callbacks.py:12] INFO For batch 93/312, loss is  201.65.
2019-09-11 23:31:05,777 [callbacks.py:12] INFO For batch 94/312, loss is  217.67.
2019-09-11 23:31:06,203 [callbacks.py:12] INFO For batch 95/312, loss is  209.74.
2019-09-11 23:31:06,610 [callbacks.py:12] INFO For batch 96/312, loss is  209.51.
2019-09-11 23:31:07,018 [callbacks.py:12] INFO For batch 97/312, loss is  202.68.
2019-09-11 23:31:07,394 [callbacks.py:12] INFO For batch 98/312, loss is  205.89.
2019-09-11 23:31:08,119 [callbacks.py:12] INFO For batch 99/312, loss is  204.67.
2019-09-11 23:31:08,719 [callbacks.py:12] INFO For batch 100/312, loss is  210.26.
2019-09-11 23:31:09,214 [callbacks.py:12] INFO For batch 101/312, loss is  210.42.
2019-09-11 23:31:09,652 [callbacks.py:12] INFO For batch 102/312, loss is  205.93.
2019-09-11 23:31:10,113 [callbacks.py:12] INFO For batch 103/312, loss is  209.72.
2019-09-11 23:31:12,663 [callbacks.py:12] INFO For batch 104/312, loss is  205.69.
2019-09-11 23:31:13,164 [callbacks.py:12] INFO For batch 105/312, loss is  214.08.
2019-09-11 23:31:13,631 [callbacks.py:12] INFO For batch 106/312, loss is  210.97.
2019-09-11 23:31:16,681 [callbacks.py:12] INFO For batch 107/312, loss is  214.23.
2019-09-11 23:31:17,208 [callbacks.py:12] INFO For batch 108/312, loss is  220.79.
2019-09-11 23:31:17,616 [callbacks.py:12] INFO For batch 109/312, loss is  202.00.
2019-09-11 23:31:18,035 [callbacks.py:12] INFO For batch 110/312, loss is  210.16.
2019-09-11 23:31:20,710 [callbacks.py:12] INFO For batch 111/312, loss is  201.86.
2019-09-11 23:31:21,082 [callbacks.py:12] INFO For batch 112/312, loss is  207.13.
2019-09-11 23:31:21,560 [callbacks.py:12] INFO For batch 113/312, loss is  219.83.
2019-09-11 23:31:21,965 [callbacks.py:12] INFO For batch 114/312, loss is  202.85.
2019-09-11 23:31:22,533 [callbacks.py:12] INFO For batch 115/312, loss is  214.48.
2019-09-11 23:31:22,902 [callbacks.py:12] INFO For batch 116/312, loss is  206.79.
2019-09-11 23:31:23,324 [callbacks.py:12] INFO For batch 117/312, loss is  200.67.
2019-09-11 23:31:23,928 [callbacks.py:12] INFO For batch 118/312, loss is  207.44.
2019-09-11 23:31:27,047 [callbacks.py:12] INFO For batch 119/312, loss is  208.45.
2019-09-11 23:31:27,462 [callbacks.py:12] INFO For batch 120/312, loss is  209.40.
2019-09-11 23:31:27,835 [callbacks.py:12] INFO For batch 121/312, loss is  207.00.
2019-09-11 23:31:28,336 [callbacks.py:12] INFO For batch 122/312, loss is  211.69.
2019-09-11 23:31:28,803 [callbacks.py:12] INFO For batch 123/312, loss is  211.33.
2019-09-11 23:31:29,189 [callbacks.py:12] INFO For batch 124/312, loss is  210.07.
2019-09-11 23:31:29,674 [callbacks.py:12] INFO For batch 125/312, loss is  217.88.
2019-09-11 23:31:30,067 [callbacks.py:12] INFO For batch 126/312, loss is  214.62.
2019-09-11 23:31:30,421 [callbacks.py:12] INFO For batch 127/312, loss is  206.22.
2019-09-11 23:31:30,986 [callbacks.py:12] INFO For batch 128/312, loss is  203.27.
2019-09-11 23:31:33,624 [callbacks.py:12] INFO For batch 129/312, loss is  201.55.
2019-09-11 23:31:34,093 [callbacks.py:12] INFO For batch 130/312, loss is  205.18.
2019-09-11 23:31:34,496 [callbacks.py:12] INFO For batch 131/312, loss is  215.20.
2019-09-11 23:31:34,940 [callbacks.py:12] INFO For batch 132/312, loss is  209.21.
2019-09-11 23:31:35,370 [callbacks.py:12] INFO For batch 133/312, loss is  211.84.
2019-09-11 23:31:35,743 [callbacks.py:12] INFO For batch 134/312, loss is  210.93.
2019-09-11 23:31:36,138 [callbacks.py:12] INFO For batch 135/312, loss is  205.64.
2019-09-11 23:31:36,682 [callbacks.py:12] INFO For batch 136/312, loss is  209.80.
2019-09-11 23:31:37,064 [callbacks.py:12] INFO For batch 137/312, loss is  204.70.
2019-09-11 23:31:37,449 [callbacks.py:12] INFO For batch 138/312, loss is  206.71.
2019-09-11 23:31:38,027 [callbacks.py:12] INFO For batch 139/312, loss is  207.82.
2019-09-11 23:31:38,395 [callbacks.py:12] INFO For batch 140/312, loss is  205.84.
2019-09-11 23:31:38,908 [callbacks.py:12] INFO For batch 141/312, loss is  215.89.
2019-09-11 23:31:39,314 [callbacks.py:12] INFO For batch 142/312, loss is  198.39.
2019-09-11 23:31:39,720 [callbacks.py:12] INFO For batch 143/312, loss is  204.44.
2019-09-11 23:31:40,284 [callbacks.py:12] INFO For batch 144/312, loss is  207.25.
2019-09-11 23:31:40,716 [callbacks.py:12] INFO For batch 145/312, loss is  206.41.
2019-09-11 23:31:41,108 [callbacks.py:12] INFO For batch 146/312, loss is  200.67.
2019-09-11 23:31:41,578 [callbacks.py:12] INFO For batch 147/312, loss is  214.37.
2019-09-11 23:31:42,031 [callbacks.py:12] INFO For batch 148/312, loss is  211.45.
2019-09-11 23:31:42,511 [callbacks.py:12] INFO For batch 149/312, loss is  205.26.
2019-09-11 23:31:42,943 [callbacks.py:12] INFO For batch 150/312, loss is  208.48.
2019-09-11 23:31:43,421 [callbacks.py:12] INFO For batch 151/312, loss is  204.61.
2019-09-11 23:31:46,622 [callbacks.py:12] INFO For batch 152/312, loss is  214.54.
2019-09-11 23:31:47,012 [callbacks.py:12] INFO For batch 153/312, loss is  207.86.
2019-09-11 23:31:47,407 [callbacks.py:12] INFO For batch 154/312, loss is  209.97.
2019-09-11 23:31:47,771 [callbacks.py:12] INFO For batch 155/312, loss is  209.93.
2019-09-11 23:31:48,182 [callbacks.py:12] INFO For batch 156/312, loss is  204.43.
2019-09-11 23:31:48,749 [callbacks.py:12] INFO For batch 157/312, loss is  216.16.
2019-09-11 23:31:49,233 [callbacks.py:12] INFO For batch 158/312, loss is  214.27.
2019-09-11 23:31:49,633 [callbacks.py:12] INFO For batch 159/312, loss is  212.34.
2019-09-11 23:31:50,106 [callbacks.py:12] INFO For batch 160/312, loss is  214.66.
2019-09-11 23:31:50,523 [callbacks.py:12] INFO For batch 161/312, loss is  204.39.
2019-09-11 23:31:51,043 [callbacks.py:12] INFO For batch 162/312, loss is  205.57.
2019-09-11 23:31:51,483 [callbacks.py:12] INFO For batch 163/312, loss is  207.82.
2019-09-11 23:31:51,930 [callbacks.py:12] INFO For batch 164/312, loss is  203.01.
2019-09-11 23:31:52,316 [callbacks.py:12] INFO For batch 165/312, loss is  204.09.
2019-09-11 23:31:52,734 [callbacks.py:12] INFO For batch 166/312, loss is  210.20.
2019-09-11 23:31:53,291 [callbacks.py:12] INFO For batch 167/312, loss is  211.53.
2019-09-11 23:31:53,677 [callbacks.py:12] INFO For batch 168/312, loss is  204.89.
2019-09-11 23:31:54,124 [callbacks.py:12] INFO For batch 169/312, loss is  212.00.
2019-09-11 23:31:54,577 [callbacks.py:12] INFO For batch 170/312, loss is  211.51.
2019-09-11 23:31:54,973 [callbacks.py:12] INFO For batch 171/312, loss is  209.39.
2019-09-11 23:31:55,361 [callbacks.py:12] INFO For batch 172/312, loss is  213.91.
2019-09-11 23:31:55,820 [callbacks.py:12] INFO For batch 173/312, loss is  208.76.
2019-09-11 23:31:56,347 [callbacks.py:12] INFO For batch 174/312, loss is  207.54.
2019-09-11 23:31:56,962 [callbacks.py:12] INFO For batch 175/312, loss is  216.23.
2019-09-11 23:31:59,571 [callbacks.py:12] INFO For batch 176/312, loss is  201.55.
2019-09-11 23:31:59,964 [callbacks.py:12] INFO For batch 177/312, loss is  194.98.
2019-09-11 23:32:00,369 [callbacks.py:12] INFO For batch 178/312, loss is  210.32.
2019-09-11 23:32:00,790 [callbacks.py:12] INFO For batch 179/312, loss is  208.26.
2019-09-11 23:32:01,263 [callbacks.py:12] INFO For batch 180/312, loss is  196.62.
2019-09-11 23:32:01,696 [callbacks.py:12] INFO For batch 181/312, loss is  209.03.
2019-09-11 23:32:02,242 [callbacks.py:12] INFO For batch 182/312, loss is  209.05.
2019-09-11 23:32:02,706 [callbacks.py:12] INFO For batch 183/312, loss is  211.89.
2019-09-11 23:32:05,414 [callbacks.py:12] INFO For batch 184/312, loss is  207.89.
2019-09-11 23:32:05,794 [callbacks.py:12] INFO For batch 185/312, loss is  210.06.
2019-09-11 23:32:06,200 [callbacks.py:12] INFO For batch 186/312, loss is  220.68.
2019-09-11 23:32:06,640 [callbacks.py:12] INFO For batch 187/312, loss is  209.75.
2019-09-11 23:32:07,162 [callbacks.py:12] INFO For batch 188/312, loss is  208.93.
2019-09-11 23:32:07,699 [callbacks.py:12] INFO For batch 189/312, loss is  207.53.
2019-09-11 23:32:08,187 [callbacks.py:12] INFO For batch 190/312, loss is  209.44.
2019-09-11 23:32:08,676 [callbacks.py:12] INFO For batch 191/312, loss is  211.26.
2019-09-11 23:32:09,190 [callbacks.py:12] INFO For batch 192/312, loss is  213.61.
2019-09-11 23:32:09,614 [callbacks.py:12] INFO For batch 193/312, loss is  209.40.
2019-09-11 23:32:10,035 [callbacks.py:12] INFO For batch 194/312, loss is  206.87.
2019-09-11 23:32:10,447 [callbacks.py:12] INFO For batch 195/312, loss is  197.25.
2019-09-11 23:32:10,891 [callbacks.py:12] INFO For batch 196/312, loss is  217.63.
2019-09-11 23:32:11,325 [callbacks.py:12] INFO For batch 197/312, loss is  207.08.
2019-09-11 23:32:14,309 [callbacks.py:12] INFO For batch 198/312, loss is  217.97.
2019-09-11 23:32:14,767 [callbacks.py:12] INFO For batch 199/312, loss is  212.22.
2019-09-11 23:32:15,232 [callbacks.py:12] INFO For batch 200/312, loss is  200.59.
2019-09-11 23:32:15,722 [callbacks.py:12] INFO For batch 201/312, loss is  218.37.
2019-09-11 23:32:16,130 [callbacks.py:12] INFO For batch 202/312, loss is  212.89.
2019-09-11 23:32:16,547 [callbacks.py:12] INFO For batch 203/312, loss is  203.07.
2019-09-11 23:32:17,073 [callbacks.py:12] INFO For batch 204/312, loss is  215.32.
2019-09-11 23:32:17,500 [callbacks.py:12] INFO For batch 205/312, loss is  206.70.
2019-09-11 23:32:17,950 [callbacks.py:12] INFO For batch 206/312, loss is  199.60.
2019-09-11 23:32:18,359 [callbacks.py:12] INFO For batch 207/312, loss is  207.61.
2019-09-11 23:32:18,874 [callbacks.py:12] INFO For batch 208/312, loss is  211.79.
2019-09-11 23:32:19,266 [callbacks.py:12] INFO For batch 209/312, loss is  208.90.
2019-09-11 23:32:19,630 [callbacks.py:12] INFO For batch 210/312, loss is  201.04.
2019-09-11 23:32:20,046 [callbacks.py:12] INFO For batch 211/312, loss is  209.54.
2019-09-11 23:32:20,501 [callbacks.py:12] INFO For batch 212/312, loss is  216.06.
2019-09-11 23:32:20,933 [callbacks.py:12] INFO For batch 213/312, loss is  208.11.
2019-09-11 23:32:21,505 [callbacks.py:12] INFO For batch 214/312, loss is  206.18.
2019-09-11 23:32:21,983 [callbacks.py:12] INFO For batch 215/312, loss is  212.14.
2019-09-11 23:32:22,343 [callbacks.py:12] INFO For batch 216/312, loss is  198.37.
2019-09-11 23:32:22,846 [callbacks.py:12] INFO For batch 217/312, loss is  213.27.
2019-09-11 23:32:23,294 [callbacks.py:12] INFO For batch 218/312, loss is  209.08.
2019-09-11 23:32:23,745 [callbacks.py:12] INFO For batch 219/312, loss is  203.58.
2019-09-11 23:32:24,192 [callbacks.py:12] INFO For batch 220/312, loss is  204.45.
2019-09-11 23:32:24,658 [callbacks.py:12] INFO For batch 221/312, loss is  200.88.
2019-09-11 23:32:25,079 [callbacks.py:12] INFO For batch 222/312, loss is  205.12.
2019-09-11 23:32:25,447 [callbacks.py:12] INFO For batch 223/312, loss is  207.39.
2019-09-11 23:32:25,940 [callbacks.py:12] INFO For batch 224/312, loss is  196.22.
2019-09-11 23:32:26,442 [callbacks.py:12] INFO For batch 225/312, loss is  203.21.
2019-09-11 23:32:27,004 [callbacks.py:12] INFO For batch 226/312, loss is  211.58.
2019-09-11 23:32:29,713 [callbacks.py:12] INFO For batch 227/312, loss is  211.44.
2019-09-11 23:32:30,127 [callbacks.py:12] INFO For batch 228/312, loss is  201.99.
2019-09-11 23:32:30,545 [callbacks.py:12] INFO For batch 229/312, loss is  207.63.
2019-09-11 23:32:33,119 [callbacks.py:12] INFO For batch 230/312, loss is  200.19.
2019-09-11 23:32:33,637 [callbacks.py:12] INFO For batch 231/312, loss is  202.78.
2019-09-11 23:32:34,010 [callbacks.py:12] INFO For batch 232/312, loss is  202.22.
2019-09-11 23:32:34,438 [callbacks.py:12] INFO For batch 233/312, loss is  201.58.
2019-09-11 23:32:34,993 [callbacks.py:12] INFO For batch 234/312, loss is  212.51.
2019-09-11 23:32:35,461 [callbacks.py:12] INFO For batch 235/312, loss is  211.23.
2019-09-11 23:32:35,874 [callbacks.py:12] INFO For batch 236/312, loss is  204.74.
2019-09-11 23:32:36,310 [callbacks.py:12] INFO For batch 237/312, loss is  199.10.
2019-09-11 23:32:36,767 [callbacks.py:12] INFO For batch 238/312, loss is  213.30.
2019-09-11 23:32:37,239 [callbacks.py:12] INFO For batch 239/312, loss is  207.19.
2019-09-11 23:32:37,690 [callbacks.py:12] INFO For batch 240/312, loss is  204.97.
2019-09-11 23:32:38,153 [callbacks.py:12] INFO For batch 241/312, loss is  215.13.
2019-09-11 23:32:38,525 [callbacks.py:12] INFO For batch 242/312, loss is  203.01.
2019-09-11 23:32:39,030 [callbacks.py:12] INFO For batch 243/312, loss is  203.01.
2019-09-11 23:32:39,525 [callbacks.py:12] INFO For batch 244/312, loss is  204.48.
2019-09-11 23:32:39,926 [callbacks.py:12] INFO For batch 245/312, loss is  208.64.
2019-09-11 23:32:40,320 [callbacks.py:12] INFO For batch 246/312, loss is  206.63.
2019-09-11 23:32:40,816 [callbacks.py:12] INFO For batch 247/312, loss is  209.79.
2019-09-11 23:32:41,361 [callbacks.py:12] INFO For batch 248/312, loss is  204.27.
2019-09-11 23:32:41,813 [callbacks.py:12] INFO For batch 249/312, loss is  214.14.
2019-09-11 23:32:42,170 [callbacks.py:12] INFO For batch 250/312, loss is  206.43.
2019-09-11 23:32:42,577 [callbacks.py:12] INFO For batch 251/312, loss is  206.63.
2019-09-11 23:32:43,075 [callbacks.py:12] INFO For batch 252/312, loss is  210.52.
2019-09-11 23:32:43,588 [callbacks.py:12] INFO For batch 253/312, loss is  210.23.
2019-09-11 23:32:43,990 [callbacks.py:12] INFO For batch 254/312, loss is  209.22.
2019-09-11 23:32:44,371 [callbacks.py:12] INFO For batch 255/312, loss is  207.95.
2019-09-11 23:32:44,944 [callbacks.py:12] INFO For batch 256/312, loss is  212.76.
2019-09-11 23:32:45,342 [callbacks.py:12] INFO For batch 257/312, loss is  202.05.
2019-09-11 23:32:45,747 [callbacks.py:12] INFO For batch 258/312, loss is  207.60.
2019-09-11 23:32:46,137 [callbacks.py:12] INFO For batch 259/312, loss is  201.38.
2019-09-11 23:32:46,582 [callbacks.py:12] INFO For batch 260/312, loss is  203.72.
2019-09-11 23:32:47,016 [callbacks.py:12] INFO For batch 261/312, loss is  214.11.
2019-09-11 23:32:47,472 [callbacks.py:12] INFO For batch 262/312, loss is  209.15.
2019-09-11 23:32:47,904 [callbacks.py:12] INFO For batch 263/312, loss is  206.67.
2019-09-11 23:32:48,392 [callbacks.py:12] INFO For batch 264/312, loss is  209.22.
2019-09-11 23:32:48,786 [callbacks.py:12] INFO For batch 265/312, loss is  199.20.
2019-09-11 23:32:49,246 [callbacks.py:12] INFO For batch 266/312, loss is  202.52.
2019-09-11 23:32:49,703 [callbacks.py:12] INFO For batch 267/312, loss is  203.12.
2019-09-11 23:32:50,101 [callbacks.py:12] INFO For batch 268/312, loss is  201.38.
2019-09-11 23:32:50,470 [callbacks.py:12] INFO For batch 269/312, loss is  201.25.
2019-09-11 23:32:50,938 [callbacks.py:12] INFO For batch 270/312, loss is  207.11.
2019-09-11 23:32:51,396 [callbacks.py:12] INFO For batch 271/312, loss is  201.89.
2019-09-11 23:32:51,866 [callbacks.py:12] INFO For batch 272/312, loss is  209.56.
2019-09-11 23:32:52,282 [callbacks.py:12] INFO For batch 273/312, loss is  196.51.
2019-09-11 23:32:52,708 [callbacks.py:12] INFO For batch 274/312, loss is  204.70.
2019-09-11 23:32:53,276 [callbacks.py:12] INFO For batch 275/312, loss is  213.87.
2019-09-11 23:32:53,672 [callbacks.py:12] INFO For batch 276/312, loss is  195.34.
2019-09-11 23:32:54,072 [callbacks.py:12] INFO For batch 277/312, loss is  210.78.
2019-09-11 23:32:54,476 [callbacks.py:12] INFO For batch 278/312, loss is  202.63.
2019-09-11 23:32:54,924 [callbacks.py:12] INFO For batch 279/312, loss is  209.09.
2019-09-11 23:32:55,445 [callbacks.py:12] INFO For batch 280/312, loss is  204.95.
2019-09-11 23:32:55,932 [callbacks.py:12] INFO For batch 281/312, loss is  199.72.
2019-09-11 23:32:56,314 [callbacks.py:12] INFO For batch 282/312, loss is  192.23.
2019-09-11 23:32:56,793 [callbacks.py:12] INFO For batch 283/312, loss is  199.74.
2019-09-11 23:32:57,291 [callbacks.py:12] INFO For batch 284/312, loss is  199.46.
2019-09-11 23:32:57,807 [callbacks.py:12] INFO For batch 285/312, loss is  208.11.
2019-09-11 23:32:58,247 [callbacks.py:12] INFO For batch 286/312, loss is  204.91.
2019-09-11 23:32:58,682 [callbacks.py:12] INFO For batch 287/312, loss is  206.13.
2019-09-11 23:32:59,128 [callbacks.py:12] INFO For batch 288/312, loss is  203.10.
2019-09-11 23:32:59,545 [callbacks.py:12] INFO For batch 289/312, loss is  208.53.
2019-09-11 23:33:00,034 [callbacks.py:12] INFO For batch 290/312, loss is  207.25.
2019-09-11 23:33:00,517 [callbacks.py:12] INFO For batch 291/312, loss is  209.03.
2019-09-11 23:33:00,922 [callbacks.py:12] INFO For batch 292/312, loss is  208.60.
2019-09-11 23:33:01,360 [callbacks.py:12] INFO For batch 293/312, loss is  212.91.
2019-09-11 23:33:01,779 [callbacks.py:12] INFO For batch 294/312, loss is  206.01.
2019-09-11 23:33:02,152 [callbacks.py:12] INFO For batch 295/312, loss is  211.23.
2019-09-11 23:33:02,701 [callbacks.py:12] INFO For batch 296/312, loss is  191.33.
2019-09-11 23:33:03,119 [callbacks.py:12] INFO For batch 297/312, loss is  206.35.
2019-09-11 23:33:03,511 [callbacks.py:12] INFO For batch 298/312, loss is  203.02.
2019-09-11 23:33:03,924 [callbacks.py:12] INFO For batch 299/312, loss is  200.47.
2019-09-11 23:33:04,398 [callbacks.py:12] INFO For batch 300/312, loss is  200.47.
2019-09-11 23:33:04,781 [callbacks.py:12] INFO For batch 301/312, loss is  203.63.
2019-09-11 23:33:05,238 [callbacks.py:12] INFO For batch 302/312, loss is  199.50.
2019-09-11 23:33:05,683 [callbacks.py:12] INFO For batch 303/312, loss is  193.09.
2019-09-11 23:33:06,274 [callbacks.py:12] INFO For batch 304/312, loss is  201.79.
2019-09-11 23:33:06,644 [callbacks.py:12] INFO For batch 305/312, loss is  197.07.
2019-09-11 23:33:07,105 [callbacks.py:12] INFO For batch 306/312, loss is  204.69.
2019-09-11 23:33:07,521 [callbacks.py:12] INFO For batch 307/312, loss is  202.15.
2019-09-11 23:33:07,969 [callbacks.py:12] INFO For batch 308/312, loss is  202.45.
2019-09-11 23:33:08,438 [callbacks.py:12] INFO For batch 309/312, loss is  206.09.
2019-09-11 23:33:08,824 [callbacks.py:12] INFO For batch 310/312, loss is  203.39.
2019-09-11 23:33:09,221 [callbacks.py:12] INFO For batch 311/312, loss is  202.01.
2019-09-11 23:33:09,743 [callbacks.py:15] INFO For batch 0, validation loss is  217.28.
2019-09-11 23:33:10,006 [callbacks.py:15] INFO For batch 1, validation loss is  217.28.
2019-09-11 23:33:10,381 [callbacks.py:15] INFO For batch 2, validation loss is  217.28.
2019-09-11 23:33:10,632 [callbacks.py:15] INFO For batch 3, validation loss is  217.28.
2019-09-11 23:33:10,935 [callbacks.py:15] INFO For batch 4, validation loss is  217.28.
2019-09-11 23:33:11,133 [callbacks.py:15] INFO For batch 5, validation loss is  217.28.
2019-09-11 23:33:11,376 [callbacks.py:15] INFO For batch 6, validation loss is  217.28.
2019-09-11 23:33:11,575 [callbacks.py:15] INFO For batch 7, validation loss is  217.28.
2019-09-11 23:33:11,851 [callbacks.py:15] INFO For batch 8, validation loss is  234.34.
2019-09-11 23:33:12,111 [callbacks.py:15] INFO For batch 9, validation loss is  234.34.
2019-09-11 23:33:12,325 [callbacks.py:15] INFO For batch 10, validation loss is  234.34.
2019-09-11 23:33:12,517 [callbacks.py:15] INFO For batch 11, validation loss is  234.34.
2019-09-11 23:33:12,727 [callbacks.py:15] INFO For batch 12, validation loss is  234.34.
2019-09-11 23:33:12,922 [callbacks.py:15] INFO For batch 13, validation loss is  234.34.
2019-09-11 23:33:13,117 [callbacks.py:15] INFO For batch 14, validation loss is  234.34.
2019-09-11 23:33:13,334 [callbacks.py:15] INFO For batch 15, validation loss is  234.34.
2019-09-11 23:33:13,541 [callbacks.py:15] INFO For batch 16, validation loss is  236.24.
2019-09-11 23:33:13,736 [callbacks.py:15] INFO For batch 17, validation loss is  236.24.
2019-09-11 23:33:13,895 [callbacks.py:15] INFO For batch 18, validation loss is  236.24.
2019-09-11 23:33:14,057 [callbacks.py:15] INFO For batch 19, validation loss is  236.24.
2019-09-11 23:33:14,231 [callbacks.py:15] INFO For batch 20, validation loss is  236.24.
2019-09-11 23:33:14,432 [callbacks.py:15] INFO For batch 21, validation loss is  236.24.
2019-09-11 23:33:14,635 [callbacks.py:15] INFO For batch 22, validation loss is  236.24.
2019-09-11 23:33:14,784 [callbacks.py:15] INFO For batch 23, validation loss is  236.24.
2019-09-11 23:33:15,040 [callbacks.py:15] INFO For batch 24, validation loss is  220.75.
2019-09-11 23:33:15,239 [callbacks.py:15] INFO For batch 25, validation loss is  220.75.
2019-09-11 23:33:15,390 [callbacks.py:15] INFO For batch 26, validation loss is  220.75.
2019-09-11 23:33:15,449 [callbacks.py:19] INFO The validation average loss is  228.34.
2019-09-11 23:33:17,527 [callbacks.py:23] INFO The average loss for epoch 0 is  214.28.
2019-09-11 23:33:17,847 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:296: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
2019-09-11 23:33:17,860 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:141: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
2019-09-11 23:33:19,054 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:220: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv1d instead.
2019-09-11 23:33:19,141 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:317: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:33:23,167 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2019-09-11 23:33:23,169 [saver.py:1270] INFO Restoring parameters from logs_lm/thchs30_model_1
2019-09-11 23:33:38,531 [train.py:147] INFO epochs: 1: average loss = 1.283295
2019-09-11 23:41:33,844 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=10, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 23:41:42,261 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 23:41:45,465 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 23:41:45,535 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 23:41:45,535 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 23:41:45,535 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 23:41:45,535 [layer_utils.py:109] INFO =================================================================
2019-09-11 23:41:45,535 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 23:41:45,535 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,535 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 23:41:45,536 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,536 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 23:41:45,536 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,536 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 23:41:45,536 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,536 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 23:41:45,537 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,537 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 23:41:45,537 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,537 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 23:41:45,537 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,537 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 23:41:45,538 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,538 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 23:41:45,538 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,538 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 23:41:45,538 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,538 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 23:41:45,538 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,539 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 23:41:45,539 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,539 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 23:41:45,539 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,539 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 23:41:45,539 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,540 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 23:41:45,540 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,540 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 23:41:45,540 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,540 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:41:45,541 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,541 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 23:41:45,541 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,541 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:41:45,541 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,541 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 23:41:45,541 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,542 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:41:45,542 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,542 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 23:41:45,542 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,542 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 23:41:45,542 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,543 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 23:41:45,543 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,543 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 23:41:45,543 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,543 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 23:41:45,543 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,543 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 23:41:45,544 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,544 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 23:41:45,544 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:41:45,544 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 23:41:45,544 [layer_utils.py:169] INFO =================================================================
2019-09-11 23:41:45,545 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 23:41:45,545 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 23:41:45,545 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 23:41:45,546 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 23:41:45,696 [train.py:84] INFO # of samples: 10000
2019-09-11 23:41:45,696 [train.py:85] INFO mini-batch size: 32
2019-09-11 23:41:45,696 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 23:41:45,734 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:41:45,808 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 23:41:58,050 [callbacks.py:12] INFO For batch 0/312, loss is  783.98.
2019-09-11 23:42:00,822 [callbacks.py:12] INFO For batch 1/312, loss is  422.16.
2019-09-11 23:42:03,600 [callbacks.py:12] INFO For batch 2/312, loss is  409.89.
2019-09-11 23:42:06,385 [callbacks.py:12] INFO For batch 3/312, loss is  344.18.
2019-09-11 23:42:09,321 [callbacks.py:12] INFO For batch 4/312, loss is  306.36.
2019-09-11 23:42:12,014 [callbacks.py:12] INFO For batch 5/312, loss is  300.61.
2019-09-11 23:42:14,649 [callbacks.py:12] INFO For batch 6/312, loss is  267.98.
2019-09-11 23:42:15,064 [callbacks.py:12] INFO For batch 7/312, loss is  264.17.
2019-09-11 23:42:17,581 [callbacks.py:12] INFO For batch 8/312, loss is  277.42.
2019-09-11 23:42:20,426 [callbacks.py:12] INFO For batch 9/312, loss is  248.77.
2019-09-11 23:42:23,044 [callbacks.py:12] INFO For batch 10/312, loss is  246.69.
2019-09-11 23:42:25,728 [callbacks.py:12] INFO For batch 11/312, loss is  248.45.
2019-09-11 23:42:28,524 [callbacks.py:12] INFO For batch 12/312, loss is  233.26.
2019-09-11 23:42:28,986 [callbacks.py:12] INFO For batch 13/312, loss is  252.52.
2019-09-11 23:42:31,848 [callbacks.py:12] INFO For batch 14/312, loss is  226.70.
2019-09-11 23:42:32,295 [callbacks.py:12] INFO For batch 15/312, loss is  221.06.
2019-09-11 23:42:34,920 [callbacks.py:12] INFO For batch 16/312, loss is  220.40.
2019-09-11 23:42:37,993 [callbacks.py:12] INFO For batch 17/312, loss is  226.34.
2019-09-11 23:42:38,511 [callbacks.py:12] INFO For batch 18/312, loss is  230.59.
2019-09-11 23:42:39,013 [callbacks.py:12] INFO For batch 19/312, loss is  217.67.
2019-09-11 23:42:41,509 [callbacks.py:12] INFO For batch 20/312, loss is  221.94.
2019-09-11 23:42:44,114 [callbacks.py:12] INFO For batch 21/312, loss is  225.40.
2019-09-11 23:42:44,605 [callbacks.py:12] INFO For batch 22/312, loss is  214.40.
2019-09-11 23:42:47,179 [callbacks.py:12] INFO For batch 23/312, loss is  224.98.
2019-09-11 23:42:47,601 [callbacks.py:12] INFO For batch 24/312, loss is  218.49.
2019-09-11 23:42:48,039 [callbacks.py:12] INFO For batch 25/312, loss is  217.03.
2019-09-11 23:42:48,539 [callbacks.py:12] INFO For batch 26/312, loss is  226.97.
2019-09-11 23:42:48,989 [callbacks.py:12] INFO For batch 27/312, loss is  212.85.
2019-09-11 23:42:51,877 [callbacks.py:12] INFO For batch 28/312, loss is  223.55.
2019-09-11 23:42:52,287 [callbacks.py:12] INFO For batch 29/312, loss is  214.15.
2019-09-11 23:42:55,497 [callbacks.py:12] INFO For batch 30/312, loss is  223.59.
2019-09-11 23:42:58,119 [callbacks.py:12] INFO For batch 31/312, loss is  224.53.
2019-09-11 23:43:00,809 [callbacks.py:12] INFO For batch 32/312, loss is  213.22.
2019-09-11 23:43:01,189 [callbacks.py:12] INFO For batch 33/312, loss is  214.87.
2019-09-11 23:43:01,636 [callbacks.py:12] INFO For batch 34/312, loss is  216.11.
2019-09-11 23:43:04,163 [callbacks.py:12] INFO For batch 35/312, loss is  215.25.
2019-09-11 23:43:06,981 [callbacks.py:12] INFO For batch 36/312, loss is  214.09.
2019-09-11 23:43:07,386 [callbacks.py:12] INFO For batch 37/312, loss is  208.99.
2019-09-11 23:43:07,861 [callbacks.py:12] INFO For batch 38/312, loss is  218.75.
2019-09-11 23:43:08,330 [callbacks.py:12] INFO For batch 39/312, loss is  210.33.
2019-09-11 23:43:08,719 [callbacks.py:12] INFO For batch 40/312, loss is  214.38.
2019-09-11 23:43:09,119 [callbacks.py:12] INFO For batch 41/312, loss is  217.05.
2019-09-11 23:43:12,190 [callbacks.py:12] INFO For batch 42/312, loss is  216.78.
2019-09-11 23:43:12,688 [callbacks.py:12] INFO For batch 43/312, loss is  214.24.
2019-09-11 23:43:13,149 [callbacks.py:12] INFO For batch 44/312, loss is  209.25.
2019-09-11 23:43:15,875 [callbacks.py:12] INFO For batch 45/312, loss is  202.66.
2019-09-11 23:43:18,673 [callbacks.py:12] INFO For batch 46/312, loss is  206.25.
2019-09-11 23:43:19,168 [callbacks.py:12] INFO For batch 47/312, loss is  206.32.
2019-09-11 23:43:21,738 [callbacks.py:12] INFO For batch 48/312, loss is  216.52.
2019-09-11 23:43:22,175 [callbacks.py:12] INFO For batch 49/312, loss is  209.96.
2019-09-11 23:43:22,591 [callbacks.py:12] INFO For batch 50/312, loss is  212.95.
2019-09-11 23:43:23,068 [callbacks.py:12] INFO For batch 51/312, loss is  208.81.
2019-09-11 23:43:23,485 [callbacks.py:12] INFO For batch 52/312, loss is  201.81.
2019-09-11 23:43:23,912 [callbacks.py:12] INFO For batch 53/312, loss is  211.91.
2019-09-11 23:43:24,439 [callbacks.py:12] INFO For batch 54/312, loss is  200.02.
2019-09-11 23:43:24,899 [callbacks.py:12] INFO For batch 55/312, loss is  215.06.
2019-09-11 23:43:25,352 [callbacks.py:12] INFO For batch 56/312, loss is  205.81.
2019-09-11 23:43:28,194 [callbacks.py:12] INFO For batch 57/312, loss is  216.17.
2019-09-11 23:43:28,625 [callbacks.py:12] INFO For batch 58/312, loss is  200.52.
2019-09-11 23:43:29,036 [callbacks.py:12] INFO For batch 59/312, loss is  215.14.
2019-09-11 23:43:31,791 [callbacks.py:12] INFO For batch 60/312, loss is  208.69.
2019-09-11 23:43:32,213 [callbacks.py:12] INFO For batch 61/312, loss is  213.27.
2019-09-11 23:43:32,598 [callbacks.py:12] INFO For batch 62/312, loss is  214.77.
2019-09-11 23:43:33,053 [callbacks.py:12] INFO For batch 63/312, loss is  204.94.
2019-09-11 23:43:33,543 [callbacks.py:12] INFO For batch 64/312, loss is  210.62.
2019-09-11 23:43:34,013 [callbacks.py:12] INFO For batch 65/312, loss is  206.63.
2019-09-11 23:43:34,581 [callbacks.py:12] INFO For batch 66/312, loss is  208.99.
2019-09-11 23:43:35,270 [callbacks.py:12] INFO For batch 67/312, loss is  209.57.
2019-09-11 23:43:35,906 [callbacks.py:12] INFO For batch 68/312, loss is  210.36.
2019-09-11 23:43:36,353 [callbacks.py:12] INFO For batch 69/312, loss is  203.45.
2019-09-11 23:43:36,775 [callbacks.py:12] INFO For batch 70/312, loss is  212.04.
2019-09-11 23:43:37,260 [callbacks.py:12] INFO For batch 71/312, loss is  204.14.
2019-09-11 23:43:37,675 [callbacks.py:12] INFO For batch 72/312, loss is  203.66.
2019-09-11 23:43:38,362 [callbacks.py:12] INFO For batch 73/312, loss is  205.89.
2019-09-11 23:43:38,746 [callbacks.py:12] INFO For batch 74/312, loss is  205.61.
2019-09-11 23:43:39,203 [callbacks.py:12] INFO For batch 75/312, loss is  202.69.
2019-09-11 23:43:39,807 [callbacks.py:12] INFO For batch 76/312, loss is  212.08.
2019-09-11 23:43:40,324 [callbacks.py:12] INFO For batch 77/312, loss is  214.12.
2019-09-11 23:43:40,826 [callbacks.py:12] INFO For batch 78/312, loss is  210.70.
2019-09-11 23:43:43,843 [callbacks.py:12] INFO For batch 79/312, loss is  209.83.
2019-09-11 23:43:46,793 [callbacks.py:12] INFO For batch 80/312, loss is  215.01.
2019-09-11 23:43:47,263 [callbacks.py:12] INFO For batch 81/312, loss is  208.79.
2019-09-11 23:43:50,073 [callbacks.py:12] INFO For batch 82/312, loss is  212.53.
2019-09-11 23:43:50,623 [callbacks.py:12] INFO For batch 83/312, loss is  215.63.
2019-09-11 23:43:51,089 [callbacks.py:12] INFO For batch 84/312, loss is  203.80.
2019-09-11 23:43:51,516 [callbacks.py:12] INFO For batch 85/312, loss is  206.57.
2019-09-11 23:43:52,007 [callbacks.py:12] INFO For batch 86/312, loss is  202.08.
2019-09-11 23:43:52,474 [callbacks.py:12] INFO For batch 87/312, loss is  207.79.
2019-09-11 23:43:55,306 [callbacks.py:12] INFO For batch 88/312, loss is  214.12.
2019-09-11 23:43:55,785 [callbacks.py:12] INFO For batch 89/312, loss is  203.27.
2019-09-11 23:43:56,214 [callbacks.py:12] INFO For batch 90/312, loss is  213.18.
2019-09-11 23:43:56,832 [callbacks.py:12] INFO For batch 91/312, loss is  213.69.
2019-09-11 23:43:57,296 [callbacks.py:12] INFO For batch 92/312, loss is  206.84.
2019-09-11 23:43:57,871 [callbacks.py:12] INFO For batch 93/312, loss is  205.46.
2019-09-11 23:43:58,365 [callbacks.py:12] INFO For batch 94/312, loss is  211.92.
2019-09-11 23:43:59,085 [callbacks.py:12] INFO For batch 95/312, loss is  215.12.
2019-09-11 23:43:59,584 [callbacks.py:12] INFO For batch 96/312, loss is  196.96.
2019-09-11 23:44:00,043 [callbacks.py:12] INFO For batch 97/312, loss is  202.11.
2019-09-11 23:44:00,445 [callbacks.py:12] INFO For batch 98/312, loss is  204.94.
2019-09-11 23:44:00,912 [callbacks.py:12] INFO For batch 99/312, loss is  206.98.
2019-09-11 23:44:01,355 [callbacks.py:12] INFO For batch 100/312, loss is  207.37.
2019-09-11 23:44:01,843 [callbacks.py:12] INFO For batch 101/312, loss is  209.29.
2019-09-11 23:44:02,255 [callbacks.py:12] INFO For batch 102/312, loss is  211.84.
2019-09-11 23:44:02,810 [callbacks.py:12] INFO For batch 103/312, loss is  209.68.
2019-09-11 23:44:03,397 [callbacks.py:12] INFO For batch 104/312, loss is  213.95.
2019-09-11 23:44:03,912 [callbacks.py:12] INFO For batch 105/312, loss is  201.74.
2019-09-11 23:44:04,564 [callbacks.py:12] INFO For batch 106/312, loss is  207.74.
2019-09-11 23:44:04,991 [callbacks.py:12] INFO For batch 107/312, loss is  208.74.
2019-09-11 23:44:05,534 [callbacks.py:12] INFO For batch 108/312, loss is  197.24.
2019-09-11 23:44:06,154 [callbacks.py:12] INFO For batch 109/312, loss is  217.26.
2019-09-11 23:44:06,616 [callbacks.py:12] INFO For batch 110/312, loss is  217.53.
2019-09-11 23:44:07,065 [callbacks.py:12] INFO For batch 111/312, loss is  211.82.
2019-09-11 23:44:09,811 [callbacks.py:12] INFO For batch 112/312, loss is  213.30.
2019-09-11 23:44:10,238 [callbacks.py:12] INFO For batch 113/312, loss is  204.21.
2019-09-11 23:44:10,682 [callbacks.py:12] INFO For batch 114/312, loss is  203.34.
2019-09-11 23:44:11,166 [callbacks.py:12] INFO For batch 115/312, loss is  212.25.
2019-09-11 23:44:11,743 [callbacks.py:12] INFO For batch 116/312, loss is  197.76.
2019-09-11 23:44:12,232 [callbacks.py:12] INFO For batch 117/312, loss is  216.99.
2019-09-11 23:44:12,810 [callbacks.py:12] INFO For batch 118/312, loss is  213.12.
2019-09-11 23:44:13,335 [callbacks.py:12] INFO For batch 119/312, loss is  201.32.
2019-09-11 23:44:13,889 [callbacks.py:12] INFO For batch 120/312, loss is  210.11.
2019-09-11 23:44:14,489 [callbacks.py:12] INFO For batch 121/312, loss is  208.72.
2019-09-11 23:44:15,018 [callbacks.py:12] INFO For batch 122/312, loss is  213.57.
2019-09-11 23:44:15,500 [callbacks.py:12] INFO For batch 123/312, loss is  202.66.
2019-09-11 23:44:16,124 [callbacks.py:12] INFO For batch 124/312, loss is  205.41.
2019-09-11 23:44:16,526 [callbacks.py:12] INFO For batch 125/312, loss is  204.03.
2019-09-11 23:44:16,983 [callbacks.py:12] INFO For batch 126/312, loss is  200.44.
2019-09-11 23:44:19,642 [callbacks.py:12] INFO For batch 127/312, loss is  205.98.
2019-09-11 23:44:20,153 [callbacks.py:12] INFO For batch 128/312, loss is  207.23.
2019-09-11 23:44:20,596 [callbacks.py:12] INFO For batch 129/312, loss is  209.37.
2019-09-11 23:44:20,987 [callbacks.py:12] INFO For batch 130/312, loss is  203.34.
2019-09-11 23:44:24,134 [callbacks.py:12] INFO For batch 131/312, loss is  209.13.
2019-09-11 23:44:24,586 [callbacks.py:12] INFO For batch 132/312, loss is  205.56.
2019-09-11 23:44:25,113 [callbacks.py:12] INFO For batch 133/312, loss is  206.83.
2019-09-11 23:44:25,629 [callbacks.py:12] INFO For batch 134/312, loss is  206.47.
2019-09-11 23:44:26,242 [callbacks.py:12] INFO For batch 135/312, loss is  208.20.
2019-09-11 23:44:26,721 [callbacks.py:12] INFO For batch 136/312, loss is  212.73.
2019-09-11 23:44:27,350 [callbacks.py:12] INFO For batch 137/312, loss is  209.96.
2019-09-11 23:44:27,971 [callbacks.py:12] INFO For batch 138/312, loss is  213.75.
2019-09-11 23:44:28,468 [callbacks.py:12] INFO For batch 139/312, loss is  196.03.
2019-09-11 23:44:28,951 [callbacks.py:12] INFO For batch 140/312, loss is  208.06.
2019-09-11 23:44:29,482 [callbacks.py:12] INFO For batch 141/312, loss is  200.96.
2019-09-11 23:44:29,893 [callbacks.py:12] INFO For batch 142/312, loss is  206.77.
2019-09-11 23:44:30,282 [callbacks.py:12] INFO For batch 143/312, loss is  203.12.
2019-09-11 23:44:30,693 [callbacks.py:12] INFO For batch 144/312, loss is  206.16.
2019-09-11 23:44:31,128 [callbacks.py:12] INFO For batch 145/312, loss is  209.58.
2019-09-11 23:44:31,917 [callbacks.py:12] INFO For batch 146/312, loss is  213.54.
2019-09-11 23:44:32,816 [callbacks.py:12] INFO For batch 147/312, loss is  214.14.
2019-09-11 23:44:33,255 [callbacks.py:12] INFO For batch 148/312, loss is  204.61.
2019-09-11 23:44:33,694 [callbacks.py:12] INFO For batch 149/312, loss is  215.08.
2019-09-11 23:44:34,165 [callbacks.py:12] INFO For batch 150/312, loss is  205.76.
2019-09-11 23:44:34,653 [callbacks.py:12] INFO For batch 151/312, loss is  216.40.
2019-09-11 23:44:35,191 [callbacks.py:12] INFO For batch 152/312, loss is  204.70.
2019-09-11 23:44:35,591 [callbacks.py:12] INFO For batch 153/312, loss is  203.90.
2019-09-11 23:44:38,390 [callbacks.py:12] INFO For batch 154/312, loss is  206.05.
2019-09-11 23:44:41,318 [callbacks.py:12] INFO For batch 155/312, loss is  202.59.
2019-09-11 23:44:41,810 [callbacks.py:12] INFO For batch 156/312, loss is  212.99.
2019-09-11 23:44:42,213 [callbacks.py:12] INFO For batch 157/312, loss is  202.51.
2019-09-11 23:44:42,817 [callbacks.py:12] INFO For batch 158/312, loss is  211.68.
2019-09-11 23:44:43,247 [callbacks.py:12] INFO For batch 159/312, loss is  211.01.
2019-09-11 23:44:43,712 [callbacks.py:12] INFO For batch 160/312, loss is  200.19.
2019-09-11 23:44:44,239 [callbacks.py:12] INFO For batch 161/312, loss is  208.75.
2019-09-11 23:44:44,664 [callbacks.py:12] INFO For batch 162/312, loss is  203.13.
2019-09-11 23:44:45,178 [callbacks.py:12] INFO For batch 163/312, loss is  202.17.
2019-09-11 23:44:45,709 [callbacks.py:12] INFO For batch 164/312, loss is  214.42.
2019-09-11 23:44:49,029 [callbacks.py:12] INFO For batch 165/312, loss is  209.22.
2019-09-11 23:44:52,475 [callbacks.py:12] INFO For batch 166/312, loss is  212.51.
2019-09-11 23:44:52,922 [callbacks.py:12] INFO For batch 167/312, loss is  205.77.
2019-09-11 23:44:53,402 [callbacks.py:12] INFO For batch 168/312, loss is  204.90.
2019-09-11 23:44:53,840 [callbacks.py:12] INFO For batch 169/312, loss is  216.79.
2019-09-11 23:44:54,375 [callbacks.py:12] INFO For batch 170/312, loss is  201.69.
2019-09-11 23:44:54,804 [callbacks.py:12] INFO For batch 171/312, loss is  207.90.
2019-09-11 23:44:55,277 [callbacks.py:12] INFO For batch 172/312, loss is  211.12.
2019-09-11 23:44:58,608 [callbacks.py:12] INFO For batch 173/312, loss is  200.57.
2019-09-11 23:44:59,064 [callbacks.py:12] INFO For batch 174/312, loss is  206.32.
2019-09-11 23:44:59,586 [callbacks.py:12] INFO For batch 175/312, loss is  199.78.
2019-09-11 23:45:00,025 [callbacks.py:12] INFO For batch 176/312, loss is  207.69.
2019-09-11 23:45:00,562 [callbacks.py:12] INFO For batch 177/312, loss is  212.26.
2019-09-11 23:45:00,982 [callbacks.py:12] INFO For batch 178/312, loss is  200.63.
2019-09-11 23:45:01,479 [callbacks.py:12] INFO For batch 179/312, loss is  208.13.
2019-09-11 23:45:01,961 [callbacks.py:12] INFO For batch 180/312, loss is  200.81.
2019-09-11 23:45:02,386 [callbacks.py:12] INFO For batch 181/312, loss is  204.09.
2019-09-11 23:45:02,758 [callbacks.py:12] INFO For batch 182/312, loss is  205.86.
2019-09-11 23:45:03,310 [callbacks.py:12] INFO For batch 183/312, loss is  204.97.
2019-09-11 23:45:03,788 [callbacks.py:12] INFO For batch 184/312, loss is  206.43.
2019-09-11 23:45:04,479 [callbacks.py:12] INFO For batch 185/312, loss is  205.73.
2019-09-11 23:45:05,084 [callbacks.py:12] INFO For batch 186/312, loss is  204.67.
2019-09-11 23:45:05,608 [callbacks.py:12] INFO For batch 187/312, loss is  206.81.
2019-09-11 23:45:06,168 [callbacks.py:12] INFO For batch 188/312, loss is  203.21.
2019-09-11 23:45:06,687 [callbacks.py:12] INFO For batch 189/312, loss is  207.43.
2019-09-11 23:45:09,872 [callbacks.py:12] INFO For batch 190/312, loss is  209.89.
2019-09-11 23:45:10,295 [callbacks.py:12] INFO For batch 191/312, loss is  197.68.
2019-09-11 23:45:10,756 [callbacks.py:12] INFO For batch 192/312, loss is  201.98.
2019-09-11 23:45:11,374 [callbacks.py:12] INFO For batch 193/312, loss is  213.34.
2019-09-11 23:45:14,845 [callbacks.py:12] INFO For batch 194/312, loss is  204.98.
2019-09-11 23:45:15,343 [callbacks.py:12] INFO For batch 195/312, loss is  213.97.
2019-09-11 23:45:15,822 [callbacks.py:12] INFO For batch 196/312, loss is  199.78.
2019-09-11 23:45:16,257 [callbacks.py:12] INFO For batch 197/312, loss is  211.47.
2019-09-11 23:45:16,886 [callbacks.py:12] INFO For batch 198/312, loss is  206.62.
2019-09-11 23:45:17,314 [callbacks.py:12] INFO For batch 199/312, loss is  202.86.
2019-09-11 23:45:17,799 [callbacks.py:12] INFO For batch 200/312, loss is  208.15.
2019-09-11 23:45:18,305 [callbacks.py:12] INFO For batch 201/312, loss is  211.95.
2019-09-11 23:45:20,970 [callbacks.py:12] INFO For batch 202/312, loss is  204.05.
2019-09-11 23:45:21,353 [callbacks.py:12] INFO For batch 203/312, loss is  208.28.
2019-09-11 23:45:21,758 [callbacks.py:12] INFO For batch 204/312, loss is  201.38.
2019-09-11 23:45:22,261 [callbacks.py:12] INFO For batch 205/312, loss is  199.59.
2019-09-11 23:45:22,801 [callbacks.py:12] INFO For batch 206/312, loss is  204.00.
2019-09-11 23:45:23,246 [callbacks.py:12] INFO For batch 207/312, loss is  208.11.
2019-09-11 23:45:25,846 [callbacks.py:12] INFO For batch 208/312, loss is  207.80.
2019-09-11 23:45:26,251 [callbacks.py:12] INFO For batch 209/312, loss is  209.13.
2019-09-11 23:45:26,750 [callbacks.py:12] INFO For batch 210/312, loss is  206.66.
2019-09-11 23:45:27,220 [callbacks.py:12] INFO For batch 211/312, loss is  208.35.
2019-09-11 23:45:27,641 [callbacks.py:12] INFO For batch 212/312, loss is  206.99.
2019-09-11 23:45:28,130 [callbacks.py:12] INFO For batch 213/312, loss is  210.75.
2019-09-11 23:45:31,409 [callbacks.py:12] INFO For batch 214/312, loss is  205.80.
2019-09-11 23:45:31,807 [callbacks.py:12] INFO For batch 215/312, loss is  203.02.
2019-09-11 23:45:32,159 [callbacks.py:12] INFO For batch 216/312, loss is  202.57.
2019-09-11 23:45:35,161 [callbacks.py:12] INFO For batch 217/312, loss is  204.94.
2019-09-11 23:45:35,685 [callbacks.py:12] INFO For batch 218/312, loss is  209.21.
2019-09-11 23:45:36,091 [callbacks.py:12] INFO For batch 219/312, loss is  202.21.
2019-09-11 23:45:36,484 [callbacks.py:12] INFO For batch 220/312, loss is  209.42.
2019-09-11 23:45:37,014 [callbacks.py:12] INFO For batch 221/312, loss is  205.38.
2019-09-11 23:45:37,476 [callbacks.py:12] INFO For batch 222/312, loss is  200.96.
2019-09-11 23:45:37,916 [callbacks.py:12] INFO For batch 223/312, loss is  209.45.
2019-09-11 23:45:38,469 [callbacks.py:12] INFO For batch 224/312, loss is  207.37.
2019-09-11 23:45:41,905 [callbacks.py:12] INFO For batch 225/312, loss is  203.06.
2019-09-11 23:45:42,309 [callbacks.py:12] INFO For batch 226/312, loss is  205.56.
2019-09-11 23:45:42,745 [callbacks.py:12] INFO For batch 227/312, loss is  207.44.
2019-09-11 23:45:43,367 [callbacks.py:12] INFO For batch 228/312, loss is  204.59.
2019-09-11 23:45:43,766 [callbacks.py:12] INFO For batch 229/312, loss is  204.66.
2019-09-11 23:45:44,190 [callbacks.py:12] INFO For batch 230/312, loss is  199.61.
2019-09-11 23:45:44,683 [callbacks.py:12] INFO For batch 231/312, loss is  208.42.
2019-09-11 23:45:45,086 [callbacks.py:12] INFO For batch 232/312, loss is  211.73.
2019-09-11 23:45:45,627 [callbacks.py:12] INFO For batch 233/312, loss is  207.92.
2019-09-11 23:45:46,177 [callbacks.py:12] INFO For batch 234/312, loss is  209.68.
2019-09-11 23:45:46,773 [callbacks.py:12] INFO For batch 235/312, loss is  212.48.
2019-09-11 23:45:47,253 [callbacks.py:12] INFO For batch 236/312, loss is  204.80.
2019-09-11 23:45:47,806 [callbacks.py:12] INFO For batch 237/312, loss is  207.68.
2019-09-11 23:45:48,351 [callbacks.py:12] INFO For batch 238/312, loss is  199.70.
2019-09-11 23:45:48,770 [callbacks.py:12] INFO For batch 239/312, loss is  205.88.
2019-09-11 23:45:49,185 [callbacks.py:12] INFO For batch 240/312, loss is  213.73.
2019-09-11 23:45:49,590 [callbacks.py:12] INFO For batch 241/312, loss is  196.18.
2019-09-11 23:45:50,171 [callbacks.py:12] INFO For batch 242/312, loss is  211.07.
2019-09-11 23:45:50,644 [callbacks.py:12] INFO For batch 243/312, loss is  210.46.
2019-09-11 23:45:51,346 [callbacks.py:12] INFO For batch 244/312, loss is  212.71.
2019-09-11 23:45:51,986 [callbacks.py:12] INFO For batch 245/312, loss is  205.62.
2019-09-11 23:45:52,552 [callbacks.py:12] INFO For batch 246/312, loss is  203.79.
2019-09-11 23:45:53,125 [callbacks.py:12] INFO For batch 247/312, loss is  205.28.
2019-09-11 23:45:53,693 [callbacks.py:12] INFO For batch 248/312, loss is  206.83.
2019-09-11 23:45:54,140 [callbacks.py:12] INFO For batch 249/312, loss is  208.82.
2019-09-11 23:45:54,509 [callbacks.py:12] INFO For batch 250/312, loss is  203.96.
2019-09-11 23:45:54,991 [callbacks.py:12] INFO For batch 251/312, loss is  212.12.
2019-09-11 23:45:55,414 [callbacks.py:12] INFO For batch 252/312, loss is  207.46.
2019-09-11 23:45:55,833 [callbacks.py:12] INFO For batch 253/312, loss is  204.66.
2019-09-11 23:45:56,272 [callbacks.py:12] INFO For batch 254/312, loss is  203.10.
2019-09-11 23:45:56,806 [callbacks.py:12] INFO For batch 255/312, loss is  208.33.
2019-09-11 23:45:57,413 [callbacks.py:12] INFO For batch 256/312, loss is  201.49.
2019-09-11 23:45:57,997 [callbacks.py:12] INFO For batch 257/312, loss is  198.73.
2019-09-11 23:46:00,555 [callbacks.py:12] INFO For batch 258/312, loss is  205.11.
2019-09-11 23:46:00,948 [callbacks.py:12] INFO For batch 259/312, loss is  205.60.
2019-09-11 23:46:01,466 [callbacks.py:12] INFO For batch 260/312, loss is  213.32.
2019-09-11 23:46:01,976 [callbacks.py:12] INFO For batch 261/312, loss is  196.76.
2019-09-11 23:46:02,455 [callbacks.py:12] INFO For batch 262/312, loss is  199.14.
2019-09-11 23:46:02,847 [callbacks.py:12] INFO For batch 263/312, loss is  205.20.
2019-09-11 23:46:03,271 [callbacks.py:12] INFO For batch 264/312, loss is  207.15.
2019-09-11 23:46:03,673 [callbacks.py:12] INFO For batch 265/312, loss is  202.20.
2019-09-11 23:46:04,098 [callbacks.py:12] INFO For batch 266/312, loss is  200.55.
2019-09-11 23:46:04,666 [callbacks.py:12] INFO For batch 267/312, loss is  206.63.
2019-09-11 23:46:05,283 [callbacks.py:12] INFO For batch 268/312, loss is  208.21.
2019-09-11 23:46:05,809 [callbacks.py:12] INFO For batch 269/312, loss is  195.11.
2019-09-11 23:46:08,984 [callbacks.py:12] INFO For batch 270/312, loss is  210.55.
2019-09-11 23:46:09,442 [callbacks.py:12] INFO For batch 271/312, loss is  210.77.
2019-09-11 23:46:09,986 [callbacks.py:12] INFO For batch 272/312, loss is  210.92.
2019-09-11 23:46:10,407 [callbacks.py:12] INFO For batch 273/312, loss is  214.71.
2019-09-11 23:46:10,829 [callbacks.py:12] INFO For batch 274/312, loss is  217.50.
2019-09-11 23:46:11,285 [callbacks.py:12] INFO For batch 275/312, loss is  206.40.
2019-09-11 23:46:11,880 [callbacks.py:12] INFO For batch 276/312, loss is  209.87.
2019-09-11 23:46:12,312 [callbacks.py:12] INFO For batch 277/312, loss is  200.82.
2019-09-11 23:46:12,848 [callbacks.py:12] INFO For batch 278/312, loss is  206.91.
2019-09-11 23:46:13,326 [callbacks.py:12] INFO For batch 279/312, loss is  202.70.
2019-09-11 23:46:13,730 [callbacks.py:12] INFO For batch 280/312, loss is  210.67.
2019-09-11 23:46:14,232 [callbacks.py:12] INFO For batch 281/312, loss is  207.34.
2019-09-11 23:46:14,680 [callbacks.py:12] INFO For batch 282/312, loss is  208.49.
2019-09-11 23:46:15,183 [callbacks.py:12] INFO For batch 283/312, loss is  213.79.
2019-09-11 23:46:15,691 [callbacks.py:12] INFO For batch 284/312, loss is  207.92.
2019-09-11 23:46:16,262 [callbacks.py:12] INFO For batch 285/312, loss is  209.61.
2019-09-11 23:46:16,748 [callbacks.py:12] INFO For batch 286/312, loss is  207.21.
2019-09-11 23:46:17,375 [callbacks.py:12] INFO For batch 287/312, loss is  209.00.
2019-09-11 23:46:17,871 [callbacks.py:12] INFO For batch 288/312, loss is  201.41.
2019-09-11 23:46:18,348 [callbacks.py:12] INFO For batch 289/312, loss is  209.98.
2019-09-11 23:46:18,842 [callbacks.py:12] INFO For batch 290/312, loss is  206.75.
2019-09-11 23:46:19,208 [callbacks.py:12] INFO For batch 291/312, loss is  193.81.
2019-09-11 23:46:19,760 [callbacks.py:12] INFO For batch 292/312, loss is  208.80.
2019-09-11 23:46:20,579 [callbacks.py:12] INFO For batch 293/312, loss is  203.66.
2019-09-11 23:46:21,251 [callbacks.py:12] INFO For batch 294/312, loss is  201.20.
2019-09-11 23:46:21,768 [callbacks.py:12] INFO For batch 295/312, loss is  198.89.
2019-09-11 23:46:22,259 [callbacks.py:12] INFO For batch 296/312, loss is  203.78.
2019-09-11 23:46:22,679 [callbacks.py:12] INFO For batch 297/312, loss is  207.21.
2019-09-11 23:46:23,277 [callbacks.py:12] INFO For batch 298/312, loss is  208.37.
2019-09-11 23:46:23,706 [callbacks.py:12] INFO For batch 299/312, loss is  206.64.
2019-09-11 23:46:24,254 [callbacks.py:12] INFO For batch 300/312, loss is  203.71.
2019-09-11 23:46:24,755 [callbacks.py:12] INFO For batch 301/312, loss is  209.56.
2019-09-11 23:46:25,259 [callbacks.py:12] INFO For batch 302/312, loss is  204.56.
2019-09-11 23:46:25,783 [callbacks.py:12] INFO For batch 303/312, loss is  204.81.
2019-09-11 23:46:26,228 [callbacks.py:12] INFO For batch 304/312, loss is  201.24.
2019-09-11 23:46:26,737 [callbacks.py:12] INFO For batch 305/312, loss is  204.51.
2019-09-11 23:46:27,294 [callbacks.py:12] INFO For batch 306/312, loss is  198.40.
2019-09-11 23:46:27,889 [callbacks.py:12] INFO For batch 307/312, loss is  200.54.
2019-09-11 23:46:28,489 [callbacks.py:12] INFO For batch 308/312, loss is  199.75.
2019-09-11 23:46:31,621 [callbacks.py:12] INFO For batch 309/312, loss is  205.86.
2019-09-11 23:46:32,072 [callbacks.py:12] INFO For batch 310/312, loss is  203.67.
2019-09-11 23:46:32,456 [callbacks.py:12] INFO For batch 311/312, loss is  206.90.
2019-09-11 23:46:32,955 [callbacks.py:15] INFO For batch 0, validation loss is  215.20.
2019-09-11 23:46:33,333 [callbacks.py:15] INFO For batch 1, validation loss is  215.20.
2019-09-11 23:46:33,554 [callbacks.py:15] INFO For batch 2, validation loss is  215.20.
2019-09-11 23:46:33,903 [callbacks.py:15] INFO For batch 3, validation loss is  215.20.
2019-09-11 23:46:34,193 [callbacks.py:15] INFO For batch 4, validation loss is  215.20.
2019-09-11 23:46:34,475 [callbacks.py:15] INFO For batch 5, validation loss is  215.20.
2019-09-11 23:46:34,790 [callbacks.py:15] INFO For batch 6, validation loss is  215.20.
2019-09-11 23:46:35,052 [callbacks.py:15] INFO For batch 7, validation loss is  215.20.
2019-09-11 23:46:35,383 [callbacks.py:15] INFO For batch 8, validation loss is  232.30.
2019-09-11 23:46:35,764 [callbacks.py:15] INFO For batch 9, validation loss is  232.30.
2019-09-11 23:46:36,098 [callbacks.py:15] INFO For batch 10, validation loss is  232.30.
2019-09-11 23:46:36,346 [callbacks.py:15] INFO For batch 11, validation loss is  232.30.
2019-09-11 23:46:36,562 [callbacks.py:15] INFO For batch 12, validation loss is  232.30.
2019-09-11 23:46:36,753 [callbacks.py:15] INFO For batch 13, validation loss is  232.30.
2019-09-11 23:46:36,985 [callbacks.py:15] INFO For batch 14, validation loss is  232.30.
2019-09-11 23:46:37,230 [callbacks.py:15] INFO For batch 15, validation loss is  232.30.
2019-09-11 23:46:38,092 [callbacks.py:15] INFO For batch 16, validation loss is  234.63.
2019-09-11 23:46:38,406 [callbacks.py:15] INFO For batch 17, validation loss is  234.63.
2019-09-11 23:46:38,643 [callbacks.py:15] INFO For batch 18, validation loss is  234.63.
2019-09-11 23:46:38,906 [callbacks.py:15] INFO For batch 19, validation loss is  234.63.
2019-09-11 23:46:39,152 [callbacks.py:15] INFO For batch 20, validation loss is  234.63.
2019-09-11 23:46:39,342 [callbacks.py:15] INFO For batch 21, validation loss is  234.63.
2019-09-11 23:46:39,537 [callbacks.py:15] INFO For batch 22, validation loss is  234.63.
2019-09-11 23:46:39,713 [callbacks.py:15] INFO For batch 23, validation loss is  234.63.
2019-09-11 23:46:39,906 [callbacks.py:15] INFO For batch 24, validation loss is  218.31.
2019-09-11 23:46:40,152 [callbacks.py:15] INFO For batch 25, validation loss is  218.31.
2019-09-11 23:46:40,339 [callbacks.py:15] INFO For batch 26, validation loss is  218.31.
2019-09-11 23:46:40,340 [callbacks.py:19] INFO The validation average loss is  226.37.
2019-09-11 23:46:43,238 [callbacks.py:23] INFO The average loss for epoch 0 is  213.58.
2019-09-11 23:46:43,662 [callbacks.py:12] INFO For batch 0/312, loss is  198.82.
2019-09-11 23:46:44,184 [callbacks.py:12] INFO For batch 1/312, loss is  208.11.
2019-09-11 23:46:44,567 [callbacks.py:12] INFO For batch 2/312, loss is  204.04.
2019-09-11 23:46:44,980 [callbacks.py:12] INFO For batch 3/312, loss is  202.42.
2019-09-11 23:46:45,413 [callbacks.py:12] INFO For batch 4/312, loss is  199.01.
2019-09-11 23:46:45,994 [callbacks.py:12] INFO For batch 5/312, loss is  217.90.
2019-09-11 23:46:46,434 [callbacks.py:12] INFO For batch 6/312, loss is  197.23.
2019-09-11 23:46:46,857 [callbacks.py:12] INFO For batch 7/312, loss is  201.16.
2019-09-11 23:46:47,305 [callbacks.py:12] INFO For batch 8/312, loss is  202.28.
2019-09-11 23:46:47,926 [callbacks.py:12] INFO For batch 9/312, loss is  207.80.
2019-09-11 23:46:51,116 [callbacks.py:12] INFO For batch 10/312, loss is  201.60.
2019-09-11 23:46:51,715 [callbacks.py:12] INFO For batch 11/312, loss is  206.49.
2019-09-11 23:46:52,107 [callbacks.py:12] INFO For batch 12/312, loss is  202.17.
2019-09-11 23:46:52,581 [callbacks.py:12] INFO For batch 13/312, loss is  194.47.
2019-09-11 23:46:53,006 [callbacks.py:12] INFO For batch 14/312, loss is  201.57.
2019-09-11 23:46:53,429 [callbacks.py:12] INFO For batch 15/312, loss is  211.53.
2019-09-11 23:46:55,437 [callbacks.py:12] INFO For batch 16/312, loss is  206.39.
2019-09-11 23:46:55,858 [callbacks.py:12] INFO For batch 17/312, loss is  208.27.
2019-09-11 23:46:56,275 [callbacks.py:12] INFO For batch 18/312, loss is  199.73.
2019-09-11 23:46:56,679 [callbacks.py:12] INFO For batch 19/312, loss is  192.65.
2019-09-11 23:46:57,107 [callbacks.py:12] INFO For batch 20/312, loss is  204.38.
2019-09-11 23:46:57,628 [callbacks.py:12] INFO For batch 21/312, loss is  209.23.
2019-09-11 23:46:58,059 [callbacks.py:12] INFO For batch 22/312, loss is  211.75.
2019-09-11 23:46:58,440 [callbacks.py:12] INFO For batch 23/312, loss is  197.10.
2019-09-11 23:46:58,914 [callbacks.py:12] INFO For batch 24/312, loss is  200.04.
2019-09-11 23:46:59,579 [callbacks.py:12] INFO For batch 25/312, loss is  208.15.
2019-09-11 23:47:00,015 [callbacks.py:12] INFO For batch 26/312, loss is  198.18.
2019-09-11 23:47:00,666 [callbacks.py:12] INFO For batch 27/312, loss is  206.11.
2019-09-11 23:47:01,157 [callbacks.py:12] INFO For batch 28/312, loss is  205.05.
2019-09-11 23:47:01,644 [callbacks.py:12] INFO For batch 29/312, loss is  202.72.
2019-09-11 23:47:02,086 [callbacks.py:12] INFO For batch 30/312, loss is  196.67.
2019-09-11 23:47:02,667 [callbacks.py:12] INFO For batch 31/312, loss is  203.67.
2019-09-11 23:47:05,718 [callbacks.py:12] INFO For batch 32/312, loss is  200.26.
2019-09-11 23:47:06,131 [callbacks.py:12] INFO For batch 33/312, loss is  205.42.
2019-09-11 23:47:06,665 [callbacks.py:12] INFO For batch 34/312, loss is  206.60.
2019-09-11 23:47:07,054 [callbacks.py:12] INFO For batch 35/312, loss is  200.72.
2019-09-11 23:47:07,489 [callbacks.py:12] INFO For batch 36/312, loss is  202.12.
2019-09-11 23:47:08,096 [callbacks.py:12] INFO For batch 37/312, loss is  205.98.
2019-09-11 23:47:08,578 [callbacks.py:12] INFO For batch 38/312, loss is  202.21.
2019-09-11 23:47:09,024 [callbacks.py:12] INFO For batch 39/312, loss is  202.48.
2019-09-11 23:47:09,482 [callbacks.py:12] INFO For batch 40/312, loss is  199.52.
2019-09-11 23:47:09,921 [callbacks.py:12] INFO For batch 41/312, loss is  204.92.
2019-09-11 23:47:10,360 [callbacks.py:12] INFO For batch 42/312, loss is  202.77.
2019-09-11 23:47:10,760 [callbacks.py:12] INFO For batch 43/312, loss is  198.68.
2019-09-11 23:47:11,163 [callbacks.py:12] INFO For batch 44/312, loss is  202.81.
2019-09-11 23:47:11,552 [callbacks.py:12] INFO For batch 45/312, loss is  195.48.
2019-09-11 23:47:12,041 [callbacks.py:12] INFO For batch 46/312, loss is  203.30.
2019-09-11 23:47:12,543 [callbacks.py:12] INFO For batch 47/312, loss is  201.78.
2019-09-11 23:47:13,033 [callbacks.py:12] INFO For batch 48/312, loss is  202.69.
2019-09-11 23:47:13,627 [callbacks.py:12] INFO For batch 49/312, loss is  203.03.
2019-09-11 23:47:14,220 [callbacks.py:12] INFO For batch 50/312, loss is  202.06.
2019-09-11 23:47:14,582 [callbacks.py:12] INFO For batch 51/312, loss is  192.55.
2019-09-11 23:47:14,965 [callbacks.py:12] INFO For batch 52/312, loss is  206.46.
2019-09-11 23:47:15,386 [callbacks.py:12] INFO For batch 53/312, loss is  203.13.
2019-09-11 23:47:15,768 [callbacks.py:12] INFO For batch 54/312, loss is  198.87.
2019-09-11 23:47:16,462 [callbacks.py:12] INFO For batch 55/312, loss is  200.12.
2019-09-11 23:47:16,869 [callbacks.py:12] INFO For batch 56/312, loss is  205.27.
2019-09-11 23:47:17,257 [callbacks.py:12] INFO For batch 57/312, loss is  201.16.
2019-09-11 23:47:17,754 [callbacks.py:12] INFO For batch 58/312, loss is  207.04.
2019-09-11 23:47:18,172 [callbacks.py:12] INFO For batch 59/312, loss is  202.06.
2019-09-11 23:47:18,748 [callbacks.py:12] INFO For batch 60/312, loss is  200.73.
2019-09-11 23:47:19,255 [callbacks.py:12] INFO For batch 61/312, loss is  207.69.
2019-09-11 23:47:19,994 [callbacks.py:12] INFO For batch 62/312, loss is  203.53.
2019-09-11 23:47:20,564 [callbacks.py:12] INFO For batch 63/312, loss is  208.25.
2019-09-11 23:47:20,959 [callbacks.py:12] INFO For batch 64/312, loss is  201.71.
2019-09-11 23:47:21,601 [callbacks.py:12] INFO For batch 65/312, loss is  196.95.
2019-09-11 23:47:22,126 [callbacks.py:12] INFO For batch 66/312, loss is  204.60.
2019-09-11 23:47:24,809 [callbacks.py:12] INFO For batch 67/312, loss is  201.70.
2019-09-11 23:47:25,242 [callbacks.py:12] INFO For batch 68/312, loss is  202.34.
2019-09-11 23:47:25,660 [callbacks.py:12] INFO For batch 69/312, loss is  209.70.
2019-09-11 23:47:26,178 [callbacks.py:12] INFO For batch 70/312, loss is  211.89.
2019-09-11 23:47:26,670 [callbacks.py:12] INFO For batch 71/312, loss is  207.26.
2019-09-11 23:47:27,226 [callbacks.py:12] INFO For batch 72/312, loss is  207.70.
2019-09-11 23:47:27,971 [callbacks.py:12] INFO For batch 73/312, loss is  205.48.
2019-09-11 23:47:28,472 [callbacks.py:12] INFO For batch 74/312, loss is  203.92.
2019-09-11 23:47:28,898 [callbacks.py:12] INFO For batch 75/312, loss is  211.42.
2019-09-11 23:47:29,308 [callbacks.py:12] INFO For batch 76/312, loss is  206.01.
2019-09-11 23:47:29,828 [callbacks.py:12] INFO For batch 77/312, loss is  202.95.
2019-09-11 23:47:30,290 [callbacks.py:12] INFO For batch 78/312, loss is  202.92.
2019-09-11 23:47:30,737 [callbacks.py:12] INFO For batch 79/312, loss is  200.97.
2019-09-11 23:47:31,176 [callbacks.py:12] INFO For batch 80/312, loss is  202.68.
2019-09-11 23:47:31,601 [callbacks.py:12] INFO For batch 81/312, loss is  197.36.
2019-09-11 23:48:45,887 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=10, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 23:48:56,297 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 23:49:00,434 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 23:49:00,516 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 23:49:00,516 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 23:49:00,516 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 23:49:00,516 [layer_utils.py:109] INFO =================================================================
2019-09-11 23:49:00,516 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 23:49:00,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,517 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 23:49:00,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,517 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 23:49:00,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,518 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 23:49:00,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,518 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 23:49:00,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,518 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 23:49:00,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,518 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 23:49:00,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,519 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 23:49:00,519 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,519 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 23:49:00,519 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,519 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 23:49:00,519 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,519 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 23:49:00,520 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,520 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 23:49:00,520 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,520 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 23:49:00,520 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,520 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 23:49:00,520 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,521 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 23:49:00,521 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,521 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 23:49:00,521 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,521 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:49:00,521 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,522 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 23:49:00,522 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,522 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:49:00,522 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,522 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 23:49:00,522 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,522 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:49:00,523 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,523 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 23:49:00,523 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,523 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 23:49:00,523 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,523 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 23:49:00,523 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,524 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 23:49:00,524 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,524 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 23:49:00,524 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,524 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 23:49:00,524 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,525 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 23:49:00,525 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:49:00,525 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 23:49:00,525 [layer_utils.py:169] INFO =================================================================
2019-09-11 23:49:00,526 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 23:49:00,526 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 23:49:00,526 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 23:49:00,526 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 23:49:00,736 [train.py:84] INFO # of samples: 10000
2019-09-11 23:49:00,737 [train.py:85] INFO mini-batch size: 32
2019-09-11 23:49:00,737 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 23:49:00,782 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:49:00,873 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 23:49:17,700 [callbacks.py:16] INFO For batch 0/312, loss is    7.49.
2019-09-11 23:51:04,565 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=10, log='train.log', logprefix='thchs30', lr=0.0008, nworkers=1, pretrain=None, saved_dir='./checkpoint')
2019-09-11 23:51:13,541 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-11 23:51:17,450 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-11 23:51:17,514 [layer_utils.py:106] INFO Model: "model_1"
2019-09-11 23:51:17,514 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-11 23:51:17,514 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-11 23:51:17,514 [layer_utils.py:109] INFO =================================================================
2019-09-11 23:51:17,514 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-11 23:51:17,514 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,514 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-11 23:51:17,514 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,514 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-11 23:51:17,514 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,515 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-11 23:51:17,515 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,515 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-11 23:51:17,515 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,515 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-11 23:51:17,515 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,515 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-11 23:51:17,515 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,515 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-11 23:51:17,515 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,515 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-11 23:51:17,515 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,516 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-11 23:51:17,516 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,516 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-11 23:51:17,516 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,516 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-11 23:51:17,516 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,516 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-11 23:51:17,516 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,516 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-11 23:51:17,516 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,516 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-11 23:51:17,516 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,517 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-11 23:51:17,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,517 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:51:17,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,517 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-11 23:51:17,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,517 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:51:17,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,517 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-11 23:51:17,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,517 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-11 23:51:17,517 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,518 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-11 23:51:17,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,518 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-11 23:51:17,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,518 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-11 23:51:17,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,518 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-11 23:51:17,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,518 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-11 23:51:17,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,518 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-11 23:51:17,518 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,519 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-11 23:51:17,519 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-11 23:51:17,519 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-11 23:51:17,519 [layer_utils.py:169] INFO =================================================================
2019-09-11 23:51:17,519 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-11 23:51:17,519 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-11 23:51:17,519 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-11 23:51:17,520 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-11 23:51:17,660 [train.py:84] INFO # of samples: 10000
2019-09-11 23:51:17,661 [train.py:85] INFO mini-batch size: 32
2019-09-11 23:51:17,661 [train.py:86] INFO # of iterations per epoch: 312
2019-09-11 23:51:17,696 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-11 23:51:17,766 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-11 23:51:30,001 [callbacks.py:16] INFO For batch 0/312, loss is   18.32.
2019-09-11 23:52:36,945 [callbacks.py:16] INFO For batch 40/312, loss is  239.11.
2019-09-11 23:53:22,767 [callbacks.py:16] INFO For batch 80/312, loss is  209.34.
2019-09-11 23:53:55,200 [callbacks.py:16] INFO For batch 120/312, loss is  208.21.
2019-09-11 23:54:14,999 [callbacks.py:16] INFO For batch 160/312, loss is  206.40.
2019-09-11 23:54:38,411 [callbacks.py:16] INFO For batch 200/312, loss is  206.87.
2019-09-11 23:54:58,717 [callbacks.py:16] INFO For batch 240/312, loss is  207.25.
2019-09-11 23:55:13,918 [callbacks.py:16] INFO For batch 280/312, loss is  204.57.
2019-09-11 23:55:31,492 [callbacks.py:24] INFO The validation average loss is  225.87.
2019-09-11 23:55:35,763 [callbacks.py:28] INFO The average loss for epoch 0 is  212.56.
2019-09-11 23:55:36,115 [callbacks.py:16] INFO For batch 0/312, loss is  162.77.
2019-09-11 23:55:52,995 [callbacks.py:16] INFO For batch 40/312, loss is  201.71.
2019-09-11 23:56:10,848 [callbacks.py:16] INFO For batch 80/312, loss is  199.43.
2019-09-11 23:56:25,729 [callbacks.py:16] INFO For batch 120/312, loss is  194.84.
2019-09-11 23:56:40,857 [callbacks.py:16] INFO For batch 160/312, loss is  188.69.
2019-09-11 23:57:00,946 [callbacks.py:16] INFO For batch 200/312, loss is  182.87.
2019-09-11 23:57:17,969 [callbacks.py:16] INFO For batch 240/312, loss is  174.40.
2019-09-11 23:57:32,986 [callbacks.py:16] INFO For batch 280/312, loss is  169.14.
2019-09-11 23:57:55,815 [callbacks.py:24] INFO The validation average loss is  240.88.
2019-09-11 23:57:55,832 [callbacks.py:28] INFO The average loss for epoch 1 is  184.93.
2019-09-11 23:57:56,208 [callbacks.py:16] INFO For batch 0/312, loss is  130.43.
2019-09-11 23:58:11,474 [callbacks.py:16] INFO For batch 40/312, loss is  158.05.
2019-09-11 23:58:26,780 [callbacks.py:16] INFO For batch 80/312, loss is  152.23.
2019-09-11 23:58:42,178 [callbacks.py:16] INFO For batch 120/312, loss is  148.29.
2019-09-11 23:58:57,251 [callbacks.py:16] INFO For batch 160/312, loss is  143.67.
2019-09-11 23:59:14,190 [callbacks.py:16] INFO For batch 200/312, loss is  139.58.
2019-09-11 23:59:29,328 [callbacks.py:16] INFO For batch 240/312, loss is  136.86.
2019-09-11 23:59:44,273 [callbacks.py:16] INFO For batch 280/312, loss is  132.82.
2019-09-12 00:00:01,736 [callbacks.py:24] INFO The validation average loss is  282.95.
2019-09-12 00:00:01,742 [callbacks.py:28] INFO The average loss for epoch 2 is  143.21.
2019-09-12 00:00:02,174 [callbacks.py:16] INFO For batch 0/312, loss is  104.97.
2019-09-12 00:00:17,303 [callbacks.py:16] INFO For batch 40/312, loss is  127.71.
2019-09-12 00:00:32,196 [callbacks.py:16] INFO For batch 80/312, loss is  124.17.
2019-09-12 00:00:47,408 [callbacks.py:16] INFO For batch 120/312, loss is  123.90.
2019-09-12 00:01:02,436 [callbacks.py:16] INFO For batch 160/312, loss is  119.33.
2019-09-12 00:01:18,050 [callbacks.py:16] INFO For batch 200/312, loss is  117.37.
2019-09-12 00:01:33,542 [callbacks.py:16] INFO For batch 240/312, loss is  114.87.
2019-09-12 00:01:48,657 [callbacks.py:16] INFO For batch 280/312, loss is  113.36.
2019-09-12 00:02:06,526 [callbacks.py:24] INFO The validation average loss is  307.56.
2019-09-12 00:02:06,528 [callbacks.py:28] INFO The average loss for epoch 3 is  119.51.
2019-09-12 00:02:06,882 [callbacks.py:16] INFO For batch 0/312, loss is   90.60.
2019-09-12 00:02:27,079 [callbacks.py:16] INFO For batch 40/312, loss is  111.18.
2019-09-12 00:02:42,173 [callbacks.py:16] INFO For batch 80/312, loss is  107.26.
2019-09-12 00:02:57,383 [callbacks.py:16] INFO For batch 120/312, loss is  107.93.
2019-09-12 00:03:12,529 [callbacks.py:16] INFO For batch 160/312, loss is  106.82.
2019-09-12 00:03:27,826 [callbacks.py:16] INFO For batch 200/312, loss is  105.30.
2019-09-12 00:03:43,023 [callbacks.py:16] INFO For batch 240/312, loss is  102.91.
2019-09-12 00:03:57,890 [callbacks.py:16] INFO For batch 280/312, loss is  101.51.
2019-09-12 00:04:15,209 [callbacks.py:24] INFO The validation average loss is  326.33.
2019-09-12 00:04:15,211 [callbacks.py:28] INFO The average loss for epoch 4 is  105.59.
2019-09-12 00:04:15,668 [callbacks.py:16] INFO For batch 0/312, loss is   80.72.
2019-09-12 00:04:30,509 [callbacks.py:16] INFO For batch 40/312, loss is   98.80.
2019-09-12 00:04:45,705 [callbacks.py:16] INFO For batch 80/312, loss is   98.75.
2019-09-12 00:05:01,062 [callbacks.py:16] INFO For batch 120/312, loss is   99.00.
2019-09-12 00:05:15,984 [callbacks.py:16] INFO For batch 160/312, loss is   96.72.
2019-09-12 00:05:31,005 [callbacks.py:16] INFO For batch 200/312, loss is   95.49.
2019-09-12 00:05:45,888 [callbacks.py:16] INFO For batch 240/312, loss is   94.14.
2019-09-12 00:06:00,781 [callbacks.py:16] INFO For batch 280/312, loss is   93.32.
2019-09-12 00:06:16,236 [callbacks.py:24] INFO The validation average loss is  336.10.
2019-09-12 00:06:16,238 [callbacks.py:28] INFO The average loss for epoch 5 is   96.32.
2019-09-12 00:06:16,620 [callbacks.py:16] INFO For batch 0/312, loss is   75.00.
2019-09-12 00:06:31,870 [callbacks.py:16] INFO For batch 40/312, loss is   91.89.
2019-09-12 00:06:46,916 [callbacks.py:16] INFO For batch 80/312, loss is   92.72.
2019-09-12 00:07:01,945 [callbacks.py:16] INFO For batch 120/312, loss is   90.99.
2019-09-12 00:07:16,636 [callbacks.py:16] INFO For batch 160/312, loss is   90.29.
2019-09-12 00:07:31,643 [callbacks.py:16] INFO For batch 200/312, loss is   89.22.
2019-09-12 00:07:46,419 [callbacks.py:16] INFO For batch 240/312, loss is   88.44.
2019-09-12 00:08:01,627 [callbacks.py:16] INFO For batch 280/312, loss is   88.40.
2019-09-12 00:08:17,429 [callbacks.py:24] INFO The validation average loss is  352.80.
2019-09-12 00:08:17,430 [callbacks.py:28] INFO The average loss for epoch 6 is   90.02.
2019-09-12 00:08:17,875 [callbacks.py:16] INFO For batch 0/312, loss is   70.06.
2019-09-12 00:08:33,040 [callbacks.py:16] INFO For batch 40/312, loss is   87.06.
2019-09-12 00:08:47,865 [callbacks.py:16] INFO For batch 80/312, loss is   85.89.
2019-09-12 00:09:02,742 [callbacks.py:16] INFO For batch 120/312, loss is   85.49.
2019-09-12 00:09:18,215 [callbacks.py:16] INFO For batch 160/312, loss is   85.77.
2019-09-12 00:09:33,641 [callbacks.py:16] INFO For batch 200/312, loss is   84.51.
2019-09-12 00:09:49,792 [callbacks.py:16] INFO For batch 240/312, loss is   82.72.
2019-09-12 00:10:06,266 [callbacks.py:16] INFO For batch 280/312, loss is   83.76.
2019-09-12 00:10:23,386 [callbacks.py:24] INFO The validation average loss is  359.33.
2019-09-12 00:10:23,392 [callbacks.py:28] INFO The average loss for epoch 7 is   84.87.
2019-09-12 00:10:23,776 [callbacks.py:16] INFO For batch 0/312, loss is   66.67.
2019-09-12 00:10:39,725 [callbacks.py:16] INFO For batch 40/312, loss is   82.28.
2019-09-12 00:10:55,892 [callbacks.py:16] INFO For batch 80/312, loss is   81.56.
2019-09-12 00:11:11,641 [callbacks.py:16] INFO For batch 120/312, loss is   81.41.
2019-09-12 00:11:27,205 [callbacks.py:16] INFO For batch 160/312, loss is   80.33.
2019-09-12 00:11:42,517 [callbacks.py:16] INFO For batch 200/312, loss is   79.94.
2019-09-12 00:11:58,834 [callbacks.py:16] INFO For batch 240/312, loss is   79.77.
2019-09-12 00:12:14,894 [callbacks.py:16] INFO For batch 280/312, loss is   80.34.
2019-09-12 00:12:33,433 [callbacks.py:24] INFO The validation average loss is  354.76.
2019-09-12 00:12:33,450 [callbacks.py:28] INFO The average loss for epoch 8 is   80.73.
2019-09-12 00:12:33,872 [callbacks.py:16] INFO For batch 0/312, loss is   63.96.
2019-09-12 00:12:50,001 [callbacks.py:16] INFO For batch 40/312, loss is   77.72.
2019-09-12 00:13:05,867 [callbacks.py:16] INFO For batch 80/312, loss is   78.19.
2019-09-12 00:13:21,520 [callbacks.py:16] INFO For batch 120/312, loss is   77.75.
2019-09-12 00:13:36,996 [callbacks.py:16] INFO For batch 160/312, loss is   76.67.
2019-09-12 00:13:53,137 [callbacks.py:16] INFO For batch 200/312, loss is   77.30.
2019-09-12 00:14:09,083 [callbacks.py:16] INFO For batch 240/312, loss is   76.55.
2019-09-12 00:14:24,801 [callbacks.py:16] INFO For batch 280/312, loss is   76.30.
2019-09-12 00:14:44,862 [callbacks.py:24] INFO The validation average loss is  350.79.
2019-09-12 00:14:44,881 [callbacks.py:28] INFO The average loss for epoch 9 is   77.02.
2019-09-12 00:14:47,220 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:296: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
2019-09-12 00:14:47,232 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:141: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
2019-09-12 00:14:48,640 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:220: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv1d instead.
2019-09-12 00:14:48,722 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:317: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-12 00:14:52,491 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2019-09-12 00:14:52,515 [saver.py:1270] INFO Restoring parameters from logs_lm/thchs30_model_2
2019-09-12 00:15:09,150 [train.py:147] INFO epochs: 1: average loss = 1.208273
2019-09-12 00:15:22,541 [train.py:147] INFO epochs: 2: average loss = 1.192376
2019-09-12 00:15:35,963 [train.py:147] INFO epochs: 3: average loss = 1.181628
2019-09-12 00:15:49,435 [train.py:147] INFO epochs: 4: average loss = 1.173936
2019-09-12 00:16:02,691 [train.py:147] INFO epochs: 5: average loss = 1.166256
2019-09-12 00:16:16,024 [train.py:147] INFO epochs: 6: average loss = 1.160200
2019-09-12 00:16:29,517 [train.py:147] INFO epochs: 7: average loss = 1.154773
2019-09-12 00:16:42,850 [train.py:147] INFO epochs: 8: average loss = 1.150773
2019-09-12 00:16:56,310 [train.py:147] INFO epochs: 9: average loss = 1.146817
2019-09-12 00:17:09,731 [train.py:147] INFO epochs: 10: average loss = 1.144655
2019-09-12 00:26:52,204 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=2, log='train.log', logprefix='thchs30multigpu', lr=0.0008, nworkers=4, pretrain=None, saved_dir='./checkpoint')
2019-09-12 00:27:23,447 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-12 00:27:26,738 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-12 00:27:26,801 [layer_utils.py:106] INFO Model: "model_1"
2019-09-12 00:27:26,801 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-12 00:27:26,802 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-12 00:27:26,802 [layer_utils.py:109] INFO =================================================================
2019-09-12 00:27:26,802 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-12 00:27:26,802 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,802 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-12 00:27:26,802 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,802 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-12 00:27:26,802 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,802 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-12 00:27:26,802 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,802 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-12 00:27:26,802 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,803 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-12 00:27:26,803 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,803 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-12 00:27:26,803 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,803 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-12 00:27:26,803 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,803 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-12 00:27:26,803 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,803 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-12 00:27:26,803 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,803 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-12 00:27:26,803 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,804 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-12 00:27:26,804 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,804 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-12 00:27:26,804 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,804 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-12 00:27:26,804 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,804 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-12 00:27:26,804 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,804 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-12 00:27:26,804 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,804 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:27:26,804 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,805 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-12 00:27:26,805 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,805 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:27:26,805 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,805 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-12 00:27:26,805 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,805 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:27:26,805 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,805 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-12 00:27:26,805 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,805 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-12 00:27:26,805 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,806 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-12 00:27:26,806 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,806 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-12 00:27:26,806 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,806 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-12 00:27:26,806 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,806 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-12 00:27:26,806 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,806 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-12 00:27:26,806 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:27:26,806 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-12 00:27:26,806 [layer_utils.py:169] INFO =================================================================
2019-09-12 00:27:26,807 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-12 00:27:26,807 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-12 00:27:26,807 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-12 00:27:26,807 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-12 00:27:31,160 [train.py:84] INFO # of samples: 10000
2019-09-12 00:27:31,161 [train.py:85] INFO mini-batch size: 32
2019-09-12 00:27:31,161 [train.py:86] INFO # of iterations per epoch: 312
2019-09-12 00:27:31,218 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-12 00:27:31,420 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-12 00:28:28,535 [callbacks.py:16] INFO For batch 40/312, loss is  272.49.
2019-09-12 00:28:41,333 [callbacks.py:16] INFO For batch 80/312, loss is  212.87.
2019-09-12 00:28:53,551 [callbacks.py:16] INFO For batch 120/312, loss is  207.74.
2019-09-12 00:29:02,444 [callbacks.py:16] INFO For batch 160/312, loss is  209.17.
2019-09-12 00:29:11,849 [callbacks.py:16] INFO For batch 200/312, loss is  207.52.
2019-09-12 00:29:22,016 [callbacks.py:16] INFO For batch 240/312, loss is  206.10.
2019-09-12 00:29:30,553 [callbacks.py:16] INFO For batch 280/312, loss is  207.37.
2019-09-12 00:29:42,312 [callbacks.py:24] INFO The validation average loss is  226.06.
2019-09-12 00:29:43,457 [callbacks.py:28] INFO The average loss for epoch 0 is  215.85.
2019-09-12 00:29:50,684 [callbacks.py:16] INFO For batch 40/312, loss is  369.04.
2019-09-12 00:30:00,561 [callbacks.py:16] INFO For batch 80/312, loss is  203.94.
2019-09-12 00:30:09,178 [callbacks.py:16] INFO For batch 120/312, loss is  204.02.
2019-09-12 00:30:17,153 [callbacks.py:16] INFO For batch 160/312, loss is  200.88.
2019-09-12 00:30:24,185 [callbacks.py:16] INFO For batch 200/312, loss is  198.70.
2019-09-12 00:30:31,383 [callbacks.py:16] INFO For batch 240/312, loss is  196.56.
2019-09-12 00:30:39,082 [callbacks.py:16] INFO For batch 280/312, loss is  195.59.
2019-09-12 00:30:49,437 [callbacks.py:24] INFO The validation average loss is  225.97.
2019-09-12 00:30:49,597 [callbacks.py:28] INFO The average loss for epoch 1 is  199.68.
2019-09-12 00:30:52,989 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:296: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
2019-09-12 00:30:52,999 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:141: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
2019-09-12 00:30:53,865 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:220: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv1d instead.
2019-09-12 00:30:53,945 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:317: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-12 00:30:57,818 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2019-09-12 00:30:57,820 [saver.py:1270] INFO Restoring parameters from logs_lm/thchs30_model_12
2019-09-12 00:31:14,080 [train.py:147] INFO epochs: 1: average loss = 1.142390
2019-09-12 00:31:27,299 [train.py:147] INFO epochs: 2: average loss = 1.140696
2019-09-12 00:34:57,257 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=10, log='train.log', logprefix='thchs30multigpu', lr=0.0008, nworkers=4, pretrain=None, saved_dir='./checkpoint')
2019-09-12 00:35:05,603 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-12 00:35:08,816 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-12 00:35:08,879 [layer_utils.py:106] INFO Model: "model_1"
2019-09-12 00:35:08,879 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-12 00:35:08,879 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-12 00:35:08,879 [layer_utils.py:109] INFO =================================================================
2019-09-12 00:35:08,879 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-12 00:35:08,879 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,880 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-12 00:35:08,880 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,880 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-12 00:35:08,880 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,880 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-12 00:35:08,880 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,880 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-12 00:35:08,880 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,880 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-12 00:35:08,880 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,880 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-12 00:35:08,880 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,881 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-12 00:35:08,881 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,881 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-12 00:35:08,881 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,881 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-12 00:35:08,881 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,881 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-12 00:35:08,881 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,881 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-12 00:35:08,881 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,881 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-12 00:35:08,881 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,882 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-12 00:35:08,882 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,882 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-12 00:35:08,882 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,882 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-12 00:35:08,882 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,882 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:35:08,882 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,882 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-12 00:35:08,882 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,882 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:35:08,882 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,883 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-12 00:35:08,883 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,883 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:35:08,883 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,883 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-12 00:35:08,883 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,883 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-12 00:35:08,883 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,883 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-12 00:35:08,883 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,883 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-12 00:35:08,883 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,883 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-12 00:35:08,884 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,884 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-12 00:35:08,884 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,884 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-12 00:35:08,884 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:35:08,884 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-12 00:35:08,884 [layer_utils.py:169] INFO =================================================================
2019-09-12 00:35:08,885 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-12 00:35:08,885 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-12 00:35:08,885 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-12 00:35:08,885 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-12 00:35:13,265 [train.py:84] INFO # of samples: 10000
2019-09-12 00:35:13,266 [train.py:85] INFO mini-batch size: 32
2019-09-12 00:35:13,266 [train.py:86] INFO # of iterations per epoch: 312
2019-09-12 00:35:13,319 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-12 00:35:13,521 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-12 00:36:07,085 [callbacks.py:16] INFO For batch 40/312, loss is  258.20.
2019-09-12 00:36:20,719 [callbacks.py:16] INFO For batch 80/312, loss is  209.18.
2019-09-12 00:36:31,032 [callbacks.py:16] INFO For batch 120/312, loss is  207.99.
2019-09-12 00:36:40,070 [callbacks.py:16] INFO For batch 160/312, loss is  206.68.
2019-09-12 00:36:47,164 [callbacks.py:16] INFO For batch 200/312, loss is  207.53.
2019-09-12 00:36:56,139 [callbacks.py:16] INFO For batch 240/312, loss is  206.12.
2019-09-12 00:37:05,133 [callbacks.py:16] INFO For batch 280/312, loss is  205.18.
2019-09-12 00:37:17,233 [callbacks.py:24] INFO The validation average loss is  227.41.
2019-09-12 00:37:18,504 [callbacks.py:28] INFO The average loss for epoch 0 is  212.79.
2019-09-12 00:37:27,721 [callbacks.py:16] INFO For batch 40/312, loss is  365.97.
2019-09-12 00:37:34,995 [callbacks.py:16] INFO For batch 80/312, loss is  199.30.
2019-09-12 00:37:43,392 [callbacks.py:16] INFO For batch 120/312, loss is  196.12.
2019-09-12 00:37:50,964 [callbacks.py:16] INFO For batch 160/312, loss is  190.97.
2019-09-12 00:37:59,152 [callbacks.py:16] INFO For batch 200/312, loss is  184.68.
2019-09-12 00:38:06,756 [callbacks.py:16] INFO For batch 240/312, loss is  177.66.
2019-09-12 00:38:14,851 [callbacks.py:16] INFO For batch 280/312, loss is  170.65.
2019-09-12 00:38:26,136 [callbacks.py:24] INFO The validation average loss is  244.39.
2019-09-12 00:38:26,137 [callbacks.py:28] INFO The average loss for epoch 1 is  186.46.
2019-09-12 00:38:34,435 [callbacks.py:16] INFO For batch 40/312, loss is  291.96.
2019-09-12 00:38:41,845 [callbacks.py:16] INFO For batch 80/312, loss is  152.76.
2019-09-12 00:38:49,343 [callbacks.py:16] INFO For batch 120/312, loss is  147.03.
2019-09-12 00:38:56,729 [callbacks.py:16] INFO For batch 160/312, loss is  143.32.
2019-09-12 00:39:04,339 [callbacks.py:16] INFO For batch 200/312, loss is  138.64.
2019-09-12 00:39:11,946 [callbacks.py:16] INFO For batch 240/312, loss is  133.63.
2019-09-12 00:39:19,438 [callbacks.py:16] INFO For batch 280/312, loss is  130.51.
2019-09-12 00:39:28,716 [callbacks.py:24] INFO The validation average loss is  279.41.
2019-09-12 00:39:28,718 [callbacks.py:28] INFO The average loss for epoch 2 is  142.05.
2019-09-12 00:39:36,642 [callbacks.py:16] INFO For batch 40/312, loss is  225.77.
2019-09-12 00:39:44,201 [callbacks.py:16] INFO For batch 80/312, loss is  123.60.
2019-09-12 00:39:51,629 [callbacks.py:16] INFO For batch 120/312, loss is  119.66.
2019-09-12 00:39:58,951 [callbacks.py:16] INFO For batch 160/312, loss is  117.34.
2019-09-12 00:40:06,475 [callbacks.py:16] INFO For batch 200/312, loss is  114.11.
2019-09-12 00:40:13,669 [callbacks.py:16] INFO For batch 240/312, loss is  113.93.
2019-09-12 00:40:21,097 [callbacks.py:16] INFO For batch 280/312, loss is  111.02.
2019-09-12 00:40:30,418 [callbacks.py:24] INFO The validation average loss is  312.10.
2019-09-12 00:40:30,420 [callbacks.py:28] INFO The average loss for epoch 3 is  117.04.
2019-09-12 00:40:38,217 [callbacks.py:16] INFO For batch 40/312, loss is  195.28.
2019-09-12 00:40:45,485 [callbacks.py:16] INFO For batch 80/312, loss is  106.34.
2019-09-12 00:40:52,698 [callbacks.py:16] INFO For batch 120/312, loss is  105.18.
2019-09-12 00:41:00,059 [callbacks.py:16] INFO For batch 160/312, loss is  102.45.
2019-09-12 00:41:07,382 [callbacks.py:16] INFO For batch 200/312, loss is  102.28.
2019-09-12 00:41:14,926 [callbacks.py:16] INFO For batch 240/312, loss is  100.83.
2019-09-12 00:41:22,264 [callbacks.py:16] INFO For batch 280/312, loss is   99.64.
2019-09-12 00:41:31,889 [callbacks.py:24] INFO The validation average loss is  325.79.
2019-09-12 00:41:31,890 [callbacks.py:28] INFO The average loss for epoch 4 is  102.90.
2019-09-12 00:41:39,472 [callbacks.py:16] INFO For batch 40/312, loss is  174.69.
2019-09-12 00:41:47,798 [callbacks.py:16] INFO For batch 80/312, loss is   95.63.
2019-09-12 00:41:55,226 [callbacks.py:16] INFO For batch 120/312, loss is   94.95.
2019-09-12 00:42:02,452 [callbacks.py:16] INFO For batch 160/312, loss is   93.77.
2019-09-12 00:42:09,896 [callbacks.py:16] INFO For batch 200/312, loss is   92.26.
2019-09-12 00:42:17,523 [callbacks.py:16] INFO For batch 240/312, loss is   91.40.
2019-09-12 00:42:25,043 [callbacks.py:16] INFO For batch 280/312, loss is   91.25.
2019-09-12 00:42:34,948 [callbacks.py:24] INFO The validation average loss is  337.90.
2019-09-12 00:42:35,009 [callbacks.py:28] INFO The average loss for epoch 5 is   93.40.
2019-09-12 00:42:43,435 [callbacks.py:16] INFO For batch 40/312, loss is  162.99.
2019-09-12 00:42:53,170 [callbacks.py:16] INFO For batch 80/312, loss is   89.30.
2019-09-12 00:43:02,024 [callbacks.py:16] INFO For batch 120/312, loss is   88.60.
2019-09-12 00:43:10,897 [callbacks.py:16] INFO For batch 160/312, loss is   88.04.
2019-09-12 00:43:19,753 [callbacks.py:16] INFO For batch 200/312, loss is   86.84.
2019-09-12 00:43:28,758 [callbacks.py:16] INFO For batch 240/312, loss is   86.79.
2019-09-12 00:43:37,796 [callbacks.py:16] INFO For batch 280/312, loss is   85.18.
2019-09-12 00:43:51,812 [callbacks.py:24] INFO The validation average loss is  355.73.
2019-09-12 00:43:51,883 [callbacks.py:28] INFO The average loss for epoch 6 is   87.51.
2019-09-12 00:44:01,228 [callbacks.py:16] INFO For batch 40/312, loss is  152.08.
2019-09-12 00:44:09,921 [callbacks.py:16] INFO For batch 80/312, loss is   83.96.
2019-09-12 00:44:19,154 [callbacks.py:16] INFO For batch 120/312, loss is   82.52.
2019-09-12 00:44:29,123 [callbacks.py:16] INFO For batch 160/312, loss is   82.70.
2019-09-12 00:44:38,115 [callbacks.py:16] INFO For batch 200/312, loss is   82.45.
2019-09-12 00:44:47,970 [callbacks.py:16] INFO For batch 240/312, loss is   82.72.
2019-09-12 00:44:58,498 [callbacks.py:16] INFO For batch 280/312, loss is   81.50.
2019-09-12 00:45:11,724 [callbacks.py:24] INFO The validation average loss is  365.77.
2019-09-12 00:45:11,725 [callbacks.py:28] INFO The average loss for epoch 7 is   82.69.
2019-09-12 00:45:21,276 [callbacks.py:16] INFO For batch 40/312, loss is  144.93.
2019-09-12 00:45:32,148 [callbacks.py:16] INFO For batch 80/312, loss is   80.40.
2019-09-12 00:45:42,913 [callbacks.py:16] INFO For batch 120/312, loss is   79.65.
2019-09-12 00:45:54,890 [callbacks.py:16] INFO For batch 160/312, loss is   79.10.
2019-09-12 00:46:04,088 [callbacks.py:16] INFO For batch 200/312, loss is   79.30.
2019-09-12 00:46:14,591 [callbacks.py:16] INFO For batch 240/312, loss is   78.71.
2019-09-12 00:46:25,848 [callbacks.py:16] INFO For batch 280/312, loss is   77.22.
2019-09-12 00:46:39,907 [callbacks.py:24] INFO The validation average loss is  355.82.
2019-09-12 00:46:39,964 [callbacks.py:28] INFO The average loss for epoch 8 is   79.12.
2019-09-12 00:46:50,962 [callbacks.py:16] INFO For batch 40/312, loss is  140.39.
2019-09-12 00:47:02,638 [callbacks.py:16] INFO For batch 80/312, loss is   77.27.
2019-09-12 00:47:13,725 [callbacks.py:16] INFO For batch 120/312, loss is   75.91.
2019-09-12 00:47:24,176 [callbacks.py:16] INFO For batch 160/312, loss is   75.19.
2019-09-12 00:47:34,929 [callbacks.py:16] INFO For batch 200/312, loss is   76.33.
2019-09-12 00:47:45,153 [callbacks.py:16] INFO For batch 240/312, loss is   75.38.
2019-09-12 00:47:55,999 [callbacks.py:16] INFO For batch 280/312, loss is   74.99.
2019-09-12 00:48:11,090 [callbacks.py:24] INFO The validation average loss is  351.74.
2019-09-12 00:48:11,130 [callbacks.py:28] INFO The average loss for epoch 9 is   75.95.
2019-09-12 00:48:15,513 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:296: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
2019-09-12 00:48:15,525 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:141: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
2019-09-12 00:48:16,354 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:220: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv1d instead.
2019-09-12 00:48:16,431 [deprecation.py:323] WARNING From /home/comp/15485625/repos/DeepSpeechRecognition/model_language/transformer.py:317: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-12 00:48:20,486 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2019-09-12 00:48:20,516 [saver.py:1270] INFO Restoring parameters from logs_lm/thchs30multigpu_model_14
2019-09-12 00:48:36,747 [train.py:147] INFO epochs: 1: average loss = 1.139189
2019-09-12 00:48:50,279 [train.py:147] INFO epochs: 2: average loss = 1.138219
2019-09-12 00:49:03,769 [train.py:147] INFO epochs: 3: average loss = 1.136875
2019-09-12 00:49:17,052 [train.py:147] INFO epochs: 4: average loss = 1.135949
2019-09-12 00:49:30,553 [train.py:147] INFO epochs: 5: average loss = 1.135177
2019-09-12 00:49:44,162 [train.py:147] INFO epochs: 6: average loss = 1.134626
2019-09-12 00:49:57,592 [train.py:147] INFO epochs: 7: average loss = 1.133703
2019-09-12 00:50:11,176 [train.py:147] INFO epochs: 8: average loss = 1.133291
2019-09-12 00:50:24,678 [train.py:147] INFO epochs: 9: average loss = 1.132622
2019-09-12 00:50:38,106 [train.py:147] INFO epochs: 10: average loss = 1.132453
2019-09-12 00:56:26,516 [train.py:29] INFO Configurations: Namespace(batch_size=32, data_dir='/home/comp/15485625/data/speech/sp2chs', datasets='thchs30', epochs=100, log='train.log', logprefix='thchs30multigpu', lr=0.0008, nworkers=4, pretrain=None, saved_dir='./checkpoint')
2019-09-12 00:56:57,585 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-09-12 00:57:00,618 [deprecation.py:506] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-09-12 00:57:00,690 [layer_utils.py:106] INFO Model: "model_1"
2019-09-12 00:57:00,690 [layer_utils.py:107] INFO _________________________________________________________________
2019-09-12 00:57:00,690 [layer_utils.py:104] INFO Layer (type)                 Output Shape              Param #   
2019-09-12 00:57:00,690 [layer_utils.py:109] INFO =================================================================
2019-09-12 00:57:00,690 [layer_utils.py:104] INFO the_inputs (InputLayer)      (None, None, 200, 1)      0         
2019-09-12 00:57:00,690 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,691 [layer_utils.py:104] INFO conv2d_1 (Conv2D)            (None, None, 200, 32)     320       
2019-09-12 00:57:00,691 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,691 [layer_utils.py:104] INFO batch_normalization_1 (Batch (None, None, 200, 32)     128       
2019-09-12 00:57:00,691 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,691 [layer_utils.py:104] INFO conv2d_2 (Conv2D)            (None, None, 200, 32)     9248      
2019-09-12 00:57:00,691 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,691 [layer_utils.py:104] INFO batch_normalization_2 (Batch (None, None, 200, 32)     128       
2019-09-12 00:57:00,691 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,691 [layer_utils.py:104] INFO max_pooling2d_1 (MaxPooling2 (None, None, 100, 32)     0         
2019-09-12 00:57:00,691 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,691 [layer_utils.py:104] INFO conv2d_3 (Conv2D)            (None, None, 100, 64)     18496     
2019-09-12 00:57:00,691 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,692 [layer_utils.py:104] INFO batch_normalization_3 (Batch (None, None, 100, 64)     256       
2019-09-12 00:57:00,692 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,692 [layer_utils.py:104] INFO conv2d_4 (Conv2D)            (None, None, 100, 64)     36928     
2019-09-12 00:57:00,692 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,692 [layer_utils.py:104] INFO batch_normalization_4 (Batch (None, None, 100, 64)     256       
2019-09-12 00:57:00,692 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,692 [layer_utils.py:104] INFO max_pooling2d_2 (MaxPooling2 (None, None, 50, 64)      0         
2019-09-12 00:57:00,692 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,692 [layer_utils.py:104] INFO conv2d_5 (Conv2D)            (None, None, 50, 128)     73856     
2019-09-12 00:57:00,692 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,692 [layer_utils.py:104] INFO batch_normalization_5 (Batch (None, None, 50, 128)     512       
2019-09-12 00:57:00,692 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,693 [layer_utils.py:104] INFO conv2d_6 (Conv2D)            (None, None, 50, 128)     147584    
2019-09-12 00:57:00,693 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,693 [layer_utils.py:104] INFO batch_normalization_6 (Batch (None, None, 50, 128)     512       
2019-09-12 00:57:00,693 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,693 [layer_utils.py:104] INFO max_pooling2d_3 (MaxPooling2 (None, None, 25, 128)     0         
2019-09-12 00:57:00,693 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,693 [layer_utils.py:104] INFO conv2d_7 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:57:00,693 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,693 [layer_utils.py:104] INFO batch_normalization_7 (Batch (None, None, 25, 128)     512       
2019-09-12 00:57:00,693 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,693 [layer_utils.py:104] INFO conv2d_8 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:57:00,693 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,694 [layer_utils.py:104] INFO batch_normalization_8 (Batch (None, None, 25, 128)     512       
2019-09-12 00:57:00,694 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,694 [layer_utils.py:104] INFO conv2d_9 (Conv2D)            (None, None, 25, 128)     147584    
2019-09-12 00:57:00,694 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,694 [layer_utils.py:104] INFO batch_normalization_9 (Batch (None, None, 25, 128)     512       
2019-09-12 00:57:00,694 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,694 [layer_utils.py:104] INFO conv2d_10 (Conv2D)           (None, None, 25, 128)     147584    
2019-09-12 00:57:00,694 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,694 [layer_utils.py:104] INFO batch_normalization_10 (Batc (None, None, 25, 128)     512       
2019-09-12 00:57:00,694 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,694 [layer_utils.py:104] INFO reshape_1 (Reshape)          (None, None, 3200)        0         
2019-09-12 00:57:00,694 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,695 [layer_utils.py:104] INFO dropout_1 (Dropout)          (None, None, 3200)        0         
2019-09-12 00:57:00,695 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,695 [layer_utils.py:104] INFO dense_1 (Dense)              (None, None, 256)         819456    
2019-09-12 00:57:00,695 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,695 [layer_utils.py:104] INFO dropout_2 (Dropout)          (None, None, 256)         0         
2019-09-12 00:57:00,695 [layer_utils.py:171] INFO _________________________________________________________________
2019-09-12 00:57:00,695 [layer_utils.py:104] INFO dense_2 (Dense)              (None, None, 1042)        267794    
2019-09-12 00:57:00,695 [layer_utils.py:169] INFO =================================================================
2019-09-12 00:57:00,696 [layer_utils.py:182] INFO Total params: 1,967,858
2019-09-12 00:57:00,696 [layer_utils.py:183] INFO Trainable params: 1,965,938
2019-09-12 00:57:00,696 [layer_utils.py:184] INFO Non-trainable params: 1,920
2019-09-12 00:57:00,696 [layer_utils.py:185] INFO _________________________________________________________________
2019-09-12 00:57:05,090 [train.py:84] INFO # of samples: 10000
2019-09-12 00:57:05,152 [train.py:85] INFO mini-batch size: 32
2019-09-12 00:57:05,152 [train.py:86] INFO # of iterations per epoch: 312
2019-09-12 00:57:05,206 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-09-12 00:57:05,409 [deprecation.py:323] WARNING From /home/comp/15485625/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
2019-09-12 00:58:03,692 [callbacks.py:16] INFO For batch 40/312, loss is  266.33.
2019-09-12 00:58:18,035 [callbacks.py:16] INFO For batch 80/312, loss is  211.09.
2019-09-12 00:58:30,780 [callbacks.py:16] INFO For batch 120/312, loss is  207.79.
2019-09-12 00:58:40,588 [callbacks.py:16] INFO For batch 160/312, loss is  208.06.
2019-09-12 00:58:52,335 [callbacks.py:16] INFO For batch 200/312, loss is  206.72.
2019-09-12 00:59:01,292 [callbacks.py:16] INFO For batch 240/312, loss is  205.19.
2019-09-12 00:59:11,712 [callbacks.py:16] INFO For batch 280/312, loss is  205.45.
2019-09-12 00:59:23,888 [callbacks.py:24] INFO The validation average loss is  222.02.
2019-09-12 00:59:27,825 [callbacks.py:28] INFO The average loss for epoch 0 is  213.89.
2019-09-12 00:59:36,799 [callbacks.py:16] INFO For batch 40/312, loss is  367.76.
2019-09-12 00:59:44,062 [callbacks.py:16] INFO For batch 80/312, loss is  200.83.
2019-09-12 00:59:51,919 [callbacks.py:16] INFO For batch 120/312, loss is  197.37.
2019-09-12 01:00:00,759 [callbacks.py:16] INFO For batch 160/312, loss is  195.48.
2019-09-12 01:00:08,001 [callbacks.py:16] INFO For batch 200/312, loss is  188.46.
2019-09-12 01:00:15,695 [callbacks.py:16] INFO For batch 240/312, loss is  185.19.
2019-09-12 01:00:23,607 [callbacks.py:16] INFO For batch 280/312, loss is  177.80.
2019-09-12 01:00:35,088 [callbacks.py:24] INFO The validation average loss is  246.35.
2019-09-12 01:00:35,089 [callbacks.py:28] INFO The average loss for epoch 1 is  190.94.
2019-09-12 01:00:43,178 [callbacks.py:16] INFO For batch 40/312, loss is  307.43.
2019-09-12 01:00:51,515 [callbacks.py:16] INFO For batch 80/312, loss is  163.56.
2019-09-12 01:01:00,491 [callbacks.py:16] INFO For batch 120/312, loss is  157.75.
2019-09-12 01:01:07,971 [callbacks.py:16] INFO For batch 160/312, loss is  153.44.
2019-09-12 01:01:15,476 [callbacks.py:16] INFO For batch 200/312, loss is  149.36.
2019-09-12 01:01:22,770 [callbacks.py:16] INFO For batch 240/312, loss is  144.77.
2019-09-12 01:01:30,127 [callbacks.py:16] INFO For batch 280/312, loss is  140.13.
2019-09-12 01:01:41,549 [callbacks.py:24] INFO The validation average loss is  261.11.
2019-09-12 01:01:41,560 [callbacks.py:28] INFO The average loss for epoch 2 is  152.43.
2019-09-12 01:01:49,899 [callbacks.py:16] INFO For batch 40/312, loss is  246.20.
2019-09-12 01:01:57,866 [callbacks.py:16] INFO For batch 80/312, loss is  131.98.
2019-09-12 01:02:05,442 [callbacks.py:16] INFO For batch 120/312, loss is  130.18.
2019-09-12 01:02:13,481 [callbacks.py:16] INFO For batch 160/312, loss is  127.98.
2019-09-12 01:02:20,751 [callbacks.py:16] INFO For batch 200/312, loss is  124.09.
2019-09-12 01:02:28,731 [callbacks.py:16] INFO For batch 240/312, loss is  122.47.
2019-09-12 01:02:36,143 [callbacks.py:16] INFO For batch 280/312, loss is  120.24.
2019-09-12 01:02:46,985 [callbacks.py:24] INFO The validation average loss is  286.32.
2019-09-12 01:02:46,988 [callbacks.py:28] INFO The average loss for epoch 3 is  126.75.
2019-09-12 01:02:55,952 [callbacks.py:16] INFO For batch 40/312, loss is  211.34.
2019-09-12 01:03:03,869 [callbacks.py:16] INFO For batch 80/312, loss is  114.67.
2019-09-12 01:03:11,310 [callbacks.py:16] INFO For batch 120/312, loss is  114.48.
2019-09-12 01:03:18,989 [callbacks.py:16] INFO For batch 160/312, loss is  111.30.
2019-09-12 01:03:26,182 [callbacks.py:16] INFO For batch 200/312, loss is  110.42.
2019-09-12 01:03:33,755 [callbacks.py:16] INFO For batch 240/312, loss is  109.32.
2019-09-12 01:03:41,253 [callbacks.py:16] INFO For batch 280/312, loss is  107.64.
2019-09-12 01:03:51,776 [callbacks.py:24] INFO The validation average loss is  297.45.
2019-09-12 01:03:51,944 [callbacks.py:28] INFO The average loss for epoch 4 is  111.54.
2019-09-12 01:03:59,698 [callbacks.py:16] INFO For batch 40/312, loss is  190.98.
2019-09-12 01:04:07,535 [callbacks.py:16] INFO For batch 80/312, loss is  104.08.
2019-09-12 01:04:15,159 [callbacks.py:16] INFO For batch 120/312, loss is  104.24.
2019-09-12 01:04:22,264 [callbacks.py:16] INFO For batch 160/312, loss is  101.76.
2019-09-12 01:04:29,792 [callbacks.py:16] INFO For batch 200/312, loss is  101.26.
2019-09-12 01:04:37,052 [callbacks.py:16] INFO For batch 240/312, loss is   98.87.
2019-09-12 01:04:44,523 [callbacks.py:16] INFO For batch 280/312, loss is   99.56.
2019-09-12 01:04:57,261 [callbacks.py:24] INFO The validation average loss is  336.03.
2019-09-12 01:04:57,305 [callbacks.py:28] INFO The average loss for epoch 5 is  101.78.
2019-09-12 01:05:04,985 [callbacks.py:16] INFO For batch 40/312, loss is  176.13.
2019-09-12 01:05:12,519 [callbacks.py:16] INFO For batch 80/312, loss is   96.10.
2019-09-12 01:05:20,091 [callbacks.py:16] INFO For batch 120/312, loss is   96.41.
2019-09-12 01:05:27,424 [callbacks.py:16] INFO For batch 160/312, loss is   94.59.
2019-09-12 01:05:35,872 [callbacks.py:16] INFO For batch 200/312, loss is   93.83.
2019-09-12 01:05:44,616 [callbacks.py:16] INFO For batch 240/312, loss is   91.63.
2019-09-12 01:05:55,030 [callbacks.py:16] INFO For batch 280/312, loss is   93.64.
2019-09-12 01:06:09,004 [callbacks.py:24] INFO The validation average loss is  340.19.
2019-09-12 01:06:09,006 [callbacks.py:28] INFO The average loss for epoch 6 is   94.52.
2019-09-12 01:06:17,702 [callbacks.py:16] INFO For batch 40/312, loss is  163.51.
2019-09-12 01:06:27,353 [callbacks.py:16] INFO For batch 80/312, loss is   92.08.
2019-09-12 01:06:36,394 [callbacks.py:16] INFO For batch 120/312, loss is   90.21.
2019-09-12 01:06:45,234 [callbacks.py:16] INFO For batch 160/312, loss is   88.95.
2019-09-12 01:06:55,717 [callbacks.py:16] INFO For batch 200/312, loss is   89.26.
2019-09-12 01:07:05,373 [callbacks.py:16] INFO For batch 240/312, loss is   87.96.
2019-09-12 01:07:14,482 [callbacks.py:16] INFO For batch 280/312, loss is   87.91.
2019-09-12 01:07:26,416 [callbacks.py:24] INFO The validation average loss is  349.34.
2019-09-12 01:07:26,427 [callbacks.py:28] INFO The average loss for epoch 7 is   89.51.
2019-09-12 01:07:36,028 [callbacks.py:16] INFO For batch 40/312, loss is  158.90.
2019-09-12 01:07:45,493 [callbacks.py:16] INFO For batch 80/312, loss is   85.42.
2019-09-12 01:07:56,386 [callbacks.py:16] INFO For batch 120/312, loss is   85.69.
2019-09-12 01:08:05,711 [callbacks.py:16] INFO For batch 160/312, loss is   85.60.
2019-09-12 01:08:15,136 [callbacks.py:16] INFO For batch 200/312, loss is   84.13.
2019-09-12 01:08:24,639 [callbacks.py:16] INFO For batch 240/312, loss is   85.32.
2019-09-12 01:08:35,831 [callbacks.py:16] INFO For batch 280/312, loss is   84.51.
2019-09-12 01:08:50,423 [callbacks.py:24] INFO The validation average loss is  357.94.
2019-09-12 01:08:50,424 [callbacks.py:28] INFO The average loss for epoch 8 is   85.26.
2019-09-12 01:09:01,129 [callbacks.py:16] INFO For batch 40/312, loss is  149.16.
2019-09-12 01:09:11,032 [callbacks.py:16] INFO For batch 80/312, loss is   82.43.
2019-09-12 01:09:22,337 [callbacks.py:16] INFO For batch 120/312, loss is   82.35.
2019-09-12 01:09:32,739 [callbacks.py:16] INFO For batch 160/312, loss is   82.56.
2019-09-12 01:09:41,652 [callbacks.py:16] INFO For batch 200/312, loss is   81.26.
2019-09-12 01:09:51,600 [callbacks.py:16] INFO For batch 240/312, loss is   80.14.
2019-09-12 01:10:01,686 [callbacks.py:16] INFO For batch 280/312, loss is   81.22.
2019-09-12 01:10:14,644 [callbacks.py:24] INFO The validation average loss is  351.66.
2019-09-12 01:10:14,650 [callbacks.py:28] INFO The average loss for epoch 9 is   81.72.
2019-09-12 01:10:25,380 [callbacks.py:16] INFO For batch 40/312, loss is  145.49.
2019-09-12 01:10:35,791 [callbacks.py:16] INFO For batch 80/312, loss is   79.85.
2019-09-12 01:10:46,113 [callbacks.py:16] INFO For batch 120/312, loss is   78.27.
2019-09-12 01:10:56,537 [callbacks.py:16] INFO For batch 160/312, loss is   79.01.
2019-09-12 01:11:08,367 [callbacks.py:16] INFO For batch 200/312, loss is   79.08.
2019-09-12 01:11:18,681 [callbacks.py:16] INFO For batch 240/312, loss is   79.10.
2019-09-12 01:11:29,318 [callbacks.py:16] INFO For batch 280/312, loss is   77.63.
2019-09-12 01:11:41,991 [callbacks.py:24] INFO The validation average loss is  362.45.
2019-09-12 01:11:42,196 [callbacks.py:28] INFO The average loss for epoch 10 is   78.90.
2019-09-12 01:11:53,597 [callbacks.py:16] INFO For batch 40/312, loss is  139.44.
2019-09-12 01:12:04,154 [callbacks.py:16] INFO For batch 80/312, loss is   77.29.
2019-09-12 01:12:13,377 [callbacks.py:16] INFO For batch 120/312, loss is   76.82.
2019-09-12 01:12:22,629 [callbacks.py:16] INFO For batch 160/312, loss is   76.54.
2019-09-12 01:12:32,199 [callbacks.py:16] INFO For batch 200/312, loss is   76.08.
2019-09-12 01:12:42,716 [callbacks.py:16] INFO For batch 240/312, loss is   76.66.
2019-09-12 01:12:52,568 [callbacks.py:16] INFO For batch 280/312, loss is   75.96.
2019-09-12 01:13:08,420 [callbacks.py:24] INFO The validation average loss is  361.31.
2019-09-12 01:13:08,488 [callbacks.py:28] INFO The average loss for epoch 11 is   76.59.
2019-09-12 01:13:19,077 [callbacks.py:16] INFO For batch 40/312, loss is  135.84.
2019-09-12 01:13:30,603 [callbacks.py:16] INFO For batch 80/312, loss is   75.27.
2019-09-12 01:13:45,603 [callbacks.py:16] INFO For batch 120/312, loss is   75.03.
2019-09-12 01:14:04,161 [callbacks.py:16] INFO For batch 160/312, loss is   74.77.
2019-09-12 01:14:28,169 [callbacks.py:16] INFO For batch 200/312, loss is   75.00.
2019-09-12 01:14:44,550 [callbacks.py:16] INFO For batch 240/312, loss is   74.74.
2019-09-12 01:15:06,606 [callbacks.py:16] INFO For batch 280/312, loss is   74.67.
2019-09-12 01:15:29,948 [callbacks.py:24] INFO The validation average loss is  380.42.
2019-09-12 01:15:29,967 [callbacks.py:28] INFO The average loss for epoch 12 is   74.83.
2019-09-12 01:15:49,226 [callbacks.py:16] INFO For batch 40/312, loss is  132.44.
2019-09-12 01:16:15,240 [callbacks.py:16] INFO For batch 80/312, loss is   73.70.
2019-09-12 01:16:33,988 [callbacks.py:16] INFO For batch 120/312, loss is   72.92.
2019-09-12 01:16:57,139 [callbacks.py:16] INFO For batch 160/312, loss is   72.13.
2019-09-12 01:17:17,996 [callbacks.py:16] INFO For batch 200/312, loss is   72.76.
2019-09-12 01:17:43,100 [callbacks.py:16] INFO For batch 240/312, loss is   71.84.
2019-09-12 01:18:01,679 [callbacks.py:16] INFO For batch 280/312, loss is   72.90.
2019-09-12 01:18:26,911 [callbacks.py:24] INFO The validation average loss is  382.00.
2019-09-12 01:18:26,929 [callbacks.py:28] INFO The average loss for epoch 13 is   72.77.
2019-09-12 01:18:45,956 [callbacks.py:16] INFO For batch 40/312, loss is  128.84.
2019-09-12 01:19:06,513 [callbacks.py:16] INFO For batch 80/312, loss is   70.52.
2019-09-12 01:19:23,600 [callbacks.py:16] INFO For batch 120/312, loss is   71.47.
2019-09-12 01:19:39,782 [callbacks.py:16] INFO For batch 160/312, loss is   72.58.
2019-09-12 01:19:56,183 [callbacks.py:16] INFO For batch 200/312, loss is   71.07.
2019-09-12 01:20:14,630 [callbacks.py:16] INFO For batch 240/312, loss is   71.32.
2019-09-12 01:20:28,424 [callbacks.py:16] INFO For batch 280/312, loss is   70.78.
2019-09-12 01:20:52,759 [callbacks.py:24] INFO The validation average loss is  384.13.
2019-09-12 01:20:52,835 [callbacks.py:28] INFO The average loss for epoch 14 is   71.36.
2019-09-12 01:21:09,425 [callbacks.py:16] INFO For batch 40/312, loss is  127.63.
2019-09-12 01:21:22,840 [callbacks.py:16] INFO For batch 80/312, loss is   70.44.
2019-09-12 01:21:36,121 [callbacks.py:16] INFO For batch 120/312, loss is   71.23.
2019-09-12 01:21:53,861 [callbacks.py:16] INFO For batch 160/312, loss is   69.49.
2019-09-12 01:22:08,280 [callbacks.py:16] INFO For batch 200/312, loss is   69.50.
2019-09-12 01:22:25,711 [callbacks.py:16] INFO For batch 240/312, loss is   69.55.
2019-09-12 01:22:41,709 [callbacks.py:16] INFO For batch 280/312, loss is   68.48.
2019-09-12 01:23:05,346 [callbacks.py:24] INFO The validation average loss is  388.85.
2019-09-12 01:23:05,384 [callbacks.py:28] INFO The average loss for epoch 15 is   69.69.
2019-09-12 01:23:18,982 [callbacks.py:16] INFO For batch 40/312, loss is  123.48.
2019-09-12 01:23:34,964 [callbacks.py:16] INFO For batch 80/312, loss is   68.02.
2019-09-12 01:23:51,280 [callbacks.py:16] INFO For batch 120/312, loss is   68.89.
2019-09-12 01:24:05,334 [callbacks.py:16] INFO For batch 160/312, loss is   68.51.
2019-09-12 01:24:20,163 [callbacks.py:16] INFO For batch 200/312, loss is   67.97.
2019-09-12 01:24:35,651 [callbacks.py:16] INFO For batch 240/312, loss is   67.67.
2019-09-12 01:24:52,776 [callbacks.py:16] INFO For batch 280/312, loss is   66.77.
2019-09-12 01:25:12,430 [callbacks.py:24] INFO The validation average loss is  378.25.
2019-09-12 01:25:12,437 [callbacks.py:28] INFO The average loss for epoch 16 is   68.03.
2019-09-12 01:25:27,327 [callbacks.py:16] INFO For batch 40/312, loss is  121.67.
2019-09-12 01:25:44,155 [callbacks.py:16] INFO For batch 80/312, loss is   67.20.
2019-09-12 01:26:00,000 [callbacks.py:16] INFO For batch 120/312, loss is   66.85.
2019-09-12 01:26:15,044 [callbacks.py:16] INFO For batch 160/312, loss is   67.44.
2019-09-12 01:26:31,319 [callbacks.py:16] INFO For batch 200/312, loss is   66.45.
2019-09-12 01:26:46,616 [callbacks.py:16] INFO For batch 240/312, loss is   67.46.
2019-09-12 01:27:06,066 [callbacks.py:16] INFO For batch 280/312, loss is   67.36.
2019-09-12 01:27:25,749 [callbacks.py:24] INFO The validation average loss is  375.11.
2019-09-12 01:27:25,876 [callbacks.py:28] INFO The average loss for epoch 17 is   67.22.
2019-09-12 01:27:41,879 [callbacks.py:16] INFO For batch 40/312, loss is  120.57.
2019-09-12 01:28:00,420 [callbacks.py:16] INFO For batch 80/312, loss is   66.28.
2019-09-12 01:28:15,175 [callbacks.py:16] INFO For batch 120/312, loss is   65.89.
2019-09-12 01:28:30,841 [callbacks.py:16] INFO For batch 160/312, loss is   66.03.
2019-09-12 01:28:45,738 [callbacks.py:16] INFO For batch 200/312, loss is   64.94.
2019-09-12 01:29:04,644 [callbacks.py:16] INFO For batch 240/312, loss is   65.95.
2019-09-12 01:29:18,882 [callbacks.py:16] INFO For batch 280/312, loss is   64.88.
2019-09-12 01:29:44,410 [callbacks.py:24] INFO The validation average loss is  368.77.
2019-09-12 01:29:44,433 [callbacks.py:28] INFO The average loss for epoch 18 is   65.68.
2019-09-12 01:30:02,751 [callbacks.py:16] INFO For batch 40/312, loss is  118.99.
2019-09-12 01:30:17,216 [callbacks.py:16] INFO For batch 80/312, loss is   66.33.
2019-09-12 01:30:31,232 [callbacks.py:16] INFO For batch 120/312, loss is   67.04.
2019-09-12 01:30:57,498 [callbacks.py:16] INFO For batch 160/312, loss is   64.51.
2019-09-12 01:31:17,942 [callbacks.py:16] INFO For batch 200/312, loss is   64.65.
2019-09-12 01:31:31,979 [callbacks.py:16] INFO For batch 240/312, loss is   65.20.
2019-09-12 01:31:46,565 [callbacks.py:16] INFO For batch 280/312, loss is   65.18.
2019-09-12 01:32:12,317 [callbacks.py:24] INFO The validation average loss is  376.09.
2019-09-12 01:32:12,328 [callbacks.py:28] INFO The average loss for epoch 19 is   65.66.
2019-09-12 01:32:28,180 [callbacks.py:16] INFO For batch 40/312, loss is  117.11.
2019-09-12 01:32:47,009 [callbacks.py:16] INFO For batch 80/312, loss is   64.14.
2019-09-12 01:33:05,487 [callbacks.py:16] INFO For batch 120/312, loss is   64.20.
2019-09-12 01:33:29,348 [callbacks.py:16] INFO For batch 160/312, loss is   64.25.
2019-09-12 01:33:48,979 [callbacks.py:16] INFO For batch 200/312, loss is   64.34.
2019-09-12 01:34:08,894 [callbacks.py:16] INFO For batch 240/312, loss is   63.48.
2019-09-12 01:34:22,354 [callbacks.py:16] INFO For batch 280/312, loss is   63.97.
2019-09-12 01:34:43,384 [callbacks.py:24] INFO The validation average loss is  363.28.
2019-09-12 01:34:43,436 [callbacks.py:28] INFO The average loss for epoch 20 is   64.12.
2019-09-12 01:35:00,126 [callbacks.py:16] INFO For batch 40/312, loss is  114.63.
2019-09-12 01:35:15,931 [callbacks.py:16] INFO For batch 80/312, loss is   63.84.
2019-09-12 01:35:33,668 [callbacks.py:16] INFO For batch 120/312, loss is   64.15.
2019-09-12 01:35:55,345 [callbacks.py:16] INFO For batch 160/312, loss is   63.00.
2019-09-12 01:36:22,002 [callbacks.py:16] INFO For batch 200/312, loss is   63.87.
2019-09-12 01:36:39,106 [callbacks.py:16] INFO For batch 240/312, loss is   62.98.
2019-09-12 01:37:13,748 [callbacks.py:16] INFO For batch 280/312, loss is   61.98.
2019-09-12 01:37:44,021 [callbacks.py:24] INFO The validation average loss is  400.21.
2019-09-12 01:37:44,027 [callbacks.py:28] INFO The average loss for epoch 21 is   63.35.
2019-09-12 01:38:21,099 [callbacks.py:16] INFO For batch 40/312, loss is  114.54.
2019-09-12 01:38:48,349 [callbacks.py:16] INFO For batch 80/312, loss is   62.71.
2019-09-12 01:39:14,914 [callbacks.py:16] INFO For batch 120/312, loss is   62.91.
2019-09-12 01:39:36,320 [callbacks.py:16] INFO For batch 160/312, loss is   61.76.
2019-09-12 01:40:15,760 [callbacks.py:16] INFO For batch 200/312, loss is   62.69.
2019-09-12 01:41:22,565 [callbacks.py:16] INFO For batch 240/312, loss is   61.90.
2019-09-12 01:41:46,047 [callbacks.py:16] INFO For batch 280/312, loss is   61.84.
2019-09-12 01:42:20,408 [callbacks.py:24] INFO The validation average loss is  395.45.
2019-09-12 01:42:20,430 [callbacks.py:28] INFO The average loss for epoch 22 is   62.56.
2019-09-12 01:42:43,931 [callbacks.py:16] INFO For batch 40/312, loss is  112.39.
2019-09-12 01:43:07,381 [callbacks.py:16] INFO For batch 80/312, loss is   61.96.
2019-09-12 01:43:27,099 [callbacks.py:16] INFO For batch 120/312, loss is   62.25.
2019-09-12 01:43:48,262 [callbacks.py:16] INFO For batch 160/312, loss is   62.32.
2019-09-12 01:44:08,455 [callbacks.py:16] INFO For batch 200/312, loss is   62.04.
2019-09-12 01:44:27,893 [callbacks.py:16] INFO For batch 240/312, loss is   61.44.
2019-09-12 01:44:48,124 [callbacks.py:16] INFO For batch 280/312, loss is   61.61.
2019-09-12 01:45:22,199 [callbacks.py:24] INFO The validation average loss is  397.86.
2019-09-12 01:45:22,202 [callbacks.py:28] INFO The average loss for epoch 23 is   61.98.
2019-09-12 01:45:44,644 [callbacks.py:16] INFO For batch 40/312, loss is  110.66.
2019-09-12 01:46:04,807 [callbacks.py:16] INFO For batch 80/312, loss is   61.62.
2019-09-12 01:46:24,466 [callbacks.py:16] INFO For batch 120/312, loss is   59.97.
2019-09-12 01:46:43,578 [callbacks.py:16] INFO For batch 160/312, loss is   60.93.
2019-09-12 01:47:06,387 [callbacks.py:16] INFO For batch 200/312, loss is   60.32.
2019-09-12 01:47:23,497 [callbacks.py:16] INFO For batch 240/312, loss is   61.35.
2019-09-12 01:47:44,170 [callbacks.py:16] INFO For batch 280/312, loss is   60.05.
2019-09-12 01:48:16,167 [callbacks.py:24] INFO The validation average loss is  407.27.
2019-09-12 01:48:16,198 [callbacks.py:28] INFO The average loss for epoch 24 is   60.86.
2019-09-12 01:48:41,687 [callbacks.py:16] INFO For batch 40/312, loss is  109.68.
2019-09-12 01:49:24,552 [callbacks.py:16] INFO For batch 80/312, loss is   60.71.
2019-09-12 01:49:51,851 [callbacks.py:16] INFO For batch 120/312, loss is   60.75.
2019-09-12 01:50:18,691 [callbacks.py:16] INFO For batch 160/312, loss is   60.75.
2019-09-12 01:50:42,369 [callbacks.py:16] INFO For batch 200/312, loss is   60.76.
2019-09-12 01:51:21,436 [callbacks.py:16] INFO For batch 240/312, loss is   60.68.
2019-09-12 01:51:45,115 [callbacks.py:16] INFO For batch 280/312, loss is   60.48.
2019-09-12 01:52:20,121 [callbacks.py:24] INFO The validation average loss is  394.02.
2019-09-12 01:52:20,134 [callbacks.py:28] INFO The average loss for epoch 25 is   60.74.
2019-09-12 01:52:47,178 [callbacks.py:16] INFO For batch 40/312, loss is  109.68.
2019-09-12 01:53:11,392 [callbacks.py:16] INFO For batch 80/312, loss is   60.52.
2019-09-12 01:53:32,119 [callbacks.py:16] INFO For batch 120/312, loss is   60.40.
2019-09-12 01:53:58,550 [callbacks.py:16] INFO For batch 160/312, loss is   60.63.
2019-09-12 01:54:17,548 [callbacks.py:16] INFO For batch 200/312, loss is   59.30.
2019-09-12 01:54:35,537 [callbacks.py:16] INFO For batch 240/312, loss is   59.64.
2019-09-12 01:55:01,151 [callbacks.py:16] INFO For batch 280/312, loss is   60.52.
2019-09-12 01:55:48,633 [callbacks.py:24] INFO The validation average loss is  387.75.
2019-09-12 01:55:48,697 [callbacks.py:28] INFO The average loss for epoch 26 is   60.18.
2019-09-12 01:56:18,979 [callbacks.py:16] INFO For batch 40/312, loss is  107.62.
2019-09-12 01:56:39,500 [callbacks.py:16] INFO For batch 80/312, loss is   59.42.
2019-09-12 01:57:01,060 [callbacks.py:16] INFO For batch 120/312, loss is   59.64.
2019-09-12 01:57:21,250 [callbacks.py:16] INFO For batch 160/312, loss is   58.86.
2019-09-12 01:57:39,068 [callbacks.py:16] INFO For batch 200/312, loss is   58.97.
2019-09-12 01:58:04,495 [callbacks.py:16] INFO For batch 240/312, loss is   59.32.
2019-09-12 01:58:23,098 [callbacks.py:16] INFO For batch 280/312, loss is   59.05.
2019-09-12 01:58:53,620 [callbacks.py:24] INFO The validation average loss is  406.53.
2019-09-12 01:58:53,728 [callbacks.py:28] INFO The average loss for epoch 27 is   59.27.
2019-09-12 01:59:17,439 [callbacks.py:16] INFO For batch 40/312, loss is  106.97.
2019-09-12 02:00:03,695 [callbacks.py:16] INFO For batch 80/312, loss is   59.62.
2019-09-12 02:00:20,506 [callbacks.py:16] INFO For batch 120/312, loss is   58.67.
2019-09-12 02:00:42,937 [callbacks.py:16] INFO For batch 160/312, loss is   59.41.
2019-09-12 02:01:03,652 [callbacks.py:16] INFO For batch 200/312, loss is   58.30.
2019-09-12 02:01:33,560 [callbacks.py:16] INFO For batch 240/312, loss is   59.32.
2019-09-12 02:01:52,085 [callbacks.py:16] INFO For batch 280/312, loss is   58.51.
2019-09-12 02:02:25,393 [callbacks.py:24] INFO The validation average loss is  404.14.
2019-09-12 02:02:25,411 [callbacks.py:28] INFO The average loss for epoch 28 is   59.07.
2019-09-12 02:02:53,619 [callbacks.py:16] INFO For batch 40/312, loss is  105.06.
2019-09-12 02:03:15,427 [callbacks.py:16] INFO For batch 80/312, loss is   58.80.
2019-09-12 02:03:36,522 [callbacks.py:16] INFO For batch 120/312, loss is   57.76.
2019-09-12 02:04:01,060 [callbacks.py:16] INFO For batch 160/312, loss is   58.17.
2019-09-12 02:04:19,383 [callbacks.py:16] INFO For batch 200/312, loss is   58.59.
2019-09-12 02:04:39,275 [callbacks.py:16] INFO For batch 240/312, loss is   58.36.
2019-09-12 02:05:03,886 [callbacks.py:16] INFO For batch 280/312, loss is   58.07.
2019-09-12 02:05:28,614 [callbacks.py:24] INFO The validation average loss is  411.93.
2019-09-12 02:05:28,672 [callbacks.py:28] INFO The average loss for epoch 29 is   58.35.
2019-09-12 02:05:49,131 [callbacks.py:16] INFO For batch 40/312, loss is  105.94.
2019-09-12 02:06:11,365 [callbacks.py:16] INFO For batch 80/312, loss is   58.46.
2019-09-12 02:06:28,336 [callbacks.py:16] INFO For batch 120/312, loss is   57.71.
2019-09-12 02:06:47,744 [callbacks.py:16] INFO For batch 160/312, loss is   57.77.
2019-09-12 02:07:09,369 [callbacks.py:16] INFO For batch 200/312, loss is   58.29.
2019-09-12 02:07:27,360 [callbacks.py:16] INFO For batch 240/312, loss is   57.00.
2019-09-12 02:07:49,385 [callbacks.py:16] INFO For batch 280/312, loss is   58.81.
2019-09-12 02:08:23,901 [callbacks.py:24] INFO The validation average loss is  411.83.
2019-09-12 02:08:23,919 [callbacks.py:28] INFO The average loss for epoch 30 is   58.05.
2019-09-12 02:09:23,215 [callbacks.py:16] INFO For batch 40/312, loss is  104.20.
2019-09-12 02:09:46,297 [callbacks.py:16] INFO For batch 80/312, loss is   57.78.
2019-09-12 02:10:12,864 [callbacks.py:16] INFO For batch 120/312, loss is   57.23.
2019-09-12 02:10:33,773 [callbacks.py:16] INFO For batch 160/312, loss is   56.96.
